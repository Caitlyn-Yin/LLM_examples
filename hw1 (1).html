<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>hw1</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0px solid transparent;
  border-right: 0px solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0px solid transparent;
  border-bottom: 0px solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
	border:1px solid transparent;
  background-color: transparent;
  position: absolute;
	z-index:1;
	right:3%;
	top: 0;
	bottom: 0;
	margin: auto;
	padding: 7px 0;
	display: none;
	vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
	content: "X";
	display: block;
	width: 15px;
	height: 15px;
	text-align: center;
	color:#000;
	font-weight: normal;
	font-size: 12px;
	cursor: pointer;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
  background: inherit;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-bottom:10px;
  margin-top:0; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  font-size:36px;
  line-height:40px; }

h2.bp3-heading, .bp3-running-text h2{
  font-size:28px;
  line-height:32px; }

h3.bp3-heading, .bp3-running-text h3{
  font-size:22px;
  line-height:25px; }

h4.bp3-heading, .bp3-running-text h4{
  font-size:18px;
  line-height:21px; }

h5.bp3-heading, .bp3-running-text h5{
  font-size:16px;
  line-height:19px; }

h6.bp3-heading, .bp3-running-text h6{
  font-size:14px;
  line-height:16px; }
.bp3-ui-text{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none; }

.bp3-monospace-text{
  font-family:monospace;
  text-transform:none; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  font-size:14px;
  line-height:1.5; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15);
    margin:20px 0; }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  color:#106ba3;
  text-decoration:none; }
  a:hover{
    color:#106ba3;
    cursor:pointer;
    text-decoration:underline; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  font-size:smaller;
  padding:2px 5px; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  color:#182026;
  display:block;
  font-size:13px;
  line-height:1.4;
  margin:10px 0;
  padding:13px 15px 12px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit;
    font-size:inherit;
    padding:0; }

.bp3-running-text kbd, .bp3-key{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-family:inherit;
  font-size:12px;
  height:24px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  line-height:24px;
  min-width:24px;
  padding:3px 6px;
  vertical-align:middle; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  margin:0 0 10px;
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    font-size:40px;
    margin-right:20px;
    margin-top:0; }

.bp3-alert-contents{
  word-break:break-word; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  cursor:default;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  height:30px;
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-breadcrumbs > li{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }
    .bp3-breadcrumbs > li::after{
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 00-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      content:"";
      display:block;
      height:16px;
      margin:0 5px;
      width:16px; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    font-size:inherit;
    font-weight:inherit;
    vertical-align:baseline; }

.bp3-breadcrumbs-collapsed{
  background:#ced9e0;
  border:none;
  border-radius:3px;
  cursor:pointer;
  margin-right:2px;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    content:"";
    display:block;
    height:16px;
    width:16px; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    color:#182026;
    text-decoration:none; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  min-height:30px;
  min-width:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      background-color:#106ba3;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      background-color:#0e5a8a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      background-color:#0d8050;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      background-color:#0a6640;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      background-color:#bf7326;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      background-color:#a66321;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      background-color:#c23030;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      background-color:#a82a2a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-height:40px;
    min-width:40px;
    font-size:16px;
    padding:5px 15px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      margin:0;
      position:absolute; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button.bp3-minimal:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button.bp3-outlined{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    border:1px solid rgba(24, 32, 38, 0.2);
    -webkit-box-sizing:border-box;
            box-sizing:border-box; }
    .bp3-button.bp3-outlined:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-outlined:active, .bp3-button.bp3-outlined.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-outlined{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-outlined:hover, .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-outlined:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover, .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover, .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover, .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover, .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled:hover{
      border-color:rgba(92, 112, 128, 0.1); }
    .bp3-dark .bp3-button.bp3-outlined{
      border-color:rgba(255, 255, 255, 0.4); }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        border-color:rgba(255, 255, 255, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      border-color:rgba(16, 107, 163, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        border-color:rgba(16, 107, 163, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        border-color:rgba(72, 175, 240, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          border-color:rgba(72, 175, 240, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      border-color:rgba(13, 128, 80, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        border-color:rgba(13, 128, 80, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        border-color:rgba(61, 204, 145, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          border-color:rgba(61, 204, 145, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      border-color:rgba(191, 115, 38, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        border-color:rgba(191, 115, 38, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        border-color:rgba(255, 179, 102, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          border-color:rgba(255, 179, 102, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      border-color:rgba(194, 48, 48, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        border-color:rgba(194, 48, 48, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        border-color:rgba(255, 115, 115, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          border-color:rgba(255, 115, 115, 0.2); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    border-bottom-right-radius:0;
    border-top-right-radius:0;
    margin-right:-1px; }
  .bp3-button-group.bp3-minimal .bp3-button{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      height:100%;
      width:unset; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  font-size:14px;
  line-height:1.5;
  background-color:rgba(138, 155, 168, 0.15);
  border-radius:3px;
  padding:10px 12px 9px;
  position:relative;
  width:100%; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout .bp3-heading{
    line-height:20px;
    margin-bottom:5px;
    margin-top:0; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  opacity:0.9;
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  width:100%; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }

.bp3-dialog{
  background:#ebf1f5;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text;
  width:500px; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    background:#293742;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-dialog-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding-left:20px;
  padding-right:5px;
  z-index:30; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    background:#30404d;
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  margin:20px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-multistep-dialog-panels{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }

.bp3-multistep-dialog-left-panel{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:1;
      -ms-flex:1;
          flex:1;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column; }
  .bp3-dark .bp3-multistep-dialog-left-panel{
    background:#202b33; }

.bp3-multistep-dialog-right-panel{
  background-color:#f5f8fa;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  border-radius:0 0 6px 0;
  -webkit-box-flex:3;
      -ms-flex:3;
          flex:3;
  min-width:0; }
  .bp3-dark .bp3-multistep-dialog-right-panel{
    background-color:#293742;
    border-left:1px solid rgba(16, 22, 26, 0.4); }

.bp3-multistep-dialog-footer{
  background-color:#ffffff;
  border-radius:0 0 6px 0;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  padding:10px; }
  .bp3-dark .bp3-multistep-dialog-footer{
    background:#30404d;
    border-top:1px solid rgba(16, 22, 26, 0.4); }

.bp3-dialog-step-container{
  background-color:#f5f8fa;
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-dialog-step-container{
    background:#293742;
    border-bottom:1px solid rgba(16, 22, 26, 0.4); }
  .bp3-dialog-step-container.bp3-dialog-step-viewed{
    background-color:#ffffff; }
    .bp3-dark .bp3-dialog-step-container.bp3-dialog-step-viewed{
      background:#30404d; }

.bp3-dialog-step{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#f5f8fa;
  border-radius:6px;
  cursor:not-allowed;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:4px;
  padding:6px 14px; }
  .bp3-dark .bp3-dialog-step{
    background:#293742; }
  .bp3-dialog-step-viewed .bp3-dialog-step{
    background-color:#ffffff;
    cursor:pointer; }
    .bp3-dark .bp3-dialog-step-viewed .bp3-dialog-step{
      background:#30404d; }
  .bp3-dialog-step:hover{
    background-color:#f5f8fa; }
    .bp3-dark .bp3-dialog-step:hover{
      background:#293742; }

.bp3-dialog-step-icon{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:rgba(92, 112, 128, 0.6);
  border-radius:50%;
  color:#ffffff;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:25px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:25px; }
  .bp3-dark .bp3-dialog-step-icon{
    background-color:rgba(167, 182, 194, 0.6); }
  .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-icon{
    background-color:#2b95d6; }
  .bp3-dialog-step-viewed .bp3-dialog-step-icon{
    background-color:#8a9ba8; }

.bp3-dialog-step-title{
  color:rgba(92, 112, 128, 0.6);
  -webkit-box-flex:1;
      -ms-flex:1;
          flex:1;
  padding-left:10px; }
  .bp3-dark .bp3-dialog-step-title{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-title{
    color:#2b95d6; }
  .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{
    color:#182026; }
    .bp3-dark .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{
      color:#f5f8fa; }
.bp3-drawer{
  background:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    height:50%;
    left:0;
    right:0;
    top:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-bottom{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-left{
    bottom:0;
    left:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-right{
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    background:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-drawer-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding:5px;
  padding-left:20px;
  position:relative; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  overflow:auto; }

.bp3-drawer-footer{
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  padding:10px 20px;
  position:relative; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  cursor:text;
  display:inline-block;
  max-width:100%;
  position:relative;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    bottom:-3px;
    left:-3px;
    position:absolute;
    right:-3px;
    top:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  color:inherit;
  display:inherit;
  font:inherit;
  letter-spacing:inherit;
  max-width:inherit;
  min-width:inherit;
  position:relative;
  resize:none;
  text-transform:inherit;
  vertical-align:top; }

.bp3-editable-text-input{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0;
  white-space:pre-wrap;
  width:100%; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    left:0;
    position:absolute;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    border-radius:inherit;
    z-index:2; }
    .bp3-control-group .bp3-input:focus{
      border-radius:3px;
      z-index:14; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    border-radius:inherit;
    z-index:4; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-left-container,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group .bp3-select:focus-within{
    z-index:5; }
  .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:-1px; }
  .bp3-control-group:not(.bp3-vertical) > .bp3-divider:not(:first-child){
    margin-left:6px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    border-radius:0 3px 3px 0;
    margin-right:0; }
  .bp3-control-group > :only-child{
    border-radius:3px;
    margin-right:0; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group .bp3-numeric-input:not(:first-child) .bp3-input-group{
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-control-group.bp3-fill{
    width:100%; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      border-radius:3px 3px 0 0;
      margin-top:0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  cursor:pointer;
  display:block;
  margin-bottom:10px;
  position:relative;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    left:0;
    opacity:0;
    position:absolute;
    top:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    cursor:pointer;
    display:inline-block;
    font-size:16px;
    height:1em;
    margin-right:10px;
    margin-top:-3px;
    position:relative;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none;
    vertical-align:middle;
    width:1em; }
    .bp3-control .bp3-control-indicator::before{
      content:"";
      display:block;
      height:1em;
      width:1em; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    background:#d8e1e8;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-left:10px;
    margin-top:1px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 00-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0012 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:auto; }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      background:#ffffff;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      height:calc(1em - 4px);
      left:0;
      margin:2px;
      position:absolute;
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      width:calc(1em - 4px); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    font-size:0.7em;
    text-align:center; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    line-height:0;
    margin-left:0.5em;
    margin-right:1.2em;
    visibility:hidden; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    line-height:1em;
    margin-left:1.2em;
    margin-right:0.5em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    line-height:1em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    line-height:0;
    visibility:hidden; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      background:#202b33;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  cursor:pointer;
  display:inline-block;
  height:30px;
  position:relative; }
  .bp3-file-input input{
    margin:0;
    min-width:200px;
    opacity:0; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      background:rgba(206, 217, 224, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(92, 112, 128, 0.6);
        cursor:not-allowed;
        outline:none; }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        background:rgba(57, 75, 89, 0.5);
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          -webkit-box-shadow:none;
                  box-shadow:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:rgba(92, 112, 128, 0.6);
  left:0;
  padding-right:80px;
  position:absolute;
  right:0;
  top:0;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-file-upload-input::after{
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026;
    min-height:24px;
    min-width:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    border-radius:3px;
    content:"Browse";
    line-height:24px;
    margin:3px;
    position:absolute;
    right:0;
    text-align:center;
    top:0;
    width:70px; }
    .bp3-file-upload-input::after:hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-file-upload-input:active::after{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-large .bp3-file-upload-input{
    font-size:16px;
    height:40px;
    line-height:40px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-height:30px;
      min-width:30px;
      line-height:30px;
      margin:5px;
      width:85px; }
  .bp3-dark .bp3-file-upload-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        background-color:#30404d;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        background-color:#202b33;
        background-image:none;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:active::after{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    color:#5c7080;
    font-size:12px;
    margin-top:5px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      line-height:40px;
      margin:0 10px 0 0; }
    .bp3-form-group.bp3-inline label.bp3-label{
      line-height:30px;
      margin:0 10px 0 0; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-input-left-container:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-input-left-container:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-height:24px;
    min-width:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-icon{
    z-index:1; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon{
    color:#5c7080; }
    .bp3-input-group > .bp3-input-left-container > .bp3-icon:empty,
    .bp3-input-group > .bp3-icon:empty{
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-height:30px;
    min-width:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle; }
  .bp3-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-input.bp3-large{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-bottom:15px;
  margin-top:0; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    font-weight:400;
    vertical-align:top;
    width:100%; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  min-height:0;
  padding:0;
  width:30px; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  -moz-appearance:none;
  -webkit-appearance:none;
  border-radius:3px;
  height:30px;
  padding:0 25px 0 10px;
  width:100%; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  background:none;
  -webkit-box-shadow:none;
          box-shadow:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    background:rgba(167, 182, 194, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026;
    text-decoration:none; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    background:rgba(115, 134, 148, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      color:rgba(167, 182, 194, 0.6);
      cursor:not-allowed; }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  font-size:16px;
  height:40px;
  padding-right:35px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    background-color:#202b33;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  background-color:rgba(206, 217, 224, 0.5);
  -webkit-box-shadow:none;
          box-shadow:none;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  color:#5c7080;
  pointer-events:none;
  position:absolute;
  right:7px;
  top:7px; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  letter-spacing:normal;
  position:relative;
  vertical-align:middle; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    right:12px;
    top:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select option:disabled, .bp3-dark
  .bp3-select option:disabled{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    text-align:left;
    vertical-align:top; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td,
  .bp3-running-text table tfoot tr:first-child th,
  table.bp3-html-table tfoot tr:first-child th,
  .bp3-running-text table tfoot tr:first-child td,
  table.bp3-html-table tfoot tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td,
  .bp3-dark .bp3-running-text table tfoot tr:first-child th,
  .bp3-running-text .bp3-dark table tfoot tr:first-child th,
  .bp3-dark table.bp3-html-table tfoot tr:first-child th,
  .bp3-dark .bp3-running-text table tfoot tr:first-child td,
  .bp3-running-text .bp3-dark table tfoot tr:first-child td,
  .bp3-dark table.bp3-html-table tfoot tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-bottom:6px;
  padding-top:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td,
table.bp3-html-table.bp3-html-table-bordered tfoot tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),
  table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table{ }
  .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
    background:rgba(92, 112, 128, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td,
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){
      -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
              box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
    background-color:rgba(92, 112, 128, 0.3);
    cursor:pointer; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
    background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  padding-bottom:0;
  top:40px; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-left:0;
  margin-right:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  font-family:"Icons20";
  font-size:inherit;
  font-style:normal;
  font-weight:400;
  line-height:1; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:""; }

.bp3-icon-arrow-bottom-right::before{
  content:""; }

.bp3-icon-arrow-down::before{
  content:""; }

.bp3-icon-arrow-left::before{
  content:""; }

.bp3-icon-arrow-right::before{
  content:""; }

.bp3-icon-arrow-top-left::before{
  content:""; }

.bp3-icon-arrow-top-right::before{
  content:""; }

.bp3-icon-arrow-up::before{
  content:""; }

.bp3-icon-arrows-horizontal::before{
  content:""; }

.bp3-icon-arrows-vertical::before{
  content:""; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:""; }

.bp3-icon-caret-left::before{
  content:""; }

.bp3-icon-caret-right::before{
  content:""; }

.bp3-icon-caret-up::before{
  content:""; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:""; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:""; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:""; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagnosis::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:""; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:""; }

.bp3-icon-eject::before{
  content:""; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:""; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:""; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:""; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:""; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:""; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:""; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-lab-test::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:""; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:""; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:""; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:""; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:""; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:""; }

.bp3-icon-star-empty::before{
  content:""; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:""; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:""; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:""; }

.bp3-icon-undo::before{
  content:""; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }
  .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{ }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  background:#ffffff;
  border-radius:3px;
  color:#182026;
  list-style:none;
  margin:0;
  min-width:180px;
  padding:5px;
  text-align:left; }

.bp3-menu-divider{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px; }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  color:inherit;
  line-height:20px;
  padding:5px 7px;
  text-decoration:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    color:#5c7080;
    margin-top:2px; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit !important;
    color:rgba(92, 112, 128, 0.6) !important;
    cursor:not-allowed !important;
    outline:none !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    font-size:16px;
    line-height:22px;
    padding:9px 7px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-right:10px;
      margin-top:1px; }

button.bp3-menu-item{
  background:none;
  border:none;
  text-align:left;
  width:100%; }
.bp3-menu-header{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px;
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    line-height:17px;
    margin:0;
    padding:10px 7px 0 1px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    font-size:18px;
    padding-bottom:5px;
    padding-top:15px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item{ }
  .bp3-dark .bp3-menu-item.bp3-intent-primary{
    color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-success{
    color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning{
    color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger{
    color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item::before,
  .bp3-dark .bp3-menu-item > .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item .bp3-menu-item-label{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
    background-color:rgba(138, 155, 168, 0.3); }
  .bp3-dark .bp3-menu-item.bp3-disabled{
    color:rgba(167, 182, 194, 0.6) !important; }
    .bp3-dark .bp3-menu-item.bp3-disabled::before,
    .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  background-color:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  height:50px;
  padding:0 15px;
  position:relative;
  width:100%;
  z-index:10; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    left:0;
    position:fixed;
    right:0;
    top:0; }

.bp3-navbar-heading{
  font-size:16px;
  margin-right:15px; }

.bp3-navbar-group{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px;
  margin:0 10px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:100%;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  text-align:center;
  width:100%; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  bottom:0;
  left:0;
  position:static;
  right:0;
  top:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    overflow:hidden;
    position:fixed; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    overflow:auto;
    position:fixed; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  bottom:0;
  left:0;
  position:fixed;
  right:0;
  top:0;
  opacity:1;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  z-index:20; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }
  .bp3-panel-stack-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-panel-stack2{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack2-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack2-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack2-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack2-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack2-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack2-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack2-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack2-view{
    background-color:#30404d; }
  .bp3-panel-stack2-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack2-push .bp3-panel-stack2-enter, .bp3-panel-stack2-push .bp3-panel-stack2-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack2-push .bp3-panel-stack2-enter-active, .bp3-panel-stack2-push .bp3-panel-stack2-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-push .bp3-panel-stack2-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack2-push .bp3-panel-stack2-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-pop .bp3-panel-stack2-enter, .bp3-panel-stack2-pop .bp3-panel-stack2-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack2-pop .bp3-panel-stack2-enter-active, .bp3-panel-stack2-pop .bp3-panel-stack2-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack2-pop .bp3-panel-stack2-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack2-pop .bp3-panel-stack2-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  border-radius:3px;
  display:inline-block;
  z-index:20; }
  .bp3-popover .bp3-popover-arrow{
    height:30px;
    position:absolute;
    width:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      height:20px;
      margin:5px;
      width:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-bottom:17px;
    margin-top:-17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-left:-17px;
    margin-right:17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover .bp3-popover-content{
    border-radius:3px;
    position:relative; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  border-radius:2px;
  content:"";
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg); }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  left:0;
  position:absolute;
  right:0;
  top:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  background:rgba(92, 112, 128, 0.2);
  border-radius:40px;
  display:block;
  height:8px;
  overflow:hidden;
  position:relative;
  width:100%; }
  .bp3-progress-bar .bp3-progress-meter{
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    border-radius:40px;
    height:100%;
    position:absolute;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:100%; }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  color:transparent !important;
  cursor:default;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  height:40px;
  min-width:150px;
  width:100%;
  cursor:default;
  outline:none;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    cursor:not-allowed;
    opacity:0.5; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  height:6px;
  left:0;
  right:0;
  top:5px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  height:16px;
  left:0;
  position:absolute;
  top:0;
  width:16px; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab;
    z-index:2; }
  .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    background:#bfccd6;
    -webkit-box-shadow:none;
            box-shadow:none;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    background:#5c7080;
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-slider-handle .bp3-slider-label{
    background:#394b59;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    color:#f5f8fa;
    margin-left:8px; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      background:#e1e8ed;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-bottom-right-radius:0;
    border-top-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    border-bottom-left-radius:0;
    border-top-left-radius:0;
    margin-left:8px; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  font-size:12px;
  line-height:1;
  padding:2px 5px;
  position:absolute;
  vertical-align:top; }

.bp3-slider.bp3-vertical{
  height:150px;
  min-width:40px;
  width:40px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    bottom:0;
    height:auto;
    left:5px;
    top:0;
    width:6px; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-left:0;
      margin-top:-8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      height:8px;
      margin-left:0;
      width:16px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-bottom-right-radius:3px;
      border-top-left-radius:0; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      border-bottom-left-radius:0;
      border-bottom-right-radius:0;
      border-top-left-radius:3px;
      margin-bottom:8px; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round;
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      padding:0 10px;
      width:100%; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        background-color:rgba(19, 124, 189, 0.2);
        -webkit-box-shadow:none;
                box-shadow:none; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      background-color:rgba(19, 124, 189, 0.2);
      border-radius:3px;
      bottom:0;
      height:auto;
      left:0;
      right:0;
      top:0; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  border:none;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  list-style:none;
  margin:0;
  padding:0;
  position:relative; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:#182026;
  cursor:pointer;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  font-size:14px;
  line-height:30px;
  max-width:100%;
  position:relative;
  vertical-align:top; }
  .bp3-tab a{
    color:inherit;
    display:block;
    text-decoration:none; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    background-color:transparent !important;
    -webkit-box-shadow:none !important;
            box-shadow:none !important; }
  .bp3-tab[aria-disabled="true"]{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    font-size:16px;
    line-height:40px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  left:0;
  pointer-events:none;
  position:absolute;
  top:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    background-color:#106ba3;
    bottom:0;
    height:3px;
    left:0;
    position:absolute;
    right:0; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#5c7080;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  color:#f5f8fa;
  font-size:12px;
  line-height:16px;
  max-width:100%;
  min-height:20px;
  min-width:20px;
  padding:2px 6px;
  position:relative; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-left:8px;
    padding-right:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    font-size:14px;
    line-height:20px;
    min-height:30px;
    min-width:30px;
    padding:5px 10px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-left:12px;
      padding-right:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  background:none;
  border:none;
  color:inherit;
  cursor:pointer;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin-bottom:-2px;
  margin-right:-6px !important;
  margin-top:-2px;
  opacity:0.5;
  padding:2px;
  padding-left:0; }
  .bp3-tag-remove:hover{
    background:none;
    opacity:0.8;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:0 5px 0 0; }
    .bp3-large .bp3-tag-remove:empty::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  line-height:inherit;
  min-height:30px;
  padding-left:5px;
  padding-right:0; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    color:#5c7080;
    margin-left:2px;
    margin-right:7px;
    margin-top:7px; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    margin-right:7px;
    margin-top:5px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:20px;
    width:80px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-left:5px;
      margin-top:10px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-height:30px;
      min-width:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:20px 0 0;
  max-width:500px;
  min-width:300px;
  pointer-events:all;
  position:relative !important; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-delay:50ms;
            transition-delay:50ms;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    color:#5c7080;
    margin:12px;
    margin-right:0; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    background-color:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  left:0;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none;
  right:0;
  z-index:40; }
  .bp3-toast-container.bp3-toast-container-in-portal{
    position:fixed; }
  .bp3-toast-container.bp3-toast-container-inline{
    position:absolute; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0; }
  .bp3-toast-container.bp3-toast-container-bottom{
    bottom:0;
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-exit-active ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    height:22px;
    position:absolute;
    width:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      height:14px;
      margin:4px;
      width:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-bottom:11px;
    margin-top:-11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-left:-11px;
    margin-right:11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  list-style:none;
  margin:0;
  padding-left:0; }

.bp3-tree-root{
  background-color:transparent;
  cursor:default;
  padding-left:0;
  position:relative; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:30px;
  padding-right:5px;
  width:100%; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  cursor:pointer;
  padding:7px;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  margin-right:7px;
  position:relative; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  left:calc(50% - 250px);
  top:20vh;
  width:500px;
  z-index:21; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar .bp3-input{
    background-color:transparent;
    border-radius:0; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    background-color:transparent;
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}
.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}
.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}
.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-border-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0px;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-warn-color0);
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px 5px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FileDialog-Checkbox {
  margin-top: 35px;
  display: flex;
  flex-direction: row;
  align-items: end;
  width: 100%;
}

.jp-FileDialog-Checkbox > label {
  flex: 1 1 auto;
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
  overflow-x: auto;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 50px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -50px; margin-right: -50px;
  padding-bottom: 50px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 50px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
  outline: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -50px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .remote-caret {
  position: relative;
  border-left: 2px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .remote-caret > div {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -2px;
  font-size: 0.95em;
  background-color: rgb(250, 129, 0);
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 3;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .remote-caret.hide-name > div {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .remote-caret:hover > div {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
  margin: 8px 12px 0px 12px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: flex-start;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0px;
  padding-right: 2px;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 40px;
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent {
  width: 72px;
  background: var(--jp-brand-color1);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent:focus-visible {
  background-color: var(--jp-brand-color0);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent
  .jp-icon3 {
  fill: white;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileBrowser-filterBox {
  padding: 0px;
  flex: 0 0 auto;
  margin: 8px 12px 0px 12px;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing:focus-visible {
  border: 1px solid var(--jp-brand-color1);
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon:before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

body[data-format='mobile'] .jp-OutputArea-child {
  flex-direction: column;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

body[data-format='mobile'] .jp-OutputPrompt {
  flex: 0 0 auto;
  text-align: left;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

body[data-format='mobile'] .jp-OutputArea-child .jp-OutputArea-output {
  margin-left: var(--jp-notebook-padding);
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
  overflow: hidden;
}

body[data-format='mobile'] .jp-InputArea {
  flex-direction: column;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
  overflow: hidden;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

body[data-format='mobile'] .jp-InputArea-editor {
  margin-left: var(--jp-notebook-padding);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

body[data-format='mobile'] .jp-InputPrompt {
  flex: 0 0 auto;
  text-align: left;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

.jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
}

.jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-collapseHeadingButton {
  display: none;
}

.jp-MarkdownCell:hover .jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  position: absolute;
  right: 0;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook-render * {
  contain: none !important;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
  float: left;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt:before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body div {
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

.highlight  {
  margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.CodeMirror pre {
  margin: 0;
  padding: 0;
}

/* Using table instead of flexbox so that we can use break-inside property */
/* CSS rules under this comment should not be required anymore after we move to the JupyterLab 4.0 CSS */


.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  min-width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-OutputArea-child {
  display: table;
  width: 100%;
}

.jp-OutputPrompt {
  display: table-cell;
  vertical-align: top;
  min-width: var(--jp-cell-prompt-width);
}

body[data-format='mobile'] .jp-OutputPrompt {
  display: table-row;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
}

body[data-format='mobile'] .jp-OutputArea-child .jp-OutputArea-output {
  display: table-row;
}

.jp-OutputArea-output.jp-OutputArea-executeResult {
  width: 100%;
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }

  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}
</style>

<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install torch numpy transformers datasets tiktoken wandb tqdm
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Requirement already satisfied: torch in /Users/cathyy/anaconda3/lib/python3.10/site-packages (2.0.1)
Requirement already satisfied: numpy in /Users/cathyy/anaconda3/lib/python3.10/site-packages (1.23.5)
Requirement already satisfied: transformers in /Users/cathyy/anaconda3/lib/python3.10/site-packages (4.24.0)
Requirement already satisfied: datasets in /Users/cathyy/anaconda3/lib/python3.10/site-packages (3.0.1)
Requirement already satisfied: tiktoken in /Users/cathyy/anaconda3/lib/python3.10/site-packages (0.7.0)
Requirement already satisfied: wandb in /Users/cathyy/anaconda3/lib/python3.10/site-packages (0.18.2)
Requirement already satisfied: tqdm in /Users/cathyy/anaconda3/lib/python3.10/site-packages (4.66.5)
Requirement already satisfied: filelock in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from torch) (3.9.0)
Requirement already satisfied: typing-extensions in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from torch) (4.4.0)
Requirement already satisfied: sympy in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from torch) (1.11.1)
Requirement already satisfied: networkx in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from torch) (2.8.4)
Requirement already satisfied: jinja2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from torch) (3.1.2)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.10.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from transformers) (0.25.1)
Requirement already satisfied: regex!=2019.12.17 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)
Requirement already satisfied: requests in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from transformers) (2.32.3)
Requirement already satisfied: packaging&gt;=20.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)
Requirement already satisfied: xxhash in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (3.5.0)
Requirement already satisfied: aiohttp in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (3.10.8)
Requirement already satisfied: pyarrow&gt;=15.0.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (17.0.0)
Requirement already satisfied: fsspec[http]&lt;=2024.6.1,&gt;=2023.1.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (2024.6.1)
Requirement already satisfied: pandas in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)
Requirement already satisfied: dill&lt;0.3.9,&gt;=0.3.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.8)
Requirement already satisfied: multiprocess in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.16)
Requirement already satisfied: docker-pycreds&gt;=0.4.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (0.4.0)
Requirement already satisfied: sentry-sdk&gt;=1.0.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (2.14.0)
Requirement already satisfied: psutil&gt;=5.0.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (5.9.0)
Requirement already satisfied: gitpython!=3.1.29,&gt;=1.0.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (3.1.43)
Requirement already satisfied: click!=8.0.0,&gt;=7.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (8.0.4)
Requirement already satisfied: platformdirs in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (2.5.2)
Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,&lt;6,&gt;=3.19.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (4.23.3)
Requirement already satisfied: setproctitle in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (1.3.3)
Requirement already satisfied: setuptools in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from wandb) (65.6.3)
Requirement already satisfied: six&gt;=1.4.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from docker-pycreds&gt;=0.4.0-&gt;wandb) (1.16.0)
Requirement already satisfied: attrs&gt;=17.3.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (22.1.0)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (1.3.1)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (1.4.1)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (4.0.3)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (6.1.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.12.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (1.13.1)
Requirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (2.4.2)
Requirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from gitpython!=3.1.29,&gt;=1.0.0-&gt;wandb) (4.0.11)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (1.26.14)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (2.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (2023.5.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jinja2-&gt;torch) (2.1.1)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pandas-&gt;datasets) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pandas-&gt;datasets) (2022.7)
Requirement already satisfied: mpmath&gt;=0.19 in /Users/cathyy/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy-&gt;torch) (1.2.1)
Requirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython!=3.1.29,&gt;=1.0.0-&gt;wandb) (5.0.1)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[117]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">nbconvert</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Requirement already satisfied: nbconvert in /Users/cathyy/anaconda3/lib/python3.10/site-packages (6.5.4)
Requirement already satisfied: tinycss2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (1.2.1)
Requirement already satisfied: jupyter-core&gt;=4.7 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (5.2.0)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (0.8.4)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (2.1.1)
Requirement already satisfied: traitlets&gt;=5.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (5.7.1)
Requirement already satisfied: jupyterlab-pygments in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (0.1.2)
Requirement already satisfied: defusedxml in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (0.7.1)
Requirement already satisfied: lxml in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (4.9.1)
Requirement already satisfied: nbformat&gt;=5.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (5.7.0)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (0.4)
Requirement already satisfied: nbclient&gt;=0.5.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (0.5.13)
Requirement already satisfied: pygments&gt;=2.4.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (2.11.2)
Requirement already satisfied: packaging in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (22.0)
Requirement already satisfied: beautifulsoup4 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (4.11.1)
Requirement already satisfied: jinja2&gt;=3.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (3.1.2)
Requirement already satisfied: bleach in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (4.1.0)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbconvert) (1.5.0)
Requirement already satisfied: platformdirs&gt;=2.5 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jupyter-core&gt;=4.7-&gt;nbconvert) (2.5.2)
Requirement already satisfied: nest-asyncio in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbclient&gt;=0.5.0-&gt;nbconvert) (1.5.6)
Requirement already satisfied: jupyter-client&gt;=6.1.5 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbclient&gt;=0.5.0-&gt;nbconvert) (7.3.4)
Requirement already satisfied: jsonschema&gt;=2.6 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbformat&gt;=5.1-&gt;nbconvert) (4.17.3)
Requirement already satisfied: fastjsonschema in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from nbformat&gt;=5.1-&gt;nbconvert) (2.16.2)
Requirement already satisfied: soupsieve&gt;1.2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from beautifulsoup4-&gt;nbconvert) (2.3.2.post1)
Requirement already satisfied: six&gt;=1.9.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from bleach-&gt;nbconvert) (1.16.0)
Requirement already satisfied: webencodings in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from bleach-&gt;nbconvert) (0.5.1)
Requirement already satisfied: attrs&gt;=17.4.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=5.1-&gt;nbconvert) (22.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=5.1-&gt;nbconvert) (0.18.0)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jupyter-client&gt;=6.1.5-&gt;nbclient&gt;=0.5.0-&gt;nbconvert) (2.8.2)
Requirement already satisfied: tornado&gt;=6.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jupyter-client&gt;=6.1.5-&gt;nbclient&gt;=0.5.0-&gt;nbconvert) (6.1)
Requirement already satisfied: pyzmq&gt;=23.0 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from jupyter-client&gt;=6.1.5-&gt;nbclient&gt;=0.5.0-&gt;nbconvert) (23.2.0)
Note: you may need to restart the kernel to use updated packages.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[118]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pyppeteer</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Collecting pyppeteer
  Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)
     <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">82.9/82.9 kB</span> <span class="ansi-red-fg">1.7 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>00:01
Requirement already satisfied: importlib-metadata&gt;=1.4 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pyppeteer) (4.11.3)
Collecting websockets&lt;11.0,&gt;=10.0
  Downloading websockets-10.4-cp310-cp310-macosx_11_0_arm64.whl (97 kB)
     <span class="ansi-black-intense-fg"></span> <span class="ansi-green-fg">97.9/97.9 kB</span> <span class="ansi-red-fg">7.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Requirement already satisfied: appdirs&lt;2.0.0,&gt;=1.4.3 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pyppeteer) (1.4.4)
Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.42.1 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pyppeteer) (4.66.5)
Collecting pyee&lt;12.0.0,&gt;=11.0.0
  Downloading pyee-11.1.1-py3-none-any.whl (15 kB)
Requirement already satisfied: certifi&gt;=2023 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pyppeteer) (2023.5.7)
Requirement already satisfied: urllib3&lt;2.0.0,&gt;=1.25.8 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pyppeteer) (1.26.14)
Requirement already satisfied: zipp&gt;=0.5 in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from importlib-metadata&gt;=1.4-&gt;pyppeteer) (3.11.0)
Requirement already satisfied: typing-extensions in /Users/cathyy/anaconda3/lib/python3.10/site-packages (from pyee&lt;12.0.0,&gt;=11.0.0-&gt;pyppeteer) (4.4.0)
Installing collected packages: websockets, pyee, pyppeteer
Successfully installed pyee-11.1.1 pyppeteer-2.0.0 websockets-10.4
Note: you may need to restart the kernel to use updated packages.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the directory to save the dataset</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">'data/shakespeare_char'</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Path to input file</span>
<span class="n">input_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'input.txt'</span><span class="p">)</span>

<span class="c1"># Download the tiny Shakespeare dataset if not already downloaded</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">):</span>
    <span class="n">data_url</span> <span class="o">=</span> <span class="s1">'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">data_url</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

<span class="c1"># Read the dataset</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Split into train and validation datasets</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mf">0.9</span><span class="p">)]</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mf">0.9</span><span class="p">):]</span>

<span class="c1"># Encode with tiktoken GPT-2 Byte Pair Encoding (BPE)</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"train has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"val has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>

<span class="c1"># Export to bin files</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>

<span class="c1"># Save train.bin and val.bin</span>
<span class="n">train_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">))</span>
<span class="n">val_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Data preparation complete!"</span><span class="p">)</span>


<span class="c1"># train.bin has 301,966 tokens</span>
<span class="c1"># val.bin has 36,059 tokens</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>train has 301,966 tokens
val has 36,059 tokens
Data preparation complete!
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>touch configurator.py
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train a miniature character-level shakespeare model</span>
<span class="c1"># good for debugging and playing on macbooks and such</span>

<span class="n">out_dir</span> <span class="o">=</span> <span class="s1">'out-shakespeare-char'</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">250</span> <span class="c1"># keep frequent because we'll overfit</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># don't print too too often</span>

<span class="c1"># we expect to overfit on this small dataset, so only save when val improves</span>
<span class="n">always_save_checkpoint</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">wandb_log</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># override via command line if you like</span>
<span class="n">wandb_project</span> <span class="o">=</span> <span class="s1">'shakespeare-char'</span>
<span class="n">wandb_run_name</span> <span class="o">=</span> <span class="s1">'mini-gpt'</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="s1">'shakespeare_char'</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># context of up to 256 previous characters</span>

<span class="c1"># baby GPT model :)</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># with baby networks can afford to go a bit higher</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># make equal to max_iters usually</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># learning_rate / 10 usually</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span> <span class="c1"># make a bit bigger because number of tokens per iter is small</span>

<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># not super necessary potentially</span>

<span class="c1"># on macbook also add</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cpu'</span>  <span class="c1"># run on cpu only</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># do not torch compile the model</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre><span class="ansi-blue-fg">__pycache__</span>     configurator.py hw1.ipynb       <span class="ansi-blue-fg">out</span>
bench.py        <span class="ansi-blue-fg">data</span>            model.py        sample.py
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">This training script can be run both on a single gpu in debug mode,</span>
<span class="sd">and also in a larger training run with distributed data parallel (ddp).</span>

<span class="sd">To run on a single GPU, example:</span>
<span class="sd">$ python train.py --batch_size=32 --compile=False</span>

<span class="sd">To run with DDP on 4 gpus on 1 node, example:</span>
<span class="sd">$ torchrun --standalone --nproc_per_node=4 train.py</span>

<span class="sd">To run with DDP on 4 gpus across 2 nodes, example:</span>
<span class="sd">- Run on the first (master) node with example IP 123.456.123.456:</span>
<span class="sd">$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py</span>
<span class="sd">- Run on the worker node:</span>
<span class="sd">$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py</span>
<span class="sd">(If your cluster does not have Infiniband interconnect prepend NCCL_IB_DISABLE=1)</span>
<span class="sd">"""</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">import</span> <span class="nn">configurator</span>  <span class="c1"># Import the configurator as a Python module</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">init_process_group</span><span class="p">,</span> <span class="n">destroy_process_group</span>

<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'mps'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Using MPS for training"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"MPS is not available. Falling back to CPU."</span><span class="p">)</span>
<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># default config values designed to train a gpt2 (124M) on OpenWebText</span>
<span class="c1"># I/O</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="s1">'out'</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">250</span> <span class="c1"># keep frequent because we'll overfit</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># don't print too too often</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">eval_only</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># if True, script exits right after the first eval</span>
<span class="n">always_save_checkpoint</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># if True, always save a checkpoint after each eval</span>
<span class="n">init_from</span> <span class="o">=</span> <span class="s1">'scratch'</span> <span class="c1"># 'scratch' or 'resume' or 'gpt2*'</span>
<span class="c1"># wandb logging</span>
<span class="n">wandb_log</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># disabled by default</span>
<span class="n">wandb_project</span> <span class="o">=</span> <span class="s1">'owt'</span>
<span class="n">wandb_run_name</span> <span class="o">=</span> <span class="s1">'gpt2'</span> <span class="c1"># 'run' + str(time.time())</span>
<span class="c1"># data</span>
<span class="c1">#dataset = 'openwebtext'</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s1">'shakespeare_char'</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">8</span> <span class="c1"># used to simulate larger batch sizes</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># if gradient_accumulation_steps &gt; 1, this is the micro-batch size</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># model</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># for pretraining 0 is good, for finetuning try 0.1+</span>
<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># do we use bias inside LayerNorm and Linear layers?</span>
<span class="c1"># adamw optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># max learning rate</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># total number of training iterations</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># clip gradients at this value, or disable if == 0.0</span>
<span class="c1"># learning rate decay settings</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># how many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># should be ~= max_iters per Chinchilla</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># minimum learning rate, should be ~= learning_rate/10 per Chinchilla</span>
<span class="c1"># DDP settings</span>
<span class="n">backend</span> <span class="o">=</span> <span class="s1">'nccl'</span> <span class="c1"># 'nccl', 'gloo', etc.</span>
<span class="c1"># system</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'mps'</span> <span class="c1"># examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s1">'bfloat16'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'float16'</span> <span class="c1"># 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># use PyTorch 2.0 to compile the model to be faster</span>
<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="n">config_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'_'</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">))]</span>
<span class="c1">#exec(open('configurator.py').read()) # overrides from command line or config file</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">globals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">config_keys</span><span class="p">}</span> <span class="c1"># will be useful for logging</span>
<span class="c1"># -----------------------------------------------------------------------------</span>

<span class="c1"># various inits, derived attributes, I/O setup</span>
<span class="n">ddp</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'RANK'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># is this a ddp run?</span>
<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">)</span>
    <span class="n">ddp_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'RANK'</span><span class="p">])</span>
    <span class="n">ddp_local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'LOCAL_RANK'</span><span class="p">])</span>
    <span class="n">ddp_world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'WORLD_SIZE'</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'cuda:</span><span class="si">{</span><span class="n">ddp_local_rank</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="n">ddp_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="c1"># this process will do logging, checkpointing etc.</span>
    <span class="n">seed_offset</span> <span class="o">=</span> <span class="n">ddp_rank</span> <span class="c1"># each process gets a different seed</span>
    <span class="c1"># world_size number of processes will be training simultaneously, so we can scale</span>
    <span class="c1"># down the desired gradient accumulation iterations per process proportionally</span>
    <span class="k">assert</span> <span class="n">gradient_accumulation_steps</span> <span class="o">%</span> <span class="n">ddp_world_size</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">gradient_accumulation_steps</span> <span class="o">//=</span> <span class="n">ddp_world_size</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># if not ddp, we are running on a single gpu, and one process</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">seed_offset</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ddp_world_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tokens_per_iter</span> <span class="o">=</span> <span class="n">gradient_accumulation_steps</span> <span class="o">*</span> <span class="n">ddp_world_size</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">block_size</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"tokens per iteration will be: </span><span class="si">{</span><span class="n">tokens_per_iter</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1337</span> <span class="o">+</span> <span class="n">seed_offset</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># allow tf32 on matmul</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># allow tf32 on cudnn</span>
<span class="n">device_type</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="s1">'cuda'</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">else</span> <span class="s1">'cpu'</span> <span class="c1"># for later use in torch.autocast</span>
<span class="c1"># note: float16 data type will automatically use a GradScaler</span>
<span class="n">ptdtype</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'float32'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">'bfloat16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="s1">'float16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">}[</span><span class="n">dtype</span><span class="p">]</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">'cpu'</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device_type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ptdtype</span><span class="p">)</span>

<span class="c1"># poor man's data loader</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">):</span>
    <span class="c1"># We recreate np.memmap every batch to avoid a memory leak, as per</span>
    <span class="c1"># https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122</span>
    <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">+</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">'cuda'</span><span class="p">:</span>
        <span class="c1"># pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="c1"># init these up here, can override if init_from='resume' (i.e. from a checkpoint)</span>
<span class="n">iter_num</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_val_loss</span> <span class="o">=</span> <span class="mf">1e9</span>

<span class="c1"># attempt to derive vocab_size from the dataset</span>
<span class="n">meta_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'meta.pkl'</span><span class="p">)</span>
<span class="n">meta_vocab_size</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">meta_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">meta_path</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">meta</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">meta_vocab_size</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"found vocab_size = </span><span class="si">{</span><span class="n">meta_vocab_size</span><span class="si">}</span><span class="s2"> (inside </span><span class="si">{</span><span class="n">meta_path</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="c1"># model init</span>
<span class="n">model_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span>
                  <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span> <span class="c1"># start with model_args from command line</span>
<span class="k">if</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'scratch'</span><span class="p">:</span>
    <span class="c1"># init a new model from scratch</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Initializing a new model from scratch"</span><span class="p">)</span>
    <span class="c1"># determine the vocab size we'll use for from-scratch training</span>
    <span class="k">if</span> <span class="n">meta_vocab_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)"</span><span class="p">)</span>
    <span class="n">model_args</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">meta_vocab_size</span> <span class="k">if</span> <span class="n">meta_vocab_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">50304</span>
    <span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="o">**</span><span class="n">model_args</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'resume'</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Resuming training from </span><span class="si">{</span><span class="n">out_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="c1"># resume training from a checkpoint.</span>
    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">'ckpt.pt'</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">checkpoint_model_args</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_args'</span><span class="p">]</span>
    <span class="c1"># force these config attributes to be equal otherwise we can't even resume training</span>
    <span class="c1"># the rest of the attributes (e.g. dropout) can stay as desired from command line</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'n_layer'</span><span class="p">,</span> <span class="s1">'n_head'</span><span class="p">,</span> <span class="s1">'n_embd'</span><span class="p">,</span> <span class="s1">'block_size'</span><span class="p">,</span> <span class="s1">'bias'</span><span class="p">,</span> <span class="s1">'vocab_size'</span><span class="p">]:</span>
        <span class="n">model_args</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">checkpoint_model_args</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="c1"># create the model</span>
    <span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="o">**</span><span class="n">model_args</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">]</span>
    <span class="c1"># fix the keys of the state dictionary :(</span>
    <span class="c1"># honestly no idea how checkpoints sometimes get this prefix, have to debug more</span>
    <span class="n">unwanted_prefix</span> <span class="o">=</span> <span class="s1">'_orig_mod.'</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">unwanted_prefix</span><span class="p">):</span>
            <span class="n">state_dict</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">unwanted_prefix</span><span class="p">):]]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="n">iter_num</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'iter_num'</span><span class="p">]</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'best_val_loss'</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">init_from</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'gpt2'</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initializing from OpenAI GPT-2 weights: </span><span class="si">{</span><span class="n">init_from</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="c1"># initialize from OpenAI GPT-2 weights</span>
    <span class="n">override_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">init_from</span><span class="p">,</span> <span class="n">override_args</span><span class="p">)</span>
    <span class="c1"># read off the created config params, so we can store them into checkpoint correctly</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'n_layer'</span><span class="p">,</span> <span class="s1">'n_head'</span><span class="p">,</span> <span class="s1">'n_embd'</span><span class="p">,</span> <span class="s1">'block_size'</span><span class="p">,</span> <span class="s1">'bias'</span><span class="p">,</span> <span class="s1">'vocab_size'</span><span class="p">]:</span>
        <span class="n">model_args</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="c1"># crop down the model block size if desired, using model surgery</span>
<span class="k">if</span> <span class="n">block_size</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">crop_block_size</span><span class="p">(</span><span class="n">block_size</span><span class="p">)</span>
    <span class="n">model_args</span><span class="p">[</span><span class="s1">'block_size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">block_size</span> <span class="c1"># so that the checkpoint will have the right value</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># initialize a GradScaler. If enabled=False scaler is a no-op</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="p">(</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">'float16'</span><span class="p">))</span>

<span class="c1"># optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">),</span> <span class="n">device_type</span><span class="p">)</span>
<span class="k">if</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'resume'</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizer'</span><span class="p">])</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># free up memory</span>

<span class="c1"># compile the model</span>
<span class="k">if</span> <span class="nb">compile</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"compiling the model... (takes a ~minute)"</span><span class="p">)</span>
    <span class="n">unoptimized_model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># requires PyTorch 2.0</span>

<span class="c1"># wrap model into DDP container</span>
<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">ddp_local_rank</span><span class="p">])</span>

<span class="c1"># helps estimate an arbitrarily accurate loss over either split using many batches</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">estimate_loss</span><span class="p">():</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">]:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="c1"># learning rate decay scheduler (cosine with warmup)</span>
<span class="k">def</span> <span class="nf">get_lr</span><span class="p">(</span><span class="n">it</span><span class="p">):</span>
    <span class="c1"># 1) linear warmup for warmup_iters steps</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">&lt;</span> <span class="n">warmup_iters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">it</span> <span class="o">/</span> <span class="n">warmup_iters</span>
    <span class="c1"># 2) if it &gt; lr_decay_iters, return min learning rate</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">&gt;</span> <span class="n">lr_decay_iters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">min_lr</span>
    <span class="c1"># 3) in between, use cosine decay down to min learning rate</span>
    <span class="n">decay_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">it</span> <span class="o">-</span> <span class="n">warmup_iters</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">lr_decay_iters</span> <span class="o">-</span> <span class="n">warmup_iters</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">decay_ratio</span> <span class="o">&lt;=</span> <span class="mi">1</span>
    <span class="n">coeff</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">decay_ratio</span><span class="p">))</span> <span class="c1"># coeff ranges 0..1</span>
    <span class="k">return</span> <span class="n">min_lr</span> <span class="o">+</span> <span class="n">coeff</span> <span class="o">*</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">-</span> <span class="n">min_lr</span><span class="p">)</span>

<span class="c1"># logging</span>
<span class="k">if</span> <span class="n">wandb_log</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">wandb</span>
    <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="n">wandb_project</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">wandb_run_name</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># training loop</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span> <span class="c1"># fetch the very first batch</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">local_iter_num</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># number of iterations in the lifetime of this process</span>
<span class="n">raw_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span> <span class="k">if</span> <span class="n">ddp</span> <span class="k">else</span> <span class="n">model</span> <span class="c1"># unwrap DDP container if needed</span>
<span class="n">running_mfu</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>

    <span class="c1"># determine and set the learning rate for this iteration</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">iter_num</span><span class="p">)</span> <span class="k">if</span> <span class="n">decay_lr</span> <span class="k">else</span> <span class="n">learning_rate</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">'lr'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="c1"># evaluate the loss on train/val sets and write checkpoints</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">wandb_log</span><span class="p">:</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s2">"iter"</span><span class="p">:</span> <span class="n">iter_num</span><span class="p">,</span>
                <span class="s2">"train/loss"</span><span class="p">:</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">],</span>
                <span class="s2">"val/loss"</span><span class="p">:</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">],</span>
                <span class="s2">"lr"</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
                <span class="s2">"mfu"</span><span class="p">:</span> <span class="n">running_mfu</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># convert to percentage</span>
            <span class="p">})</span>
        <span class="k">if</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span> <span class="ow">or</span> <span class="n">always_save_checkpoint</span><span class="p">:</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">iter_num</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">'model'</span><span class="p">:</span> <span class="n">raw_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">'optimizer'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">'model_args'</span><span class="p">:</span> <span class="n">model_args</span><span class="p">,</span>
                    <span class="s1">'iter_num'</span><span class="p">:</span> <span class="n">iter_num</span><span class="p">,</span>
                    <span class="s1">'best_val_loss'</span><span class="p">:</span> <span class="n">best_val_loss</span><span class="p">,</span>
                    <span class="s1">'config'</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"saving checkpoint to </span><span class="si">{</span><span class="n">out_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">'ckpt.pt'</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">eval_only</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># forward backward update, with optional gradient accumulation to simulate larger batch size</span>
    <span class="c1"># and using the GradScaler if data type is float16</span>
    <span class="k">for</span> <span class="n">micro_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
            <span class="c1"># in DDP training we only need to sync gradients at the last micro step.</span>
            <span class="c1"># the official way to do this is with model.no_sync() context manager, but</span>
            <span class="c1"># I really dislike that this bloats the code and forces us to repeat code</span>
            <span class="c1"># looking at the source of that context manager, it just toggles this variable</span>
            <span class="n">model</span><span class="o">.</span><span class="n">require_backward_grad_sync</span> <span class="o">=</span> <span class="p">(</span><span class="n">micro_step</span> <span class="o">==</span> <span class="n">gradient_accumulation_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">gradient_accumulation_steps</span> <span class="c1"># scale the loss to account for gradient accumulation</span>
        <span class="c1"># immediately async prefetch next batch while model is doing the forward pass on the GPU</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>
        <span class="c1"># backward pass, with gradient scaling if training in fp16</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># clip the gradient</span>
    <span class="k">if</span> <span class="n">grad_clip</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">grad_clip</span><span class="p">)</span>
    <span class="c1"># step the optimizer and scaler if training in fp16</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    <span class="c1"># flush the gradients as soon as we can, no need for this memory anymore</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># timing and logging</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">t1</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="c1"># get loss as float. note: this is a CPU-GPU sync point</span>
        <span class="c1"># scale up to undo the division above, approximating the true total loss (exact would have been a sum)</span>
        <span class="n">lossf</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">gradient_accumulation_steps</span>
        <span class="k">if</span> <span class="n">local_iter_num</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># let the training loop settle a bit</span>
            <span class="n">mfu</span> <span class="o">=</span> <span class="n">raw_model</span><span class="o">.</span><span class="n">estimate_mfu</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">gradient_accumulation_steps</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
            <span class="n">running_mfu</span> <span class="o">=</span> <span class="n">mfu</span> <span class="k">if</span> <span class="n">running_mfu</span> <span class="o">==</span> <span class="o">-</span><span class="mf">1.0</span> <span class="k">else</span> <span class="mf">0.9</span><span class="o">*</span><span class="n">running_mfu</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">mfu</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"iter </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: loss </span><span class="si">{</span><span class="n">lossf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, time </span><span class="si">{</span><span class="n">dt</span><span class="o">*</span><span class="mi">1000</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms, mfu </span><span class="si">{</span><span class="n">running_mfu</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="n">iter_num</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">local_iter_num</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># termination conditions</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">&gt;</span> <span class="n">max_iters</span><span class="p">:</span>
        <span class="k">break</span>

<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">destroy_process_group</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Using MPS for training
tokens per iteration will be: 30,720
Initializing a new model from scratch
defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)
number of parameters: 7.23M
num decayed parameter tensors: 18, with 7,233,536 parameters
num non-decayed parameter tensors: 9, with 1,152 parameters
using fused AdamW: False
compiling the model... (takes a ~minute)
step 0: train loss 10.8272, val loss 10.8203
iter 0: loss 10.8381, time 5056.43ms, mfu -100.00%
iter 10: loss 10.5130, time 5167.43ms, mfu 0.08%
iter 20: loss 10.1791, time 5314.52ms, mfu 0.08%
iter 30: loss 9.6569, time 5239.42ms, mfu 0.08%
iter 40: loss 8.9592, time 6412.27ms, mfu 0.08%
iter 50: loss 8.2670, time 6355.97ms, mfu 0.08%
iter 60: loss 7.4217, time 6426.43ms, mfu 0.08%
iter 70: loss 6.7772, time 6354.18ms, mfu 0.08%
iter 80: loss 6.3384, time 6347.76ms, mfu 0.08%
iter 90: loss 6.2520, time 6361.31ms, mfu 0.08%
iter 100: loss 6.1101, time 6368.35ms, mfu 0.07%
iter 110: loss 6.0081, time 6379.30ms, mfu 0.07%
iter 120: loss 5.4935, time 6458.28ms, mfu 0.07%
iter 130: loss 5.2394, time 6475.40ms, mfu 0.07%
iter 140: loss 5.0074, time 6433.29ms, mfu 0.07%
iter 150: loss 4.6577, time 6342.85ms, mfu 0.07%
iter 160: loss 4.7701, time 6355.60ms, mfu 0.07%
iter 170: loss 4.7432, time 6389.33ms, mfu 0.07%
iter 180: loss 4.7640, time 6379.44ms, mfu 0.07%
iter 190: loss 4.6977, time 6387.34ms, mfu 0.07%
iter 200: loss 4.3444, time 6393.61ms, mfu 0.07%
iter 210: loss 4.2701, time 6465.07ms, mfu 0.07%
iter 220: loss 4.4137, time 6402.08ms, mfu 0.07%
iter 230: loss 4.4545, time 6436.38ms, mfu 0.07%
iter 240: loss 4.4538, time 5291.39ms, mfu 0.07%
step 250: train loss 4.0900, val loss 4.8820
saving checkpoint to out
iter 250: loss 4.3373, time 7294.97ms, mfu 0.07%
iter 260: loss 3.9220, time 5322.67ms, mfu 0.07%
iter 270: loss 4.1287, time 5270.65ms, mfu 0.07%
iter 280: loss 4.0303, time 5321.56ms, mfu 0.07%
iter 290: loss 4.0584, time 5565.09ms, mfu 0.07%
iter 300: loss 4.0179, time 5866.88ms, mfu 0.07%
iter 310: loss 3.6910, time 5385.32ms, mfu 0.07%
iter 320: loss 3.6134, time 5714.82ms, mfu 0.07%
iter 330: loss 3.7034, time 5293.57ms, mfu 0.07%
iter 340: loss 3.5304, time 5439.78ms, mfu 0.08%
iter 350: loss 3.6297, time 5243.75ms, mfu 0.08%
iter 360: loss 3.6591, time 5257.04ms, mfu 0.08%
iter 370: loss 3.1429, time 5335.13ms, mfu 0.08%
iter 380: loss 3.7261, time 5268.08ms, mfu 0.08%
iter 390: loss 3.7555, time 5281.76ms, mfu 0.08%
iter 400: loss 3.5516, time 5380.83ms, mfu 0.08%
iter 410: loss 3.6773, time 5266.50ms, mfu 0.08%
iter 420: loss 3.4402, time 5581.04ms, mfu 0.08%
iter 430: loss 3.3433, time 5339.75ms, mfu 0.08%
iter 440: loss 3.0211, time 5281.15ms, mfu 0.08%
iter 450: loss 3.2746, time 5296.35ms, mfu 0.08%
iter 460: loss 3.5871, time 5309.66ms, mfu 0.08%
iter 470: loss 3.3737, time 5295.27ms, mfu 0.08%
iter 480: loss 2.8174, time 5352.94ms, mfu 0.08%
iter 490: loss 3.2363, time 5269.55ms, mfu 0.08%
step 500: train loss 3.2029, val loss 5.1094
iter 500: loss 3.2223, time 9208.28ms, mfu 0.08%
iter 510: loss 2.8968, time 6482.32ms, mfu 0.08%
iter 520: loss 2.9867, time 6411.49ms, mfu 0.07%
iter 530: loss 3.1556, time 6385.38ms, mfu 0.07%
iter 540: loss 3.2371, time 6418.16ms, mfu 0.07%
iter 550: loss 3.5019, time 6414.44ms, mfu 0.07%
iter 560: loss 3.3393, time 6430.07ms, mfu 0.07%
iter 570: loss 3.0979, time 7230.71ms, mfu 0.07%
iter 580: loss 3.2058, time 5260.45ms, mfu 0.07%
iter 590: loss 3.2652, time 5369.07ms, mfu 0.07%
iter 600: loss 3.0882, time 5156.86ms, mfu 0.07%
iter 610: loss 3.0384, time 5344.12ms, mfu 0.07%
iter 620: loss 2.7379, time 5344.43ms, mfu 0.08%
iter 630: loss 3.1362, time 5141.64ms, mfu 0.08%
iter 640: loss 2.5993, time 5290.90ms, mfu 0.08%
iter 650: loss 2.8653, time 5121.32ms, mfu 0.08%
iter 660: loss 2.7454, time 5139.05ms, mfu 0.08%
iter 670: loss 2.6377, time 5120.64ms, mfu 0.08%
iter 680: loss 2.9857, time 5224.71ms, mfu 0.08%
iter 690: loss 2.5737, time 5144.01ms, mfu 0.08%
iter 700: loss 2.6442, time 5109.02ms, mfu 0.08%
iter 710: loss 2.8344, time 5129.09ms, mfu 0.08%
iter 720: loss 2.6569, time 5222.91ms, mfu 0.08%
iter 730: loss 2.5624, time 5314.35ms, mfu 0.08%
iter 740: loss 2.5489, time 5121.33ms, mfu 0.08%
step 750: train loss 2.6546, val loss 5.7898
iter 750: loss 2.5928, time 6820.15ms, mfu 0.08%
iter 760: loss 2.6042, time 5140.29ms, mfu 0.08%
iter 770: loss 2.4728, time 5439.77ms, mfu 0.08%
iter 780: loss 2.5247, time 6036.04ms, mfu 0.08%
iter 790: loss 2.4532, time 5534.29ms, mfu 0.08%
iter 800: loss 2.5740, time 5820.50ms, mfu 0.08%
iter 810: loss 2.4426, time 5785.07ms, mfu 0.08%
iter 820: loss 2.3458, time 5477.59ms, mfu 0.08%
iter 830: loss 2.5454, time 5503.54ms, mfu 0.08%
iter 840: loss 2.3504, time 5572.06ms, mfu 0.08%
iter 850: loss 2.5109, time 5236.78ms, mfu 0.08%
iter 860: loss 2.3689, time 5358.89ms, mfu 0.08%
iter 870: loss 2.2603, time 5217.53ms, mfu 0.08%
iter 880: loss 2.3945, time 5202.89ms, mfu 0.08%
iter 890: loss 2.4103, time 5329.24ms, mfu 0.08%
iter 900: loss 2.3776, time 5262.23ms, mfu 0.08%
iter 910: loss 2.3730, time 5378.72ms, mfu 0.08%
iter 920: loss 2.4200, time 5239.38ms, mfu 0.08%
iter 930: loss 2.1459, time 5254.96ms, mfu 0.08%
iter 940: loss 2.3821, time 5339.52ms, mfu 0.08%
iter 950: loss 2.2758, time 6350.33ms, mfu 0.08%
iter 960: loss 2.3062, time 5646.08ms, mfu 0.08%
iter 970: loss 2.2706, time 5226.75ms, mfu 0.08%
iter 980: loss 2.1989, time 5295.23ms, mfu 0.08%
iter 990: loss 2.0917, time 6635.55ms, mfu 0.08%
step 1000: train loss 2.1397, val loss 6.2950
iter 1000: loss 2.3808, time 7029.58ms, mfu 0.08%
iter 1010: loss 1.8719, time 5492.96ms, mfu 0.08%
iter 1020: loss 2.1696, time 6350.03ms, mfu 0.08%
iter 1030: loss 2.1045, time 5586.60ms, mfu 0.08%
iter 1040: loss 2.2745, time 5186.34ms, mfu 0.08%
iter 1050: loss 2.1597, time 5336.15ms, mfu 0.08%
iter 1060: loss 2.1635, time 5276.13ms, mfu 0.08%
iter 1070: loss 1.9277, time 5564.94ms, mfu 0.08%
iter 1080: loss 2.1946, time 6059.27ms, mfu 0.08%
iter 1090: loss 1.9315, time 5843.72ms, mfu 0.08%
iter 1100: loss 1.7486, time 5345.79ms, mfu 0.08%
iter 1110: loss 2.0869, time 5241.78ms, mfu 0.08%
iter 1120: loss 2.2341, time 5171.52ms, mfu 0.08%
iter 1130: loss 1.9969, time 5259.72ms, mfu 0.08%
iter 1140: loss 2.1233, time 5286.05ms, mfu 0.08%
iter 1150: loss 1.8615, time 5441.12ms, mfu 0.08%
iter 1160: loss 2.0886, time 5181.45ms, mfu 0.08%
iter 1170: loss 2.0060, time 5384.40ms, mfu 0.08%
iter 1180: loss 1.9107, time 5492.32ms, mfu 0.08%
iter 1190: loss 1.8949, time 5163.69ms, mfu 0.08%
iter 1200: loss 1.8125, time 5183.79ms, mfu 0.08%
iter 1210: loss 1.9108, time 5350.84ms, mfu 0.08%
iter 1220: loss 1.8507, time 5188.32ms, mfu 0.08%
iter 1230: loss 1.8142, time 5427.56ms, mfu 0.08%
iter 1240: loss 1.9088, time 5199.18ms, mfu 0.08%
step 1250: train loss 1.8008, val loss 6.9380
iter 1250: loss 1.8686, time 10761.59ms, mfu 0.08%
iter 1260: loss 1.8643, time 5204.24ms, mfu 0.08%
iter 1270: loss 1.8510, time 5163.06ms, mfu 0.08%
iter 1280: loss 1.8000, time 5185.72ms, mfu 0.08%
iter 1290: loss 1.6633, time 5200.10ms, mfu 0.08%
iter 1300: loss 1.8923, time 5297.83ms, mfu 0.08%
iter 1310: loss 1.8369, time 5162.24ms, mfu 0.08%
iter 1320: loss 1.7290, time 5644.37ms, mfu 0.08%
iter 1330: loss 1.8480, time 5439.74ms, mfu 0.08%
iter 1340: loss 1.8714, time 6990.90ms, mfu 0.08%
iter 1350: loss 1.7711, time 5767.77ms, mfu 0.08%
iter 1360: loss 1.7461, time 5725.71ms, mfu 0.08%
iter 1370: loss 1.6983, time 5510.51ms, mfu 0.08%
iter 1380: loss 1.7556, time 5538.76ms, mfu 0.08%
iter 1390: loss 1.6209, time 5246.43ms, mfu 0.08%
iter 1400: loss 1.6159, time 5188.75ms, mfu 0.08%
iter 1410: loss 1.6656, time 5706.55ms, mfu 0.08%
iter 1420: loss 1.6204, time 5162.62ms, mfu 0.08%
iter 1430: loss 1.5701, time 5495.13ms, mfu 0.08%
iter 1440: loss 1.5628, time 5853.86ms, mfu 0.08%
iter 1450: loss 1.5491, time 5437.91ms, mfu 0.08%
iter 1460: loss 1.5931, time 5742.59ms, mfu 0.08%
iter 1470: loss 1.5734, time 5279.91ms, mfu 0.08%
iter 1480: loss 1.6634, time 5631.83ms, mfu 0.08%
iter 1490: loss 1.5849, time 5215.72ms, mfu 0.08%
step 1500: train loss 1.5781, val loss 7.1872
iter 1500: loss 1.7323, time 6983.83ms, mfu 0.08%
iter 1510: loss 1.6733, time 7404.56ms, mfu 0.07%
iter 1520: loss 1.4906, time 6829.56ms, mfu 0.07%
iter 1530: loss 1.5340, time 5232.68ms, mfu 0.07%
iter 1540: loss 1.5532, time 5396.18ms, mfu 0.08%
iter 1550: loss 1.4266, time 5477.49ms, mfu 0.08%
iter 1560: loss 1.5516, time 5616.75ms, mfu 0.08%
iter 1570: loss 1.3617, time 5208.28ms, mfu 0.08%
iter 1580: loss 1.4827, time 5277.19ms, mfu 0.08%
iter 1590: loss 1.4844, time 5178.04ms, mfu 0.08%
iter 1600: loss 1.7987, time 5227.72ms, mfu 0.08%
iter 1610: loss 1.6401, time 5331.16ms, mfu 0.08%
iter 1620: loss 1.3852, time 5201.75ms, mfu 0.08%
iter 1630: loss 1.4781, time 5422.35ms, mfu 0.08%
iter 1640: loss 1.3238, time 5356.45ms, mfu 0.08%
iter 1650: loss 1.3316, time 5645.21ms, mfu 0.08%
iter 1660: loss 1.4348, time 6401.16ms, mfu 0.08%
iter 1670: loss 1.5246, time 5353.96ms, mfu 0.08%
iter 1680: loss 1.2893, time 5178.33ms, mfu 0.08%
iter 1690: loss 1.6011, time 5508.87ms, mfu 0.08%
iter 1700: loss 1.5241, time 5257.44ms, mfu 0.08%
iter 1710: loss 1.4945, time 5156.91ms, mfu 0.08%
iter 1720: loss 1.4756, time 5122.11ms, mfu 0.08%
iter 1730: loss 1.4711, time 5839.21ms, mfu 0.08%
iter 1740: loss 1.2656, time 5245.64ms, mfu 0.08%
step 1750: train loss 1.4103, val loss 7.4561
iter 1750: loss 1.2972, time 7388.59ms, mfu 0.08%
iter 1760: loss 1.3261, time 5530.99ms, mfu 0.08%
iter 1770: loss 1.3016, time 5403.98ms, mfu 0.08%
iter 1780: loss 1.4683, time 5507.97ms, mfu 0.08%
iter 1790: loss 1.3994, time 5245.97ms, mfu 0.08%
iter 1800: loss 1.2767, time 5185.24ms, mfu 0.08%
iter 1810: loss 1.4873, time 5132.58ms, mfu 0.08%
iter 1820: loss 1.5761, time 5176.36ms, mfu 0.08%
iter 1830: loss 1.3188, time 5170.54ms, mfu 0.08%
iter 1840: loss 1.4132, time 5132.31ms, mfu 0.08%
iter 1850: loss 1.3222, time 5168.79ms, mfu 0.08%
iter 1860: loss 1.2322, time 5273.84ms, mfu 0.08%
iter 1870: loss 1.4058, time 5180.07ms, mfu 0.08%
iter 1880: loss 1.3794, time 5159.87ms, mfu 0.08%
iter 1890: loss 1.2778, time 5129.52ms, mfu 0.08%
iter 1900: loss 1.4142, time 5218.46ms, mfu 0.08%
iter 1910: loss 1.3837, time 5162.28ms, mfu 0.08%
iter 1920: loss 1.3138, time 5137.47ms, mfu 0.08%
iter 1930: loss 1.4355, time 5152.14ms, mfu 0.08%
iter 1940: loss 1.3566, time 5148.13ms, mfu 0.08%
iter 1950: loss 1.6037, time 5483.93ms, mfu 0.08%
iter 1960: loss 1.3802, time 5202.68ms, mfu 0.08%
iter 1970: loss 1.4658, time 5201.10ms, mfu 0.08%
iter 1980: loss 1.3241, time 5129.18ms, mfu 0.08%
iter 1990: loss 1.5097, time 5165.64ms, mfu 0.08%
step 2000: train loss 1.3155, val loss 7.4755
iter 2000: loss 1.2933, time 6969.60ms, mfu 0.08%
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd">Sample from a trained model</span>
<span class="sd">"""</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="n">init_from</span> <span class="o">=</span> <span class="s1">'resume'</span> <span class="c1"># either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="s1">'out'</span> <span class="c1"># ignored if init_from is not 'resume'</span>
<span class="n">start</span> <span class="o">=</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span> <span class="c1"># or "&lt;|endoftext|&gt;" or etc. Can also specify a file, use as: "FILE:prompt.txt"</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># number of samples to draw</span>
<span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">500</span> <span class="c1"># number of tokens generated in each sample</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="c1"># 1.0 = no change, &lt; 1.0 = less random, &gt; 1.0 = more random, in predictions</span>
<span class="n">top_k</span> <span class="o">=</span> <span class="mi">200</span> <span class="c1"># retain only the top_k most likely tokens, clamp others to have 0 probability</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">1337</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cpu'</span> <span class="c1"># examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s1">'bfloat16'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'float16'</span> <span class="c1"># 'float32' or 'bfloat16' or 'float16'</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># use PyTorch 2.0 to compile the model to be faster</span>
<span class="n">exec</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">'configurator.py'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span> <span class="c1"># overrides from command line or config file</span>
<span class="c1"># -----------------------------------------------------------------------------</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># allow tf32 on matmul</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># allow tf32 on cudnn</span>
<span class="n">device_type</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="s1">'cuda'</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">else</span> <span class="s1">'cpu'</span> <span class="c1"># for later use in torch.autocast</span>
<span class="n">ptdtype</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'float32'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">'bfloat16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="s1">'float16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">}[</span><span class="n">dtype</span><span class="p">]</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">'cpu'</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device_type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ptdtype</span><span class="p">)</span>

<span class="c1"># model</span>
<span class="k">if</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'resume'</span><span class="p">:</span>
    <span class="c1"># init from a model saved in a specific directory</span>
    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">'ckpt.pt'</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="o">**</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_args'</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">]</span>
    <span class="n">unwanted_prefix</span> <span class="o">=</span> <span class="s1">'_orig_mod.'</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">unwanted_prefix</span><span class="p">):</span>
            <span class="n">state_dict</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">unwanted_prefix</span><span class="p">):]]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">init_from</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'gpt2'</span><span class="p">):</span>
    <span class="c1"># init from a given GPT-2 model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">init_from</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">compile</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># requires PyTorch 2.0 (optional)</span>

<span class="c1"># look for the meta pickle in case it is available in the dataset folder</span>
<span class="n">load_meta</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'resume'</span> <span class="ow">and</span> <span class="s1">'config'</span> <span class="ow">in</span> <span class="n">checkpoint</span> <span class="ow">and</span> <span class="s1">'dataset'</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'config'</span><span class="p">]:</span> <span class="c1"># older checkpoints might not have these...</span>
    <span class="n">meta_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'config'</span><span class="p">][</span><span class="s1">'dataset'</span><span class="p">],</span> <span class="s1">'meta.pkl'</span><span class="p">)</span>
    <span class="n">load_meta</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">meta_path</span><span class="p">)</span>
<span class="k">if</span> <span class="n">load_meta</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Loading meta from </span><span class="si">{</span><span class="n">meta_path</span><span class="si">}</span><span class="s2">..."</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">meta_path</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">meta</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="c1"># TODO want to make this more general to arbitrary encoder/decoder schemes</span>
    <span class="n">stoi</span><span class="p">,</span> <span class="n">itos</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">'stoi'</span><span class="p">],</span> <span class="n">meta</span><span class="p">[</span><span class="s1">'itos'</span><span class="p">]</span>
    <span class="n">encode</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="p">[</span><span class="n">stoi</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>
    <span class="n">decode</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">itos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">l</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># ok let's assume gpt-2 encodings by default</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"No meta.pkl found, assuming GPT-2 encodings..."</span><span class="p">)</span>
    <span class="n">enc</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
    <span class="n">encode</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">allowed_special</span><span class="o">=</span><span class="p">{</span><span class="s2">"&lt;|endoftext|&gt;"</span><span class="p">})</span>
    <span class="n">decode</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="n">enc</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>

<span class="c1"># encode the beginning of the prompt</span>
<span class="k">if</span> <span class="n">start</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'FILE:'</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">start</span><span class="p">[</span><span class="mi">5</span><span class="p">:],</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">start_ids</span> <span class="o">=</span> <span class="n">encode</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">start_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>

<span class="c1"># run generation</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'---------------'</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Ignoring Jupyter/kernel argument: -f
Overriding config with /Users/cathyy/Library/Jupyter/runtime/kernel-bc4d9f82-decb-41b4-bff8-9fd19d6591e6.json:
{
  &#34;shell_port&#34;: 63271,
  &#34;iopub_port&#34;: 63272,
  &#34;stdin_port&#34;: 63273,
  &#34;control_port&#34;: 63275,
  &#34;hb_port&#34;: 63274,
  &#34;ip&#34;: &#34;127.0.0.1&#34;,
  &#34;key&#34;: &#34;6ac5486b-5f83a5b5ee9acfc25608504f&#34;,
  &#34;transport&#34;: &#34;tcp&#34;,
  &#34;signature_scheme&#34;: &#34;hmac-sha256&#34;,
  &#34;kernel_name&#34;: &#34;&#34;
}
number of parameters: 7.23M
No meta.pkl found, assuming GPT-2 encodings...

First Citizen:
Might to-day! O, come, to bring him
O, in the people was a little grave:
And make one unsembor of my place!
And thus have you have, and make it.


KING RICHARD III:
DUKE VINCENTIO:
When I am not in this is the Duke of love.

LADY OF YORK:
That didst thou shalt bring&#39;d your brother, and to make him.


ESCUTUS:
O, as I&#39;ll not?


KING RICHARD III:
What is not?


BRAKENBURYORK:
Upon your hands:
So I&#39;ll never must did, as we stand out it?


LEONTUTUS:
IUS:
What, you.

KING EDWARD IV:
Why, is a noble lord?


DUKE OF YORK:
I have the love, go, pardon to her.


LADY:
Ala-umerle with your grace, with him, for he must the court?


MERCAMILLWICK:
When, and in one, it is some think it is him.


Lord: let&#39;stst.

She&#39;s go with my lord.


CORIOLANUS:
Nurse:
And they me, a word, and I&#39;ll not.

LEONTESTER:
Ay, I seem to the king, for either,
Whose this we may be thus have;
What art thou thou had need with the death.


You have stay not content not my lord,
My lord: &#39;tis a part of your other,
As if thou hast not go, my brothers, Camillo,
Nurse:
Made of my sovereign, and cannot be give leave,
And to the words to help it were it not our name;
And shall not a very son but all the maid,
And, I must be bear thee.

GARETESS OF AUMNay, my lord,
I am near here and here,
When I am we are not in the king, that fall into the matter
Have you, to us for full of it be great arms.


NORTH
---------------

MIONLEORD:
BUCKINGHAM:
No, to tell you to death, sir, so.
And go with me not most to our king!

MERCALUS:
Most wisely both have with their own.


ELO:
IUS:
How would not yield, here,
The doth say, but by thyself to London, the very lord,
O, as a holy at what that
But now to make a guest
HAR LAURENCE:
Whose shame too much his deeds to me, and,
I would be but much to-twas, and myself to the breath,
And he should have you have.

Second Citizen:
O, will but his hands, that&#39;s that my lord,
Have been: the house of her all the world!


She has, it, we did dead; and all the end him be alone:

While he hath rather,--
My lord, goodly, what which&#39;s dead men if I will say,
Of this we&#39;ll be untime had this?


CORIUS:
O, what your name&#39;s good:
Say, a mighty lord.

LEONTES:
I&#39;ll do my good:
I will not bring me to,
To make us to&#39;t my loving.

ROMEO:
If King of my lord, therefore
The end.

O, thou be not still his brother&#39;s death,
O, see the ear;
But the Duke with the world&#39;s child of our heart!

3 KING HENRY VI:

That&#39;s&#39;s, I were they did.


Second Citizen:
Go, you shall I have deserved with this is day;
For that I&#39;ll be well to the manner for you.

First Citizen:
The senate-hearted will heard the house of a a man, to live that
As I will I&#39;ll not from the king to be patient!

CORIOLANUS:
The world. They wear the beggar
But thou would be gone, then might yet,

Ay, my queen, I would
Will&#39;t say thou have your liege to the grave--We&#39;ll weep.

ANGELO:
The king is not all.

KING RICHARD III
---------------

Who would not hear,
And, you say he must be be on you,
The shame in his general to make the night,
Even to his life, and his friend; and my country&#39;s dead!

Provost:
GLOUCESTER:
What&#39;sUS:
The a good gentleman, you cannot find how they come,
Thou want&#39;s by death.


ISABETH: I meet me, in the rest. Go not,

MENENIUS:
What I will have you speak before that&#39;t.


Y:
She&#39;s the most that he comes: I must be a husband.


WARWICK:
It is we do, but come; what it more doth hear you then,
For that you shall say, sir, sir:
Which I, then I understand us,
To make your poor George, my lord:
And when he take my lord.


DUCHESS OF YORK:
Why, look her&#39;s to thy a little for I say.


DUKE VINCENTIO:
He he?

NORTHUMNay:
KING HENVOLIO:
You are a wilt thou hast be the be more than the Duke of his soul:

That IUS:
I&#39;Twas, is the fair good in your own.


AUTOLANUS:
And, I have think that they are done!

BRUTIO:
There, they will be so he was
Come, no more; by the people is again.


LEONTES:
I have but be show at another!
BRUTIO:

Go hither, and my son and, get a friend, she,
And I am a fawn&#39;s the Tower.

We are the heavens till he&#39;st, and by your people I&#39;ll put to my heart.


LEONTES:
KING EDWARD IV:
May not, or I did you will stand her,--
This is a noble lord, if you
You will tell you; for your own, and his grace;
Now, I have done their grace thy noble news;
And that&#39;s in the grace.

RUKE VINCENTIO:
If his lord, you be not
With yourself
---------------

Where is but for his spirit&#39;s own tears?
The father is a crown, do you,
Under those that we are in my lord.

ELO:
CUTIA:
That is&#39;t, hear a little brother lives.


BUCKINGBRUTIO:
I will I think his true.


LADYORK:
I will not so you see of I, what well, he hath been so!


GLOUCESTER:

I will I should to himself, and will not not be on, by any.


SICINIET:
This is my lord.

HENRY BOLANUS:
DUKEer.


KING RICHARD III:
O, then, sir, you that so.


YORK:
HASTINGS:
To make you have not will.

Came, we would tell her dead.


PERDITA:
My lord; should you were so? some,

What is you, I know thy lord! now, sir?


GLOUCESTER:
Whose fair good. Lett thou I fear of good son?

Third Citizen:
Are you have be thou you, then, and Warwick shall tell you fear, and I know the--anus

Second Murderer:
The prince, you, to the people, and with the queen to the body in the?


GLOUCESTER:
The which with you shall go, I will come.



WARWICK:
Why have a lamb of the first, I may be an hour of your?


MENENRY VI
But I do you, to my lord;
No, I have made your mother.


Y CAPULET:
We must! he&#39;s by the Tower man.


BOWI&#39;ll tell me.

TYLUCIO: and no, I am a crown?


Faith, that knows what?

LADYORK:
I&#39;ll help.

ANTIGONUS:
I do you well:
The gods, let me in every man, not come,
The state, be gone. Your news
With all the king I all the general?


---------------



If not so I,
I have been
How a sovereign.

LUCIO:
If I may never in the crown.

LEONTES:
IET:
What shall be a man; love, and my lord, if this?


KING RICHARD III:
Who, I say, sir; and to be be done what leave of Clarence!


I&#39;ll come me and to all the world is not so,
To know you have it before my lord?

MENILLO:
Now, sir:
Against the king, I must you to my lord, as not,
Which are a man that we&#39;ll put himself was,
Three; this that the right of you give me.

Pray you hold the Duke of your man.

SICINIUS:
Ay, they that I am.


AUTOLHAM:
Will but that most most the people.

KING RICHARD II:
DUKE:
To speak:&#39;t to your hearts and I have dead.


FLORIZABETH:
First Gentleman:
By the man! I may be this&#39;s day?


KING EDWARD:
KING RICHARDONTESCALUS:
HEN MARGARENCE:
A boy, my father&#39;s the most brother&#39;s honour,
But he cannot speak, like the sight of a brother&#39;st, yet I
Would thought them is our duty to to his wife,
That, and it, and here from his own time
What&#39;s the heart to be be slain
And stay, sir, my brother.

ROMEO:
That we&#39;ll fly thee, that is the heart.


GLOUCAMILLO,
IUS:
I&#39;ll tell you here, &#39;tis it,
LE:
Hath with words; and not be a pair of your love.

BUCKINGHAM:
I do you, this more to quilt thou told me, we hear you
But
Tis have all those he could be deliver,
And thou be best.

MENENIUS:
O, yet my sweet fellow.


KING RICHARD III:
I shall thou be a:
Is not the banishment, speak?

DU
---------------

Nay,, a man, we look on my lord,
I have it to speak to thy death,
The old which we that I have made me,
&#39;Till no be so to be
For mine honour of his great night, and I have well-morrow!


CAMILLO:
O:
Who should say the king
Then our sweet, farewell.


QUEEN MARGARET:
Lord:
O, I will I love, as I shall forget a mother,
The new-hearted man that was?

DUCHIO:
KING RICHARD III:
O, I, I have, my lord, ay, I speak;
To thy lord; I&#39;ll, my sister&#39;s his good.

Would have no your wife, get it, be we&#39;ll live?

Was he must have a thing to speak to the better-is he I shall make it.


O, as I bid him I do I speak.

KING RICHARD III:
Or, hare is one makes us with my lord.


ROMEO:
That he shall not do you are or my friends.


QUEENRY BOLANUS:
I thank me, you.


DUKE OF AUMERNIA:
Sirrah, if thou so done, I&#39;ll see my father,
This is some, my lord, and, and what he to make me all the king,
In arms.

MENEN MARGAR LAURENCE:
It might be with your good that that he was as not here?


So, by thy mother did not of a unlike grief of the state,
And now; your company.

LEONTES:
CES:
Nay, if my lord.


BUCKINGHAM:
OKE OF YORKIO:
To be shall be well:
Ay, gentle gracious lord, my lord, ha:
When thou have been in the sweet:
Which give me, and both to do not in the duke.

BUCKINGBRUTUS:
But I was a other-morrow, and here, his majesty.


GREMIO:
The Lord:
I&#39;ll take there must do I be take it
---------------


AUTOLANIO:
OKE OF YORK:
Is is a son, I have been with all
If you will have made thee:
And I, and I bear your own.

CUTIO:
I have this is thy rest
a-day, have lived.


Come, this, I will live my lord,
In my heart, if the people
You muststst thou then to the king,--

Se, I&#39;ll break the blood
And not call&#39;d well, my lord, you.

First Murderer:
She&#39;s yourenius, I was not not so,
To be so?

SLY:
O, get you have you&#39;ll find a greater:
To help that I have you, a tunes, as I am,
How I do you have more,
For you will be many things as I had a man to take good

Stand out of you are not not; if you, let&#39;d how you will let that make my name.


AUTOLANUS:
O I did will be their leave to my lord.


Second Citizen:
Hath my mother, in these all in this?


PRINIUS:
We bid out&#39;d the rest; and made, she be most shame in death.


KING RICHARD III:
YORK:
I will the queen?

DUKE VINCENTIO:
Why, till what fear, let my father!

LORD:
God not the king is not the doth&#39;t have been &#39;I do me,
To save as I&#39;ll make the general.

First Keeper:
Hark I do; shall; I bear,
How said, I can call their blood
This nurse, I have so; I know the Lady is all.

LUCIO:
A good sir; have yours is, sir?

MENENI speak.

IOLANUS:
ThTHUMBERLAND:
And have I&#39;ll call to two his life
And bear thee, so well canst thou live I have a sight.


DUKE VINCENTIO:
Are I.

Second Gentleman:
A pair of all all his life, for my father,
He is no,
---------------


CUTUS:
I can,
GLOUC with all her,

HERMarry, sir:
Both he be well:
GLOUCESTER:
See you may the tribunes:
I will not I know our good:
And for your face to have not the house of the sea,
And she is have a true, but or never do
For you are no more with a horse!

YORK:
But, your love is I know thy voices, sir!

LADY:
O: thy right is to, that I cry you.

BRUTIO:
O, and my dead?


Hath your mean to me, then, sir, good you do it,
But take to make not be for you have not so.


LEONTES:
I am by the same I speak,
Would you shall be
But I&#39;ll do you shalt be be gone?


AUFarewell, not the king.


JULIET:
O noble lords,
Thou can her sweet news.


WARWICK:
He may do you, be a gert we have been with this is her?
 Thouillo, my lord!

Thou rather, when, I have been a wail not I&#39;ll be
With this honour&#39;st, I mayst, then.

COMINILEY:
What shall you were, what aught all the world.

DUKE OF YORK:
Come, and by these the king may be fair and the name of Lancaster.

PAULINA:
And is my lord?

QUEENRY BOLYCUS:
I would you, my lord
We were not not think it.


Second Watchman:
My lord, sir,
Yes, indeed; that is for I would is I we hear me?


Second Citizen:
And stay, you will be one; and I haveCALOLYCUS:
Shall be a little, he is this may not
And then not in the thing when it were the mense!

This is all, I call me to you do you forswose death,
Give us to my lord; for your honour;
The execution so a poor Richard&#39;s
---------------

The little-dropping fain, by the news.

AUTOLANUS:
And be liege!


TRANUS:
GLOUCESTER:
Are you shall make your uncle I:
My lord, if I must not her father&#39;s good
And&#39;t you shall not were a good face&#39;s to be be so?


LADY:
My lie! I do you, come by good all:

More. I know,

STANIO:
Why, that there, thus, now?


DUKE VINCENTIO:
As you are thy father&#39;s the king&#39;s is no your death.


ISABELLA:
What, and I the king is no more, and I am too great while

Than you saw thee to speak.

POLIXEN MARGARET:
When he to this is a good George&#39;s
And be by the king and make him.

PAULIET:
LARTIET:
HENRY BOLANUS:
And you have all my noble lord.


DONE:
RICHARD:
CUTUS:
O in mine I will have I woe;
I cannot to put on you much.


KING HENRY BOLANUS:

E:
No? I would never not be, that &#39;tis so.


ISABELLA:
DUCHESS OF YORK:
I can not speak a woman is not the blood
Were--lains the more with a kind of patience,

But, as a man, if mine is a wise
His ancient and what&#39;s see him, thy best.

KING HENRY VI:
We have not, I do beseech thee, what lies the king!

CLIFFORD:
Away, I&#39;ll come.

ROMEO:
A:
I could have not be married in an it.

DUKE OF YORK:

Come, be I have more, I guess.

ROMEO:
He is a boy.

HERMIONE:
Therefore, nor I, sir, sir, and you but I do us leave,

Thy! you are him at a a man was the a
---------------

Than Edward&#39;s his love up,
not seen your most master!

BUCKINGBRUTUS:
Then, I have well.

ROMEO:
Ay, that&#39;s:
Why, I&#39;ll be seen in my wife.

AUFarewell?


SICINIUS:
And so, too here, ladies of this o&#39;er it are the duke before this.


RICHARD III:
And give of my good lord; let&#39;s the rest?

WARWATER:
BENI would you, we know the maid.

Y: I&#39;ll heard on my death;

No,&#39; the father&#39;st thou well.

JULIET:
IUS:
Firstose young, your will meet thy mother, be:
But we have a tak; I: we in my lord;
Here! yet that now and fain in my lords!


KING EDWARD:
KING HENI shall be not their brother&#39;s, I had heard not,
Should be myself: and had in her but done with thee?


DUKE OF YORK:
BRAY: I bring me!

PAULINA:
When you, come to the son at my head,
Your lord, that is my dear comfort,

We love, being a gentle word for her wife, if ever,
And, go; my lord, if you see

are a king and help,
Let, take your part to speak never have on,
you could be in arms is this your love between.


ISABELLA:
Servant:
Come, sir, sir, to, and they were to be a:
But I take me, I am I, let them with Lancaster.

WARWICK: by my brother&#39;s day,
Thou ne&#39;ld then, I am I&#39;ll be it should be a most noble of my
Their grace are, then love, so.

CAMILLO:
Alack.

JOHN OF GAUNT:
CLIFFORD:
Say, you, and that I can be my brother.


GLOUCESTER:
I do not not,
See he was as all so but, by my woman.



---------------
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#hyperparameterExperimentation. Modify the number of layers and heads of the previous training model</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">import</span> <span class="nn">configurator</span>  <span class="c1"># Import the configurator as a Python module</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">init_process_group</span><span class="p">,</span> <span class="n">destroy_process_group</span>

<span class="kn">import</span> <span class="nn">torch._dynamo</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">suppress_errors</span> <span class="o">=</span> <span class="kc">True</span>


<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>

<span class="n">min_loss_val</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span><span class="c1"># Set initial min_loss to a large value</span>
<span class="n">min_loss_train</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>
<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># default config values designed to train a gpt2 (124M) on OpenWebText</span>
<span class="c1"># I/O</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="s1">'out'</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">250</span> <span class="c1"># keep frequent because we'll overfit</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">eval_only</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># if True, script exits right after the first eval</span>
<span class="n">always_save_checkpoint</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1">#f True, always save a checkpoint after each eval</span>
<span class="n">init_from</span> <span class="o">=</span> <span class="s1">'scratch'</span> <span class="c1"># 'scratch' or 'resume' or 'gpt2*'</span>
<span class="c1"># wandb logging</span>
<span class="n">wandb_log</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># disabled by default</span>
<span class="n">wandb_project</span> <span class="o">=</span> <span class="s1">'owt'</span>
<span class="n">wandb_run_name</span> <span class="o">=</span> <span class="s1">'gpt2'</span> <span class="c1"># 'run' + str(time.time())</span>
<span class="c1"># data</span>
<span class="c1">#dataset = 'openwebtext'</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s1">'shakespeare_char'</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">8</span> <span class="c1"># used to simulate larger batch sizes</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># if gradient_accumulation_steps &gt; 1, this is the micro-batch size</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># model</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># for pretraining 0 is good, for finetuning try 0.1+</span>
<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># do we use bias inside LayerNorm and Linear layers?</span>
<span class="c1"># adamw optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># max learning rate</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span><span class="c1"># total number of training iterations</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># clip gradients at this value, or disable if == 0.0</span>
<span class="c1"># learning rate decay settings</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># how many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1">#hould be ~= max_iters per Chinchilla</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># minimum learning rate, should be ~= learning_rate/10 per Chinchilla</span>
<span class="c1"># DDP settings</span>
<span class="n">backend</span> <span class="o">=</span> <span class="s1">'nccl'</span> <span class="c1"># 'nccl', 'gloo', etc.</span>
<span class="c1"># system</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'mps'</span>      <span class="c1">#'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s1">'bfloat16'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'float16'</span> <span class="c1"># 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># use PyTorch 2.0 to compile the model to be faster</span>
<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="n">config_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'_'</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">))]</span>
<span class="c1">#exec(open('configurator.py').read()) # overrides from command line or config file</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">globals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">config_keys</span><span class="p">}</span> <span class="c1"># will be useful for logging</span>
<span class="c1"># -----------------------------------------------------------------------------</span>

<span class="c1"># various inits, derived attributes, I/O setup</span>
<span class="n">ddp</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'RANK'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># is this a ddp run?</span>
<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">)</span>
    <span class="n">ddp_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'RANK'</span><span class="p">])</span>
    <span class="n">ddp_local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'LOCAL_RANK'</span><span class="p">])</span>
    <span class="n">ddp_world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'WORLD_SIZE'</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'cuda:</span><span class="si">{</span><span class="n">ddp_local_rank</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="n">ddp_rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="c1"># this process will do logging, checkpointing etc.</span>
    <span class="n">seed_offset</span> <span class="o">=</span> <span class="n">ddp_rank</span> <span class="c1"># each process gets a different seed</span>
    <span class="c1"># world_size number of processes will be training simultaneously, so we can scale</span>
    <span class="c1"># down the desired gradient accumulation iterations per process proportionally</span>
    <span class="k">assert</span> <span class="n">gradient_accumulation_steps</span> <span class="o">%</span> <span class="n">ddp_world_size</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">gradient_accumulation_steps</span> <span class="o">//=</span> <span class="n">ddp_world_size</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># if not ddp, we are running on a single gpu, and one process</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">seed_offset</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ddp_world_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tokens_per_iter</span> <span class="o">=</span> <span class="n">gradient_accumulation_steps</span> <span class="o">*</span> <span class="n">ddp_world_size</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">block_size</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"tokens per iteration will be: </span><span class="si">{</span><span class="n">tokens_per_iter</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1337</span> <span class="o">+</span> <span class="n">seed_offset</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># allow tf32 on matmul</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># allow tf32 on cudnn</span>
<span class="n">device_type</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="s1">'cuda'</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">else</span> <span class="s1">'cpu'</span> <span class="c1"># for later use in torch.autocast</span>
<span class="c1"># note: float16 data type will automatically use a GradScaler</span>
<span class="n">ptdtype</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'float32'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">'bfloat16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="s1">'float16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">}[</span><span class="n">dtype</span><span class="p">]</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">'cpu'</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device_type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ptdtype</span><span class="p">)</span>

<span class="c1"># poor man's data loader</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">):</span>
    <span class="c1"># We recreate np.memmap every batch to avoid a memory leak, as per</span>
    <span class="c1"># https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122</span>
    <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">+</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">'cuda'</span><span class="p">:</span>
        <span class="c1"># pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="c1"># init these up here, can override if init_from='resume' (i.e. from a checkpoint)</span>
<span class="n">iter_num</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_val_loss</span> <span class="o">=</span> <span class="mf">1e9</span>

<span class="c1"># attempt to derive vocab_size from the dataset</span>
<span class="n">meta_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'meta.pkl'</span><span class="p">)</span>
<span class="n">meta_vocab_size</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">meta_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">meta_path</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">meta</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">meta_vocab_size</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"found vocab_size = </span><span class="si">{</span><span class="n">meta_vocab_size</span><span class="si">}</span><span class="s2"> (inside </span><span class="si">{</span><span class="n">meta_path</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="c1"># model init</span>
<span class="n">model_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span>
                  <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span> <span class="c1"># start with model_args from command line</span>
<span class="k">if</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'scratch'</span><span class="p">:</span>
    <span class="c1"># init a new model from scratch</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Initializing a new model from scratch"</span><span class="p">)</span>
    <span class="c1"># determine the vocab size we'll use for from-scratch training</span>
    <span class="k">if</span> <span class="n">meta_vocab_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)"</span><span class="p">)</span>
    <span class="n">model_args</span><span class="p">[</span><span class="s1">'vocab_size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">meta_vocab_size</span> <span class="k">if</span> <span class="n">meta_vocab_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">50304</span>
    <span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="o">**</span><span class="n">model_args</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'resume'</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Resuming training from </span><span class="si">{</span><span class="n">out_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="c1"># resume training from a checkpoint.</span>
    <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">'ckpt.pt'</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">checkpoint_model_args</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_args'</span><span class="p">]</span>
    <span class="c1"># force these config attributes to be equal otherwise we can't even resume training</span>
    <span class="c1"># the rest of the attributes (e.g. dropout) can stay as desired from command line</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'n_layer'</span><span class="p">,</span> <span class="s1">'n_head'</span><span class="p">,</span> <span class="s1">'n_embd'</span><span class="p">,</span> <span class="s1">'block_size'</span><span class="p">,</span> <span class="s1">'bias'</span><span class="p">,</span> <span class="s1">'vocab_size'</span><span class="p">]:</span>
        <span class="n">model_args</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">checkpoint_model_args</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="c1"># create the model</span>
    <span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="o">**</span><span class="n">model_args</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">]</span>
    <span class="c1"># fix the keys of the state dictionary :(</span>
    <span class="c1"># honestly no idea how checkpoints sometimes get this prefix, have to debug more</span>
    <span class="n">unwanted_prefix</span> <span class="o">=</span> <span class="s1">'_orig_mod.'</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">unwanted_prefix</span><span class="p">):</span>
            <span class="n">state_dict</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">unwanted_prefix</span><span class="p">):]]</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="n">iter_num</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'iter_num'</span><span class="p">]</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'best_val_loss'</span><span class="p">]</span>
<span class="k">elif</span> <span class="n">init_from</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'gpt2'</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Initializing from OpenAI GPT-2 weights: </span><span class="si">{</span><span class="n">init_from</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="c1"># initialize from OpenAI GPT-2 weights</span>
    <span class="n">override_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">init_from</span><span class="p">,</span> <span class="n">override_args</span><span class="p">)</span>
    <span class="c1"># read off the created config params, so we can store them into checkpoint correctly</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'n_layer'</span><span class="p">,</span> <span class="s1">'n_head'</span><span class="p">,</span> <span class="s1">'n_embd'</span><span class="p">,</span> <span class="s1">'block_size'</span><span class="p">,</span> <span class="s1">'bias'</span><span class="p">,</span> <span class="s1">'vocab_size'</span><span class="p">]:</span>
        <span class="n">model_args</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="c1"># crop down the model block size if desired, using model surgery</span>
<span class="k">if</span> <span class="n">block_size</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_size</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">crop_block_size</span><span class="p">(</span><span class="n">block_size</span><span class="p">)</span>
    <span class="n">model_args</span><span class="p">[</span><span class="s1">'block_size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">block_size</span> <span class="c1"># so that the checkpoint will have the right value</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># initialize a GradScaler. If enabled=False scaler is a no-op</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="p">(</span><span class="n">dtype</span> <span class="o">==</span> <span class="s1">'float16'</span><span class="p">))</span>

<span class="c1"># optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">),</span> <span class="n">device_type</span><span class="p">)</span>
<span class="k">if</span> <span class="n">init_from</span> <span class="o">==</span> <span class="s1">'resume'</span><span class="p">:</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizer'</span><span class="p">])</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># free up memory</span>

<span class="c1"># compile the model</span>
<span class="k">if</span> <span class="nb">compile</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"compiling the model... (takes a ~minute)"</span><span class="p">)</span>
    <span class="n">unoptimized_model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># requires PyTorch 2.0</span>

<span class="c1"># wrap model into DDP container</span>
<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">ddp_local_rank</span><span class="p">])</span>

<span class="c1"># helps estimate an arbitrarily accurate loss over either split using many batches</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">estimate_loss</span><span class="p">():</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">]:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="c1"># learning rate decay scheduler (cosine with warmup)</span>
<span class="k">def</span> <span class="nf">get_lr</span><span class="p">(</span><span class="n">it</span><span class="p">):</span>
    <span class="c1"># 1) linear warmup for warmup_iters steps</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">&lt;</span> <span class="n">warmup_iters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">it</span> <span class="o">/</span> <span class="n">warmup_iters</span>
    <span class="c1"># 2) if it &gt; lr_decay_iters, return min learning rate</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">&gt;</span> <span class="n">lr_decay_iters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">min_lr</span>
    <span class="c1"># 3) in between, use cosine decay down to min learning rate</span>
    <span class="n">decay_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">it</span> <span class="o">-</span> <span class="n">warmup_iters</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">lr_decay_iters</span> <span class="o">-</span> <span class="n">warmup_iters</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">decay_ratio</span> <span class="o">&lt;=</span> <span class="mi">1</span>
    <span class="n">coeff</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">decay_ratio</span><span class="p">))</span> <span class="c1"># coeff ranges 0..1</span>
    <span class="k">return</span> <span class="n">min_lr</span> <span class="o">+</span> <span class="n">coeff</span> <span class="o">*</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">-</span> <span class="n">min_lr</span><span class="p">)</span>

<span class="c1"># logging</span>
<span class="k">if</span> <span class="n">wandb_log</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">wandb</span>
    <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="n">wandb_project</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">wandb_run_name</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># training loop</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span> <span class="c1"># fetch the very first batch</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">local_iter_num</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># number of iterations in the lifetime of this process</span>
<span class="n">raw_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span> <span class="k">if</span> <span class="n">ddp</span> <span class="k">else</span> <span class="n">model</span> <span class="c1"># unwrap DDP container if needed</span>
<span class="n">running_mfu</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>

    <span class="c1"># determine and set the learning rate for this iteration</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">iter_num</span><span class="p">)</span> <span class="k">if</span> <span class="n">decay_lr</span> <span class="k">else</span> <span class="n">learning_rate</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">'lr'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="c1"># Evaluate the loss on train/val sets and write checkpoints</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span>
    
        <span class="c1"># Compare and update the smallest validation loss</span>
        <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">min_loss_val</span><span class="p">:</span>
            <span class="n">min_loss_val</span> <span class="o">=</span> <span class="n">val_loss</span>

        <span class="c1"># Compare and update the smallest training loss</span>
        <span class="k">if</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="n">min_loss_train</span><span class="p">:</span>
            <span class="n">min_loss_train</span> <span class="o">=</span> <span class="n">train_loss</span>

        <span class="c1"># Print the current step, training, and validation loss</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"step </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: train loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, val loss </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">wandb_log</span><span class="p">:</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s2">"iter"</span><span class="p">:</span> <span class="n">iter_num</span><span class="p">,</span>
                <span class="s2">"train/loss"</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
                <span class="s2">"val/loss"</span><span class="p">:</span> <span class="n">val_loss</span><span class="p">,</span>
                <span class="s2">"lr"</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
                <span class="s2">"mfu"</span><span class="p">:</span> <span class="n">running_mfu</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># convert to percentage</span>
            <span class="p">})</span>

        <span class="c1"># Save checkpoint if needed</span>
        <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span> <span class="ow">or</span> <span class="n">always_save_checkpoint</span><span class="p">:</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
            <span class="k">if</span> <span class="n">iter_num</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">'model'</span><span class="p">:</span> <span class="n">raw_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">'optimizer'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">'model_args'</span><span class="p">:</span> <span class="n">model_args</span><span class="p">,</span>
                    <span class="s1">'iter_num'</span><span class="p">:</span> <span class="n">iter_num</span><span class="p">,</span>
                    <span class="s1">'best_val_loss'</span><span class="p">:</span> <span class="n">best_val_loss</span><span class="p">,</span>
                    <span class="s1">'config'</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"saving checkpoint to </span><span class="si">{</span><span class="n">out_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">'ckpt.pt'</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">iter_num</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">eval_only</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="c1"># forward backward update, with optional gradient accumulation to simulate larger batch size</span>
    <span class="c1"># and using the GradScaler if data type is float16</span>
    <span class="k">for</span> <span class="n">micro_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
            <span class="c1"># in DDP training we only need to sync gradients at the last micro step.</span>
            <span class="c1"># the official way to do this is with model.no_sync() context manager, but</span>
            <span class="c1"># I really dislike that this bloats the code and forces us to repeat code</span>
            <span class="c1"># looking at the source of that context manager, it just toggles this variable</span>
            <span class="n">model</span><span class="o">.</span><span class="n">require_backward_grad_sync</span> <span class="o">=</span> <span class="p">(</span><span class="n">micro_step</span> <span class="o">==</span> <span class="n">gradient_accumulation_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">gradient_accumulation_steps</span> <span class="c1"># scale the loss to account for gradient accumulation</span>
        <span class="c1"># immediately async prefetch next batch while model is doing the forward pass on the GPU</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>
        <span class="c1"># backward pass, with gradient scaling if training in fp16</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># clip the gradient</span>
    <span class="k">if</span> <span class="n">grad_clip</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">grad_clip</span><span class="p">)</span>
    <span class="c1"># step the optimizer and scaler if training in fp16</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    <span class="c1"># flush the gradients as soon as we can, no need for this memory anymore</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># timing and logging</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">t1</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="c1"># get loss as float. note: this is a CPU-GPU sync point</span>
        <span class="c1"># scale up to undo the division above, approximating the true total loss (exact would have been a sum)</span>
        <span class="n">lossf</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">gradient_accumulation_steps</span>
        <span class="k">if</span> <span class="n">local_iter_num</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># let the training loop settle a bit</span>
            <span class="n">mfu</span> <span class="o">=</span> <span class="n">raw_model</span><span class="o">.</span><span class="n">estimate_mfu</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">gradient_accumulation_steps</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
            <span class="n">running_mfu</span> <span class="o">=</span> <span class="n">mfu</span> <span class="k">if</span> <span class="n">running_mfu</span> <span class="o">==</span> <span class="o">-</span><span class="mf">1.0</span> <span class="k">else</span> <span class="mf">0.9</span><span class="o">*</span><span class="n">running_mfu</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">mfu</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"iter </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: loss </span><span class="si">{</span><span class="n">lossf</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, time </span><span class="si">{</span><span class="n">dt</span><span class="o">*</span><span class="mi">1000</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms, mfu </span><span class="si">{</span><span class="n">running_mfu</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="n">iter_num</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">local_iter_num</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># termination conditions</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">&gt;</span> <span class="n">max_iters</span><span class="p">:</span>
        <span class="k">break</span>

<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">destroy_process_group</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>tokens per iteration will be: 30,720
Initializing a new model from scratch
defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)
number of parameters: 7.23M
num decayed parameter tensors: 18, with 7,233,536 parameters
num non-decayed parameter tensors: 9, with 1,152 parameters
using fused AdamW: False
compiling the model... (takes a ~minute)
step 0: train loss 10.8272, val loss 10.8203
iter 0: loss 10.8381, time 5266.27ms, mfu -100.00%
iter 10: loss 10.5130, time 5193.01ms, mfu 0.08%
iter 20: loss 10.1791, time 5620.94ms, mfu 0.08%
iter 30: loss 9.6569, time 5457.37ms, mfu 0.08%
iter 40: loss 8.9592, time 5137.98ms, mfu 0.08%
iter 50: loss 8.2670, time 5109.56ms, mfu 0.08%
iter 60: loss 7.4217, time 5533.47ms, mfu 0.08%
iter 70: loss 6.7772, time 5394.84ms, mfu 0.08%
iter 80: loss 6.3384, time 5341.75ms, mfu 0.08%
iter 90: loss 6.2519, time 5243.57ms, mfu 0.08%
iter 100: loss 6.1288, time 5141.52ms, mfu 0.08%
iter 110: loss 6.0240, time 5185.93ms, mfu 0.08%
iter 120: loss 5.4966, time 5555.16ms, mfu 0.08%
iter 130: loss 5.2304, time 5179.47ms, mfu 0.08%
iter 140: loss 5.0099, time 5239.58ms, mfu 0.08%
iter 150: loss 4.6988, time 5212.68ms, mfu 0.08%
iter 160: loss 4.7795, time 5256.68ms, mfu 0.08%
iter 170: loss 4.7551, time 5165.88ms, mfu 0.08%
iter 180: loss 4.7645, time 5240.20ms, mfu 0.08%
iter 190: loss 4.6803, time 5163.44ms, mfu 0.08%
iter 200: loss 4.3318, time 5161.59ms, mfu 0.08%
iter 210: loss 4.2769, time 5399.15ms, mfu 0.08%
iter 220: loss 4.4098, time 5276.09ms, mfu 0.08%
iter 230: loss 4.4509, time 5184.08ms, mfu 0.08%
iter 240: loss 4.4467, time 5123.78ms, mfu 0.08%
step 250: train loss 4.0974, val loss 4.8850
saving checkpoint to out
iter 250: loss 4.3510, time 7339.31ms, mfu 0.08%
iter 260: loss 3.9377, time 5410.26ms, mfu 0.08%
iter 270: loss 4.1588, time 5138.77ms, mfu 0.08%
iter 280: loss 4.0463, time 5133.57ms, mfu 0.08%
iter 290: loss 4.0747, time 5185.01ms, mfu 0.08%
iter 300: loss 4.0215, time 5201.70ms, mfu 0.08%
iter 310: loss 3.7042, time 5253.30ms, mfu 0.08%
iter 320: loss 3.6267, time 5554.38ms, mfu 0.08%
iter 330: loss 3.7190, time 5163.56ms, mfu 0.08%
iter 340: loss 3.5353, time 5154.63ms, mfu 0.08%
iter 350: loss 3.6444, time 5244.93ms, mfu 0.08%
iter 360: loss 3.6720, time 5309.55ms, mfu 0.08%
iter 370: loss 3.1701, time 5186.85ms, mfu 0.08%
iter 380: loss 3.7539, time 5234.31ms, mfu 0.08%
iter 390: loss 3.7535, time 5338.72ms, mfu 0.08%
iter 400: loss 3.5834, time 5131.69ms, mfu 0.08%
iter 410: loss 3.6911, time 5211.52ms, mfu 0.08%
iter 420: loss 3.4482, time 5322.77ms, mfu 0.08%
iter 430: loss 3.3925, time 5167.03ms, mfu 0.08%
iter 440: loss 3.0784, time 5503.29ms, mfu 0.08%
iter 450: loss 3.2875, time 5463.42ms, mfu 0.08%
iter 460: loss 3.6252, time 5406.49ms, mfu 0.08%
iter 470: loss 3.4252, time 5365.48ms, mfu 0.08%
iter 480: loss 2.8320, time 5176.34ms, mfu 0.08%
iter 490: loss 3.2301, time 5157.38ms, mfu 0.08%
step 500: train loss 3.2212, val loss 5.0541
iter 500: loss 3.2794, time 6956.72ms, mfu 0.08%
iter 510: loss 2.9306, time 5167.26ms, mfu 0.08%
iter 520: loss 2.9543, time 5187.70ms, mfu 0.08%
iter 530: loss 3.1853, time 5175.39ms, mfu 0.08%
iter 540: loss 3.2137, time 5274.72ms, mfu 0.08%
iter 550: loss 3.4943, time 5141.71ms, mfu 0.08%
iter 560: loss 3.3561, time 5138.61ms, mfu 0.08%
iter 570: loss 3.1030, time 5235.64ms, mfu 0.08%
iter 580: loss 3.2393, time 5250.98ms, mfu 0.08%
iter 590: loss 3.3144, time 5139.61ms, mfu 0.08%
iter 600: loss 3.0881, time 5167.34ms, mfu 0.08%
iter 610: loss 3.0887, time 5258.65ms, mfu 0.08%
iter 620: loss 2.7479, time 5111.51ms, mfu 0.08%
iter 630: loss 3.1412, time 5146.63ms, mfu 0.08%
iter 640: loss 2.6146, time 5129.46ms, mfu 0.08%
iter 650: loss 2.8939, time 5414.26ms, mfu 0.08%
iter 660: loss 2.7797, time 5344.29ms, mfu 0.08%
iter 670: loss 2.6647, time 5137.80ms, mfu 0.08%
iter 680: loss 2.9663, time 6346.70ms, mfu 0.08%
iter 690: loss 2.5692, time 5316.48ms, mfu 0.08%
iter 700: loss 2.6489, time 5403.57ms, mfu 0.08%
iter 710: loss 2.8903, time 5082.89ms, mfu 0.08%
iter 720: loss 2.6256, time 5220.57ms, mfu 0.08%
iter 730: loss 2.5373, time 5658.63ms, mfu 0.08%
iter 740: loss 2.5371, time 5284.33ms, mfu 0.08%
step 750: train loss 2.6738, val loss 5.7380
iter 750: loss 2.6325, time 7063.21ms, mfu 0.08%
iter 760: loss 2.6389, time 5438.49ms, mfu 0.08%
iter 770: loss 2.5138, time 5280.69ms, mfu 0.08%
iter 780: loss 2.5269, time 5082.86ms, mfu 0.08%
iter 790: loss 2.4930, time 5058.02ms, mfu 0.08%
iter 800: loss 2.5772, time 5378.19ms, mfu 0.08%
iter 810: loss 2.4826, time 5200.47ms, mfu 0.08%
iter 820: loss 2.3465, time 6121.42ms, mfu 0.08%
iter 830: loss 2.6048, time 5161.10ms, mfu 0.08%
iter 840: loss 2.3555, time 5643.07ms, mfu 0.08%
iter 850: loss 2.5167, time 5065.57ms, mfu 0.08%
iter 860: loss 2.3891, time 5092.77ms, mfu 0.08%
iter 870: loss 2.2514, time 5177.66ms, mfu 0.08%
iter 880: loss 2.4172, time 5182.43ms, mfu 0.08%
iter 890: loss 2.3964, time 5093.42ms, mfu 0.08%
iter 900: loss 2.4480, time 5115.62ms, mfu 0.08%
iter 910: loss 2.4132, time 5433.95ms, mfu 0.08%
iter 920: loss 2.5034, time 6628.77ms, mfu 0.08%
iter 930: loss 2.1159, time 5082.46ms, mfu 0.08%
iter 940: loss 2.3870, time 5455.31ms, mfu 0.08%
iter 950: loss 2.3039, time 5082.79ms, mfu 0.08%
iter 960: loss 2.2866, time 5115.68ms, mfu 0.08%
iter 970: loss 2.2687, time 5101.62ms, mfu 0.08%
iter 980: loss 2.2468, time 5114.22ms, mfu 0.08%
iter 990: loss 2.0946, time 5092.97ms, mfu 0.08%
step 1000: train loss 2.1495, val loss 6.3032
iter 1000: loss 2.3327, time 7756.83ms, mfu 0.08%
iter 1010: loss 1.9599, time 6046.38ms, mfu 0.08%
iter 1020: loss 2.1337, time 5359.00ms, mfu 0.08%
iter 1030: loss 2.1232, time 5424.50ms, mfu 0.08%
iter 1040: loss 2.2534, time 5900.60ms, mfu 0.08%
iter 1050: loss 2.1482, time 5740.50ms, mfu 0.08%
iter 1060: loss 2.1936, time 5680.30ms, mfu 0.08%
iter 1070: loss 1.9218, time 5723.91ms, mfu 0.08%
iter 1080: loss 2.2113, time 6070.89ms, mfu 0.08%
iter 1090: loss 1.9698, time 5139.50ms, mfu 0.08%
iter 1100: loss 1.7959, time 5348.08ms, mfu 0.08%
iter 1110: loss 2.0179, time 7509.14ms, mfu 0.08%
iter 1120: loss 2.2788, time 5174.29ms, mfu 0.08%
iter 1130: loss 2.0036, time 5837.86ms, mfu 0.08%
iter 1140: loss 2.1348, time 5810.46ms, mfu 0.08%
iter 1150: loss 1.9259, time 6667.54ms, mfu 0.07%
iter 1160: loss 2.0508, time 5123.19ms, mfu 0.08%
iter 1170: loss 2.0503, time 5096.95ms, mfu 0.08%
iter 1180: loss 1.9252, time 5134.37ms, mfu 0.08%
iter 1190: loss 1.9504, time 5954.42ms, mfu 0.08%
iter 1200: loss 1.8043, time 5282.20ms, mfu 0.08%
iter 1210: loss 1.8939, time 5093.99ms, mfu 0.08%
iter 1220: loss 1.7935, time 5445.28ms, mfu 0.08%
iter 1230: loss 1.7855, time 5727.44ms, mfu 0.08%
iter 1240: loss 1.9397, time 5399.54ms, mfu 0.08%
step 1250: train loss 1.7955, val loss 6.8398
iter 1250: loss 1.8921, time 7531.72ms, mfu 0.08%
iter 1260: loss 1.8664, time 5317.85ms, mfu 0.08%
iter 1270: loss 1.8398, time 5555.91ms, mfu 0.08%
iter 1280: loss 1.7158, time 7275.14ms, mfu 0.07%
iter 1290: loss 1.7041, time 5970.63ms, mfu 0.07%
iter 1300: loss 1.8413, time 5691.12ms, mfu 0.07%
iter 1310: loss 1.8601, time 5773.71ms, mfu 0.07%
iter 1320: loss 1.7030, time 6340.77ms, mfu 0.07%
iter 1330: loss 1.7968, time 5877.17ms, mfu 0.07%
iter 1340: loss 1.9204, time 5399.59ms, mfu 0.07%
iter 1350: loss 1.7238, time 5384.16ms, mfu 0.08%
iter 1360: loss 1.7716, time 5531.93ms, mfu 0.08%
iter 1370: loss 1.7073, time 6468.88ms, mfu 0.07%
iter 1380: loss 1.7495, time 5490.10ms, mfu 0.07%
iter 1390: loss 1.6049, time 7616.87ms, mfu 0.07%
iter 1400: loss 1.6380, time 7013.38ms, mfu 0.07%
iter 1410: loss 1.6979, time 6432.66ms, mfu 0.07%
iter 1420: loss 1.6364, time 6262.58ms, mfu 0.07%
iter 1430: loss 1.5178, time 5714.86ms, mfu 0.07%
iter 1440: loss 1.5686, time 6470.35ms, mfu 0.07%
iter 1450: loss 1.5543, time 5652.75ms, mfu 0.07%
iter 1460: loss 1.6305, time 5461.56ms, mfu 0.07%
iter 1470: loss 1.5670, time 5828.34ms, mfu 0.07%
iter 1480: loss 1.6294, time 5493.15ms, mfu 0.07%
iter 1490: loss 1.5066, time 5759.24ms, mfu 0.07%
step 1500: train loss 1.5629, val loss 7.1271
iter 1500: loss 1.6998, time 7450.26ms, mfu 0.07%
iter 1510: loss 1.7019, time 6435.42ms, mfu 0.07%
iter 1520: loss 1.5190, time 5665.03ms, mfu 0.07%
iter 1530: loss 1.5239, time 5541.80ms, mfu 0.07%
iter 1540: loss 1.5345, time 6962.27ms, mfu 0.07%
iter 1550: loss 1.4402, time 7583.96ms, mfu 0.07%
iter 1560: loss 1.5247, time 1001614.80ms, mfu 0.06%
iter 1570: loss 1.3998, time 6615.54ms, mfu 0.06%
iter 1580: loss 1.5294, time 5314.55ms, mfu 0.06%
iter 1590: loss 1.4220, time 5201.08ms, mfu 0.07%
iter 1600: loss 1.8163, time 5186.91ms, mfu 0.07%
iter 1610: loss 1.5588, time 5366.25ms, mfu 0.07%
iter 1620: loss 1.4030, time 5247.85ms, mfu 0.07%
iter 1630: loss 1.5230, time 5974.58ms, mfu 0.07%
iter 1640: loss 1.3079, time 6120.61ms, mfu 0.07%
iter 1650: loss 1.3131, time 6161.97ms, mfu 0.07%
iter 1660: loss 1.4101, time 6136.79ms, mfu 0.07%
iter 1670: loss 1.5243, time 5459.08ms, mfu 0.07%
iter 1680: loss 1.2546, time 5283.13ms, mfu 0.07%
iter 1690: loss 1.5366, time 5365.14ms, mfu 0.07%
iter 1700: loss 1.4925, time 5361.01ms, mfu 0.07%
iter 1710: loss 1.4686, time 5382.14ms, mfu 0.07%
iter 1720: loss 1.4362, time 5330.63ms, mfu 0.08%
iter 1730: loss 1.4316, time 5754.65ms, mfu 0.08%
iter 1740: loss 1.2015, time 5459.13ms, mfu 0.08%
step 1750: train loss 1.4013, val loss 7.3982
iter 1750: loss 1.3489, time 7407.05ms, mfu 0.07%
iter 1760: loss 1.3594, time 5833.27ms, mfu 0.07%
iter 1770: loss 1.2894, time 6455.22ms, mfu 0.07%
iter 1780: loss 1.4646, time 5748.66ms, mfu 0.07%
iter 1790: loss 1.3092, time 5345.87ms, mfu 0.07%
iter 1800: loss 1.2142, time 5586.73ms, mfu 0.07%
iter 1810: loss 1.5124, time 5297.29ms, mfu 0.08%
iter 1820: loss 1.5674, time 5299.11ms, mfu 0.08%
iter 1830: loss 1.3310, time 5474.53ms, mfu 0.08%
iter 1840: loss 1.4313, time 5312.43ms, mfu 0.08%
iter 1850: loss 1.3174, time 5250.85ms, mfu 0.08%
iter 1860: loss 1.2454, time 5468.49ms, mfu 0.08%
iter 1870: loss 1.3560, time 5873.58ms, mfu 0.08%
iter 1880: loss 1.3938, time 6415.60ms, mfu 0.08%
iter 1890: loss 1.2350, time 5398.18ms, mfu 0.08%
iter 1900: loss 1.3372, time 5383.75ms, mfu 0.08%
iter 1910: loss 1.3619, time 5611.94ms, mfu 0.08%
iter 1920: loss 1.3743, time 5727.74ms, mfu 0.08%
iter 1930: loss 1.4229, time 5428.26ms, mfu 0.08%
iter 1940: loss 1.3262, time 6065.48ms, mfu 0.08%
iter 1950: loss 1.6089, time 5328.59ms, mfu 0.08%
iter 1960: loss 1.3470, time 5371.44ms, mfu 0.08%
iter 1970: loss 1.3968, time 5466.88ms, mfu 0.08%
iter 1980: loss 1.3298, time 5326.80ms, mfu 0.08%
iter 1990: loss 1.4861, time 5362.22ms, mfu 0.08%
step 2000: train loss 1.3082, val loss 7.4831
iter 2000: loss 1.3102, time 7958.11ms, mfu 0.08%
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">### evaluation metric</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">init_process_group</span><span class="p">,</span> <span class="n">destroy_process_group</span>

<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>

<span class="n">min_loss_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>  <span class="c1"># Initialize minimum validation loss</span>
<span class="n">min_loss_train</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># default configurations (you can modify this section as needed)</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="s1">'out'</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># print every 10 iterations</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">eval_only</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">always_save_checkpoint</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">init_from</span> <span class="o">=</span> <span class="s1">'scratch'</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">8</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># model</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># for pretraining 0 is good, for finetuning try 0.1+</span>
<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># do we use bias inside LayerNorm and Linear layers?</span>
<span class="c1"># adamw optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># max learning rate</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># total number of training iterations</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># clip gradients at this value, or disable if == 0.0</span>
<span class="c1"># learning rate decay settings</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># how many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># should be ~= max_iters per Chinchilla</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># minimum learning rate, should be ~= learning_rate/10 per Chinchilla</span>

<span class="n">device</span> <span class="o">=</span> <span class="s1">'mps'</span>  <span class="c1"># 'cuda' or 'cpu'</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s1">'float16'</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s1">'shakespeare_char'</span>
<span class="n">backend</span> <span class="o">=</span> <span class="s1">'nccl'</span>
<span class="c1"># -----------------------------------------------------------------------------</span>

<span class="c1"># Initialize distributed data parallel (DDP) setup</span>
<span class="n">ddp</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'RANK'</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'cuda:</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"LOCAL_RANK"</span><span class="p">])</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'RANK'</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">device_type</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="s1">'cuda'</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">else</span> <span class="s1">'cpu'</span>
<span class="n">ptdtype</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'float32'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">'float16'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">}[</span><span class="n">dtype</span><span class="p">]</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span> <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">'cpu'</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device_type</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ptdtype</span><span class="p">)</span>

<span class="c1"># Data loading</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s1">.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">+</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Initialize the model</span>
<span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">),</span> <span class="n">device_type</span><span class="p">)</span>

<span class="c1"># Evaluation Metrics</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">calculate_perplexity</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
    <span class="sd">""" Calculate the perplexity from the cross-entropy loss. """</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">calculate_ngram_diversity</span><span class="p">(</span><span class="n">generated_text</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="sd">""" Calculate the n-gram diversity. """</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># If the text is too short to form n-grams, return diversity of 0</span>
    <span class="n">ngrams</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">generated_text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span><span class="o">-</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">unique_ngrams</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">ngrams</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_ngrams</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngrams</span><span class="p">)</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">estimate_loss_and_metrics</span><span class="p">():</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">]:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        <span class="n">perplexities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        <span class="n">ngram_diversity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">perplexities</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">calculate_perplexity</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># Generate sample text and calculate n-gram diversity</span>
            <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># If 1D tensor, unsqueeze to make it 2D</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">generated_text</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
            <span class="n">diversity</span> <span class="o">=</span> <span class="n">calculate_ngram_diversity</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
            <span class="n">ngram_diversity</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">diversity</span>

        <span class="n">out</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">'loss'</span><span class="p">:</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
            <span class="s1">'perplexity'</span><span class="p">:</span> <span class="n">perplexities</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
            <span class="s1">'ngram_diversity'</span><span class="p">:</span> <span class="n">ngram_diversity</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">}</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="c1"># Training Loop</span>
<span class="k">for</span> <span class="n">iter_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Ensure the model is in training mode</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear the previous gradients</span>

    <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>  <span class="c1"># Forward pass</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Backward pass to compute gradients</span>

    <span class="c1"># Clip gradients if necessary</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">grad_clip</span><span class="p">)</span>

    <span class="c1"># Update the model parameters using the optimizer</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Log training progress every log_interval iterations</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Iteration </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Training Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Evaluate the model every eval_interval iterations</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">estimate_loss_and_metrics</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Step </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Train Loss: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'train'</span><span class="p">][</span><span class="s1">'loss'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
              <span class="sa">f</span><span class="s2">"Val Loss: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'val'</span><span class="p">][</span><span class="s1">'loss'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
              <span class="sa">f</span><span class="s2">"Train Perplexity: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'train'</span><span class="p">][</span><span class="s1">'perplexity'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
              <span class="sa">f</span><span class="s2">"Val Perplexity: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'val'</span><span class="p">][</span><span class="s1">'perplexity'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
              <span class="sa">f</span><span class="s2">"Train N-gram Diversity: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'train'</span><span class="p">][</span><span class="s1">'ngram_diversity'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
              <span class="sa">f</span><span class="s2">"Val N-gram Diversity: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'val'</span><span class="p">][</span><span class="s1">'ngram_diversity'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Stop training once the max_iters threshold is reached</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">&gt;=</span> <span class="n">max_iters</span><span class="p">:</span>
        <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The smallest training loss during training: </span><span class="si">{</span><span class="n">min_loss_train</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The smallest validation loss during training: </span><span class="si">{</span><span class="n">min_loss_val</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>number of parameters: 7.23M
num decayed parameter tensors: 18, with 7,233,536 parameters
num non-decayed parameter tensors: 9, with 1,152 parameters
using fused AdamW: False
Iteration 0: Training Loss: 10.8316
Step 0: Train Loss: 10.5135, Val Loss: 10.5108, Train Perplexity: 36813.6797, Val Perplexity: 36720.5234, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 10: Training Loss: 9.2299
Iteration 20: Training Loss: 7.8036
Iteration 30: Training Loss: 6.8566
Iteration 40: Training Loss: 6.3629
Iteration 50: Training Loss: 6.6182
Iteration 60: Training Loss: 6.3083
Iteration 70: Training Loss: 6.0940
Iteration 80: Training Loss: 6.0979
Iteration 90: Training Loss: 6.0056
Iteration 100: Training Loss: 5.8846
Iteration 110: Training Loss: 5.9656
Iteration 120: Training Loss: 5.8666
Iteration 130: Training Loss: 5.7790
Iteration 140: Training Loss: 5.6833
Iteration 150: Training Loss: 5.5832
Iteration 160: Training Loss: 5.7670
Iteration 170: Training Loss: 5.2800
Iteration 180: Training Loss: 5.1718
Iteration 190: Training Loss: 5.3567
Iteration 200: Training Loss: 5.2977
Iteration 210: Training Loss: 5.3582
Iteration 220: Training Loss: 5.1197
Iteration 230: Training Loss: 5.0543
Iteration 240: Training Loss: 5.1416
Iteration 250: Training Loss: 5.1163
Step 250: Train Loss: 5.2239, Val Loss: 5.5110, Train Perplexity: 189.0663, Val Perplexity: 253.8405, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 260: Training Loss: 5.0164
Iteration 270: Training Loss: 5.0852
Iteration 280: Training Loss: 5.6419
Iteration 290: Training Loss: 5.1387
Iteration 300: Training Loss: 4.8245
Iteration 310: Training Loss: 4.8439
Iteration 320: Training Loss: 4.9031
Iteration 330: Training Loss: 4.8592
Iteration 340: Training Loss: 4.8235
Iteration 350: Training Loss: 4.8536
Iteration 360: Training Loss: 4.7500
Iteration 370: Training Loss: 4.7640
Iteration 380: Training Loss: 5.0239
Iteration 390: Training Loss: 5.1704
Iteration 400: Training Loss: 4.7591
Iteration 410: Training Loss: 4.6709
Iteration 420: Training Loss: 4.8127
Iteration 430: Training Loss: 4.8659
Iteration 440: Training Loss: 4.6573
Iteration 450: Training Loss: 4.9509
Iteration 460: Training Loss: 4.7474
Iteration 470: Training Loss: 4.8130
Iteration 480: Training Loss: 4.6915
Iteration 490: Training Loss: 4.8408
Iteration 500: Training Loss: 4.7135
Step 500: Train Loss: 4.7327, Val Loss: 5.1584, Train Perplexity: 117.1193, Val Perplexity: 177.9242, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 510: Training Loss: 4.3853
Iteration 520: Training Loss: 4.8236
Iteration 530: Training Loss: 4.7304
Iteration 540: Training Loss: 4.7325
Iteration 550: Training Loss: 4.8643
Iteration 560: Training Loss: 4.6135
Iteration 570: Training Loss: 4.4325
Iteration 580: Training Loss: 4.5444
Iteration 590: Training Loss: 4.0857
Iteration 600: Training Loss: 4.5984
Iteration 610: Training Loss: 4.7229
Iteration 620: Training Loss: 4.7138
Iteration 630: Training Loss: 4.6952
Iteration 640: Training Loss: 4.5927
Iteration 650: Training Loss: 4.8149
Iteration 660: Training Loss: 4.5123
Iteration 670: Training Loss: 4.7237
Iteration 680: Training Loss: 4.4186
Iteration 690: Training Loss: 4.5728
Iteration 700: Training Loss: 4.4422
Iteration 710: Training Loss: 4.4986
Iteration 720: Training Loss: 4.2044
Iteration 730: Training Loss: 4.0249
Iteration 740: Training Loss: 3.9999
Iteration 750: Training Loss: 4.4203
Step 750: Train Loss: 4.3723, Val Loss: 4.9209, Train Perplexity: 80.5611, Val Perplexity: 140.5941, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 760: Training Loss: 4.5960
Iteration 770: Training Loss: 4.1842
Iteration 780: Training Loss: 4.5265
Iteration 790: Training Loss: 4.3037
Iteration 800: Training Loss: 4.4647
Iteration 810: Training Loss: 4.1660
Iteration 820: Training Loss: 4.5577
Iteration 830: Training Loss: 4.4133
Iteration 840: Training Loss: 4.4028
Iteration 850: Training Loss: 4.5207
Iteration 860: Training Loss: 4.2813
Iteration 870: Training Loss: 4.2176
Iteration 880: Training Loss: 4.4020
Iteration 890: Training Loss: 4.4074
Iteration 900: Training Loss: 4.8814
Iteration 910: Training Loss: 4.4657
Iteration 920: Training Loss: 4.8406
Iteration 930: Training Loss: 4.0810
Iteration 940: Training Loss: 4.5369
Iteration 950: Training Loss: 4.0861
Iteration 960: Training Loss: 4.1766
Iteration 970: Training Loss: 4.1897
Iteration 980: Training Loss: 4.1747
Iteration 990: Training Loss: 4.2880
Iteration 1000: Training Loss: 4.3822
Step 1000: Train Loss: 4.3182, Val Loss: 4.8652, Train Perplexity: 77.2434, Val Perplexity: 132.3988, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 1010: Training Loss: 4.4667
Iteration 1020: Training Loss: 4.3102
Iteration 1030: Training Loss: 4.4011
Iteration 1040: Training Loss: 4.0845
Iteration 1050: Training Loss: 4.5662
Iteration 1060: Training Loss: 4.2222
Iteration 1070: Training Loss: 4.0267
Iteration 1080: Training Loss: 3.8780
Iteration 1090: Training Loss: 4.4671
Iteration 1100: Training Loss: 4.4928
Iteration 1110: Training Loss: 4.5317
Iteration 1120: Training Loss: 4.1901
Iteration 1130: Training Loss: 4.0976
Iteration 1140: Training Loss: 4.1776
Iteration 1150: Training Loss: 4.0060
Iteration 1160: Training Loss: 4.4577
Iteration 1170: Training Loss: 4.2894
Iteration 1180: Training Loss: 4.1620
Iteration 1190: Training Loss: 4.1832
Iteration 1200: Training Loss: 3.7596
Iteration 1210: Training Loss: 4.2004
Iteration 1220: Training Loss: 4.1353
Iteration 1230: Training Loss: 4.1890
Iteration 1240: Training Loss: 4.1408
Iteration 1250: Training Loss: 3.9590
Step 1250: Train Loss: 4.1497, Val Loss: 4.9162, Train Perplexity: 65.2295, Val Perplexity: 141.4000, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 1260: Training Loss: 3.9003
Iteration 1270: Training Loss: 4.2247
Iteration 1280: Training Loss: 3.9799
Iteration 1290: Training Loss: 3.8705
Iteration 1300: Training Loss: 3.6778
Iteration 1310: Training Loss: 4.5428
Iteration 1320: Training Loss: 3.8313
Iteration 1330: Training Loss: 3.8468
Iteration 1340: Training Loss: 4.1440
Iteration 1350: Training Loss: 4.1777
Iteration 1360: Training Loss: 3.8810
Iteration 1370: Training Loss: 4.1075
Iteration 1380: Training Loss: 3.9438
Iteration 1390: Training Loss: 3.9353
Iteration 1400: Training Loss: 4.1933
Iteration 1410: Training Loss: 4.2095
Iteration 1420: Training Loss: 4.2831
Iteration 1430: Training Loss: 4.1704
Iteration 1440: Training Loss: 3.8001
Iteration 1450: Training Loss: 4.3565
Iteration 1460: Training Loss: 4.2197
Iteration 1470: Training Loss: 4.3430
Iteration 1480: Training Loss: 3.7647
Iteration 1490: Training Loss: 4.0975
Iteration 1500: Training Loss: 3.9147
Step 1500: Train Loss: 3.9446, Val Loss: 4.8196, Train Perplexity: 52.3852, Val Perplexity: 127.7143, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 1510: Training Loss: 3.4943
Iteration 1520: Training Loss: 3.7348
Iteration 1530: Training Loss: 3.6430
Iteration 1540: Training Loss: 4.2043
Iteration 1550: Training Loss: 4.1051
Iteration 1560: Training Loss: 4.4316
Iteration 1570: Training Loss: 4.4556
Iteration 1580: Training Loss: 3.9204
Iteration 1590: Training Loss: 3.7971
Iteration 1600: Training Loss: 4.0980
Iteration 1610: Training Loss: 4.2552
Iteration 1620: Training Loss: 3.8478
Iteration 1630: Training Loss: 3.8151
Iteration 1640: Training Loss: 3.6506
Iteration 1650: Training Loss: 3.9948
Iteration 1660: Training Loss: 4.2168
Iteration 1670: Training Loss: 3.7074
Iteration 1680: Training Loss: 3.7545
Iteration 1690: Training Loss: 4.1905
Iteration 1700: Training Loss: 3.8796
Iteration 1710: Training Loss: 4.2932
Iteration 1720: Training Loss: 4.0270
Iteration 1730: Training Loss: 3.7274
Iteration 1740: Training Loss: 3.6491
Iteration 1750: Training Loss: 4.4112
Step 1750: Train Loss: 3.8983, Val Loss: 4.8714, Train Perplexity: 50.0215, Val Perplexity: 137.5980, Train N-gram Diversity: 0.0000, Val N-gram Diversity: 0.0000
Iteration 1760: Training Loss: 3.8800
Iteration 1770: Training Loss: 3.5154
Iteration 1780: Training Loss: 3.9674
Iteration 1790: Training Loss: 3.7665
Iteration 1800: Training Loss: 3.8659
Iteration 1810: Training Loss: 4.2408
Iteration 1820: Training Loss: 3.9092
Iteration 1830: Training Loss: 3.6588
Iteration 1840: Training Loss: 3.3622
Iteration 1850: Training Loss: 3.9533
Iteration 1860: Training Loss: 3.5025
Iteration 1870: Training Loss: 3.6613
Iteration 1880: Training Loss: 3.8422
Iteration 1890: Training Loss: 3.7256
Iteration 1900: Training Loss: 3.7113
Iteration 1910: Training Loss: 3.8497
Iteration 1920: Training Loss: 3.7748
Iteration 1930: Training Loss: 3.8322
Iteration 1940: Training Loss: 4.0289
Iteration 1950: Training Loss: 4.0382
Iteration 1960: Training Loss: 3.9434
Iteration 1970: Training Loss: 3.7486
Iteration 1980: Training Loss: 4.0054
Iteration 1990: Training Loss: 3.9943
The smallest training loss during training: inf
The smallest validation loss during training: inf
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the directory containing the WikiText-2 dataset</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">'data/wikitext2'</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">'data/wikitext2'</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Paths to input files</span>
<span class="n">train_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'wiki.train.txt'</span><span class="p">)</span>
<span class="n">val_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'wiki.valid.txt'</span><span class="p">)</span>
<span class="n">test_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'wiki.test.txt'</span><span class="p">)</span>

<span class="c1"># Check if files exist</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">train_file_path</span><span class="p">),</span> <span class="s2">"Training file not found!"</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">val_file_path</span><span class="p">),</span> <span class="s2">"Validation file not found!"</span>
<span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">test_file_path</span><span class="p">),</span> <span class="s2">"Test file not found!"</span>

<span class="c1"># Read the dataset</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">val_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1"># Encode with GPT-2 Byte Pair Encoding (BPE) using tiktoken</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>  <span class="c1"># Encode training data</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>      <span class="c1"># Encode validation data</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"train has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"val has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>

<span class="c1"># Convert to numpy arrays (saving as uint16 to conserve space)</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>

<span class="c1"># Save train.bin and val.bin</span>
<span class="n">train_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">))</span>
<span class="n">val_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"WikiText-2 Data preparation complete!"</span><span class="p">)</span>

<span class="c1"># Output the sizes for verification</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"train.bin size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"val.bin size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens"</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>train has 2,448,382 tokens
val has 258,659 tokens
WikiText-2 Data preparation complete!
train.bin size: 2,448,382 tokens
val.bin size: 258,659 tokens
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">'''</span>
<span class="sd">training in another text dataset</span>
<span class="sd">'''</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">init_process_group</span><span class="p">,</span> <span class="n">destroy_process_group</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Default configuration values</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="s1">'out'</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">eval_iters</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">eval_only</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">always_save_checkpoint</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">init_from</span> <span class="o">=</span> <span class="s1">'scratch'</span>
<span class="n">wandb_log</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">wandb_project</span> <span class="o">=</span> <span class="s1">'owt'</span>
<span class="n">wandb_run_name</span> <span class="o">=</span> <span class="s1">'gpt2'</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s1">'wikitext2'</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">8</span>  <span class="c1"># Adjust to CPU-friendly settings</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>  <span class="c1"># Reduce the batch size for CPU</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># model</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># for pretraining 0 is good, for finetuning try 0.1+</span>
<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># do we use bias inside LayerNorm and Linear layers?</span>
<span class="c1"># adamw optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># max learning rate</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># total number of training iterations</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># clip gradients at this value, or disable if == 0.0</span>
<span class="c1"># learning rate decay settings</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># how many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># should be ~= max_iters per Chinchilla</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># minimum learning rate, should be ~= learning_rate/10 per Chinchilla</span>

<span class="n">dtype</span> <span class="o">=</span> <span class="s1">'float16'</span>  <span class="c1"># Float32 for CPU</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># No compilation since it's CPU</span>

<span class="c1"># Create the data directory</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">'data'</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">'out'</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set device to CPU explicitly</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'mps'</span>
<span class="n">ptdtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>  <span class="c1"># Since we're using CPU, no need for autocast</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Data loading function: Only use a portion of the data (1/4 of training data)</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">portion</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="c1"># Load a portion of the data</span>
    <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
    
    <span class="c1"># Limit to a portion of the dataset (1/4 of the data)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">portion</span><span class="p">)]</span>  <span class="c1"># Use only a fraction of the data</span>

    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    
    <span class="c1"># Move to the CPU</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Model initialization and training loop</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span>
<span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">),</span> <span class="n">device</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># No need for gradient scaling on CPU</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Training loop</span>
<span class="n">iter_num</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_val_loss</span> <span class="o">=</span> <span class="mf">1e9</span>

<span class="c1"># Function to estimate loss for train and validation</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">estimate_loss</span><span class="p">():</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">]:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_iters</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">out</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="c1"># Learning rate scheduler</span>
<span class="k">def</span> <span class="nf">get_lr</span><span class="p">(</span><span class="n">it</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">&lt;</span> <span class="n">warmup_iters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">it</span> <span class="o">/</span> <span class="n">warmup_iters</span>
    <span class="k">if</span> <span class="n">it</span> <span class="o">&gt;</span> <span class="n">lr_decay_iters</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">min_lr</span>
    <span class="n">decay_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">it</span> <span class="o">-</span> <span class="n">warmup_iters</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">lr_decay_iters</span> <span class="o">-</span> <span class="n">warmup_iters</span><span class="p">)</span>
    <span class="n">coeff</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">decay_ratio</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">min_lr</span> <span class="o">+</span> <span class="n">coeff</span> <span class="o">*</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">-</span> <span class="n">min_lr</span><span class="p">)</span>

<span class="c1"># Main training loop</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>  <span class="c1"># Fetch the first batch</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">local_iter_num</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">running_mfu</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>

<span class="k">while</span> <span class="n">iter_num</span> <span class="o">&lt;</span> <span class="n">max_iters</span><span class="p">:</span>
    <span class="c1"># Set the learning rate</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">get_lr</span><span class="p">(</span><span class="n">iter_num</span><span class="p">)</span> <span class="k">if</span> <span class="n">decay_lr</span> <span class="k">else</span> <span class="n">learning_rate</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">'lr'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="c1"># Evaluate and save model every eval_interval</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">estimate_loss</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Step </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Train Loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Save checkpoint if validation loss improves</span>
        <span class="k">if</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span> <span class="ow">or</span> <span class="n">always_save_checkpoint</span><span class="p">:</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">'model'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">'optimizer'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">'iter_num'</span><span class="p">:</span> <span class="n">iter_num</span><span class="p">,</span>
                <span class="s1">'best_val_loss'</span><span class="p">:</span> <span class="n">best_val_loss</span>
            <span class="p">}</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">'ckpt.pt'</span><span class="p">))</span>
    
    <span class="c1"># Training loop (forward, backward, and optimization)</span>
    <span class="k">for</span> <span class="n">micro_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">):</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Clip the gradients</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">grad_clip</span><span class="p">)</span>

    <span class="c1"># Step the optimizer</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Prefetch next batch</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>

    <span class="c1"># Logging</span>
    <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Iteration </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Loss </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="n">iter_num</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="c1"># the minumum of loss is 2.6</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>number of parameters: 7.23M
num decayed parameter tensors: 18, with 7,233,536 parameters
num non-decayed parameter tensors: 9, with 1,152 parameters
using fused AdamW: False
Step 0: Train Loss 10.8402, Val Loss 10.8430
Iteration 0: Loss 10.8372
Iteration 1: Loss 10.8513
Iteration 2: Loss 10.8344
Iteration 3: Loss 10.8108
Iteration 4: Loss 10.8169
Iteration 5: Loss 10.7998
Iteration 6: Loss 10.7823
Iteration 7: Loss 10.7552
Iteration 8: Loss 10.7119
Iteration 9: Loss 10.6747
Iteration 10: Loss 10.6613
Iteration 11: Loss 10.5905
Iteration 12: Loss 10.5746
Iteration 13: Loss 10.5615
Iteration 14: Loss 10.5308
Iteration 15: Loss 10.5294
Iteration 16: Loss 10.5079
Iteration 17: Loss 10.4551
Iteration 18: Loss 10.4136
Iteration 19: Loss 10.4346
Iteration 20: Loss 10.4022
Iteration 21: Loss 10.3179
Iteration 22: Loss 10.3221
Iteration 23: Loss 10.2433
Iteration 24: Loss 10.2199
Iteration 25: Loss 10.2263
Iteration 26: Loss 10.2382
Iteration 27: Loss 10.1489
Iteration 28: Loss 10.0871
Iteration 29: Loss 10.0765
Iteration 30: Loss 10.0313
Iteration 31: Loss 9.9573
Iteration 32: Loss 9.9736
Iteration 33: Loss 9.9176
Iteration 34: Loss 9.8445
Iteration 35: Loss 9.7110
Iteration 36: Loss 9.7245
Iteration 37: Loss 9.6927
Iteration 38: Loss 9.6414
Iteration 39: Loss 9.5598
Iteration 40: Loss 9.4783
Iteration 41: Loss 9.4060
Iteration 42: Loss 9.4016
Iteration 43: Loss 9.2517
Iteration 44: Loss 9.3184
Iteration 45: Loss 9.1391
Iteration 46: Loss 9.2129
Iteration 47: Loss 8.9831
Iteration 48: Loss 8.8927
Iteration 49: Loss 8.9996
Iteration 50: Loss 8.8181
Iteration 51: Loss 8.7200
Iteration 52: Loss 8.7893
Iteration 53: Loss 8.7162
Iteration 54: Loss 8.4965
Iteration 55: Loss 8.4676
Iteration 56: Loss 8.4379
Iteration 57: Loss 8.4253
Iteration 58: Loss 8.2717
Iteration 59: Loss 8.2626
Iteration 60: Loss 8.1677
Iteration 61: Loss 8.0838
Iteration 62: Loss 8.0623
Iteration 63: Loss 8.1781
Iteration 64: Loss 7.9611
Iteration 65: Loss 7.8566
Iteration 66: Loss 7.7394
Iteration 67: Loss 7.7219
Iteration 68: Loss 7.6347
Iteration 69: Loss 7.4749
Iteration 70: Loss 7.4946
Iteration 71: Loss 7.5063
Iteration 72: Loss 7.4663
Iteration 73: Loss 7.6079
Iteration 74: Loss 7.5352
Iteration 75: Loss 7.4438
Iteration 76: Loss 7.2117
Iteration 77: Loss 7.3038
Iteration 78: Loss 7.1263
Iteration 79: Loss 7.4365
Iteration 80: Loss 7.1533
Iteration 81: Loss 6.9898
Iteration 82: Loss 7.0328
Iteration 83: Loss 6.9209
Iteration 84: Loss 6.9689
Iteration 85: Loss 7.1263
Iteration 86: Loss 7.1619
Iteration 87: Loss 6.9631
Iteration 88: Loss 6.9928
Iteration 89: Loss 6.7368
Iteration 90: Loss 6.4365
Iteration 91: Loss 7.1499
Iteration 92: Loss 6.5390
Iteration 93: Loss 6.8604
Iteration 94: Loss 6.7081
Iteration 95: Loss 6.9531
Iteration 96: Loss 6.6352
Iteration 97: Loss 6.9552
Iteration 98: Loss 6.8881
Iteration 99: Loss 6.3939
Iteration 100: Loss 6.8024
Iteration 101: Loss 6.5170
Iteration 102: Loss 6.7508
Iteration 103: Loss 6.9359
Iteration 104: Loss 6.4374
Iteration 105: Loss 6.8296
Iteration 106: Loss 6.6658
Iteration 107: Loss 6.3767
Iteration 108: Loss 6.6106
Iteration 109: Loss 6.8156
Iteration 110: Loss 6.4872
Iteration 111: Loss 6.7451
Iteration 112: Loss 6.4815
Iteration 113: Loss 6.4713
Iteration 114: Loss 6.5939
Iteration 115: Loss 6.5621
Iteration 116: Loss 6.5659
Iteration 117: Loss 6.7204
Iteration 118: Loss 6.4666
Iteration 119: Loss 6.2245
Iteration 120: Loss 6.5594
Iteration 121: Loss 6.5509
Iteration 122: Loss 6.3895
Iteration 123: Loss 6.4139
Iteration 124: Loss 6.3054
Iteration 125: Loss 6.6966
Iteration 126: Loss 6.6162
Iteration 127: Loss 6.2902
Iteration 128: Loss 6.5203
Iteration 129: Loss 6.4111
Iteration 130: Loss 6.7427
Iteration 131: Loss 6.5011
Iteration 132: Loss 6.5654
Iteration 133: Loss 6.1312
Iteration 134: Loss 6.7305
Iteration 135: Loss 6.3166
Iteration 136: Loss 6.3995
Iteration 137: Loss 6.4322
Iteration 138: Loss 6.5266
Iteration 139: Loss 6.4199
Iteration 140: Loss 6.5307
Iteration 141: Loss 6.6116
Iteration 142: Loss 6.3942
Iteration 143: Loss 6.5801
Iteration 144: Loss 6.5829
Iteration 145: Loss 5.8615
Iteration 146: Loss 6.0269
Iteration 147: Loss 6.3068
Iteration 148: Loss 6.2313
Iteration 149: Loss 6.5152
Iteration 150: Loss 6.3991
Iteration 151: Loss 6.3947
Iteration 152: Loss 6.0445
Iteration 153: Loss 6.4680
Iteration 154: Loss 6.7526
Iteration 155: Loss 6.1284
Iteration 156: Loss 6.4456
Iteration 157: Loss 6.4110
Iteration 158: Loss 6.5821
Iteration 159: Loss 6.3811
Iteration 160: Loss 6.3631
Iteration 161: Loss 6.6260
Iteration 162: Loss 6.3795
Iteration 163: Loss 6.2588
Iteration 164: Loss 6.2287
Iteration 165: Loss 6.2697
Iteration 166: Loss 6.4237
Iteration 167: Loss 6.5574
Iteration 168: Loss 6.4173
Iteration 169: Loss 6.6314
Iteration 170: Loss 5.9514
Iteration 171: Loss 6.1484
Iteration 172: Loss 6.2121
Iteration 173: Loss 6.3321
Iteration 174: Loss 6.3906
Iteration 175: Loss 6.0405
Iteration 176: Loss 6.4461
Iteration 177: Loss 6.3244
Iteration 178: Loss 6.2160
Iteration 179: Loss 6.6685
Iteration 180: Loss 6.0942
Iteration 181: Loss 6.5989
Iteration 182: Loss 6.1757
Iteration 183: Loss 6.3998
Iteration 184: Loss 6.0498
Iteration 185: Loss 6.1595
Iteration 186: Loss 6.0339
Iteration 187: Loss 6.0260
Iteration 188: Loss 6.5846
Iteration 189: Loss 6.4345
Iteration 190: Loss 6.3202
Iteration 191: Loss 6.3826
Iteration 192: Loss 6.1102
Iteration 193: Loss 5.9198
Iteration 194: Loss 6.3932
Iteration 195: Loss 6.1842
Iteration 196: Loss 6.3523
Iteration 197: Loss 6.1350
Iteration 198: Loss 6.2328
Iteration 199: Loss 6.3285
Iteration 200: Loss 6.0894
Iteration 201: Loss 6.0909
Iteration 202: Loss 5.7767
Iteration 203: Loss 6.2335
Iteration 204: Loss 6.5133
Iteration 205: Loss 6.2605
Iteration 206: Loss 6.4448
Iteration 207: Loss 6.3427
Iteration 208: Loss 6.2647
Iteration 209: Loss 6.5275
Iteration 210: Loss 6.3162
Iteration 211: Loss 6.1645
Iteration 212: Loss 5.9881
Iteration 213: Loss 6.0595
Iteration 214: Loss 6.0140
Iteration 215: Loss 6.3484
Iteration 216: Loss 5.7614
Iteration 217: Loss 6.1971
Iteration 218: Loss 6.3133
Iteration 219: Loss 6.0809
Iteration 220: Loss 5.7638
Iteration 221: Loss 6.0636
Iteration 222: Loss 6.4607
Iteration 223: Loss 6.0589
Iteration 224: Loss 6.2465
Iteration 225: Loss 6.0194
Iteration 226: Loss 6.1822
Iteration 227: Loss 6.1013
Iteration 228: Loss 5.8249
Iteration 229: Loss 6.0734
Iteration 230: Loss 6.2124
Iteration 231: Loss 5.7940
Iteration 232: Loss 6.0418
Iteration 233: Loss 5.9618
Iteration 234: Loss 6.2834
Iteration 235: Loss 6.0888
Iteration 236: Loss 5.9457
Iteration 237: Loss 5.9578
Iteration 238: Loss 6.1983
Iteration 239: Loss 6.2336
Iteration 240: Loss 5.8912
Iteration 241: Loss 5.9652
Iteration 242: Loss 5.9388
Iteration 243: Loss 6.2879
Iteration 244: Loss 6.1450
Iteration 245: Loss 6.2061
Iteration 246: Loss 6.1774
Iteration 247: Loss 6.3853
Iteration 248: Loss 5.6426
Iteration 249: Loss 5.9300
Step 250: Train Loss 6.0612, Val Loss 5.5247
Iteration 250: Loss 6.2018
Iteration 251: Loss 6.1326
Iteration 252: Loss 6.0340
Iteration 253: Loss 6.2103
Iteration 254: Loss 6.2571
Iteration 255: Loss 5.7512
Iteration 256: Loss 5.8502
Iteration 257: Loss 6.1364
Iteration 258: Loss 6.0061
Iteration 259: Loss 6.0689
Iteration 260: Loss 6.1312
Iteration 261: Loss 5.6658
Iteration 262: Loss 5.9174
Iteration 263: Loss 5.9241
Iteration 264: Loss 6.2081
Iteration 265: Loss 6.4178
Iteration 266: Loss 6.0286
Iteration 267: Loss 6.0407
Iteration 268: Loss 5.8978
Iteration 269: Loss 6.1810
Iteration 270: Loss 5.9790
Iteration 271: Loss 6.0641
Iteration 272: Loss 6.1746
Iteration 273: Loss 5.4873
Iteration 274: Loss 5.7657
Iteration 275: Loss 5.9867
Iteration 276: Loss 6.0272
Iteration 277: Loss 6.1707
Iteration 278: Loss 5.3618
Iteration 279: Loss 5.8282
Iteration 280: Loss 5.5810
Iteration 281: Loss 6.0796
Iteration 282: Loss 5.9280
Iteration 283: Loss 5.9961
Iteration 284: Loss 5.6367
Iteration 285: Loss 5.6006
Iteration 286: Loss 5.5256
Iteration 287: Loss 5.7658
Iteration 288: Loss 5.6797
Iteration 289: Loss 6.2367
Iteration 290: Loss 6.1625
Iteration 291: Loss 5.4094
Iteration 292: Loss 5.9537
Iteration 293: Loss 5.8004
Iteration 294: Loss 6.1022
Iteration 295: Loss 6.1074
Iteration 296: Loss 5.9703
Iteration 297: Loss 5.7292
Iteration 298: Loss 5.8505
Iteration 299: Loss 5.8495
Iteration 300: Loss 6.0132
Iteration 301: Loss 6.2111
Iteration 302: Loss 5.8721
Iteration 303: Loss 6.0678
Iteration 304: Loss 5.7590
Iteration 305: Loss 5.7305
Iteration 306: Loss 5.9040
Iteration 307: Loss 5.8716
Iteration 308: Loss 6.1804
Iteration 309: Loss 6.0110
Iteration 310: Loss 6.1453
Iteration 311: Loss 5.9364
Iteration 312: Loss 5.9378
Iteration 313: Loss 6.0116
Iteration 314: Loss 5.9140
Iteration 315: Loss 5.8808
Iteration 316: Loss 6.0314
Iteration 317: Loss 5.9421
Iteration 318: Loss 6.2333
Iteration 319: Loss 5.4447
Iteration 320: Loss 5.7498
Iteration 321: Loss 6.4956
Iteration 322: Loss 5.6771
Iteration 323: Loss 5.8001
Iteration 324: Loss 5.7799
Iteration 325: Loss 6.0156
Iteration 326: Loss 5.8418
Iteration 327: Loss 5.7799
Iteration 328: Loss 5.9940
Iteration 329: Loss 5.6626
Iteration 330: Loss 5.5719
Iteration 331: Loss 5.8516
Iteration 332: Loss 6.1250
Iteration 333: Loss 5.6649
Iteration 334: Loss 5.6124
Iteration 335: Loss 5.7309
Iteration 336: Loss 5.7684
Iteration 337: Loss 5.5505
Iteration 338: Loss 6.1643
Iteration 339: Loss 6.0744
Iteration 340: Loss 5.8590
Iteration 341: Loss 5.9392
Iteration 342: Loss 5.8643
Iteration 343: Loss 5.8588
Iteration 344: Loss 5.6159
Iteration 345: Loss 6.0205
Iteration 346: Loss 6.0860
Iteration 347: Loss 5.7419
Iteration 348: Loss 5.7676
Iteration 349: Loss 5.7591
Iteration 350: Loss 6.0007
Iteration 351: Loss 5.8290
Iteration 352: Loss 6.1017
Iteration 353: Loss 5.9348
Iteration 354: Loss 5.9599
Iteration 355: Loss 5.7379
Iteration 356: Loss 5.8958
Iteration 357: Loss 6.0143
Iteration 358: Loss 5.8682
Iteration 359: Loss 6.0591
Iteration 360: Loss 5.9818
Iteration 361: Loss 5.7727
Iteration 362: Loss 6.3000
Iteration 363: Loss 5.7504
Iteration 364: Loss 5.8644
Iteration 365: Loss 5.9575
Iteration 366: Loss 5.8331
Iteration 367: Loss 5.6263
Iteration 368: Loss 6.0115
Iteration 369: Loss 5.4060
Iteration 370: Loss 5.6646
Iteration 371: Loss 5.2564
Iteration 372: Loss 5.9875
Iteration 373: Loss 5.4509
Iteration 374: Loss 5.2786
Iteration 375: Loss 5.7598
Iteration 376: Loss 5.8215
Iteration 377: Loss 5.8233
Iteration 378: Loss 5.8140
Iteration 379: Loss 5.8647
Iteration 380: Loss 5.7329
Iteration 381: Loss 5.5195
Iteration 382: Loss 5.8352
Iteration 383: Loss 5.8888
Iteration 384: Loss 6.0760
Iteration 385: Loss 6.0398
Iteration 386: Loss 5.7472
Iteration 387: Loss 5.7506
Iteration 388: Loss 5.6546
Iteration 389: Loss 5.7640
Iteration 390: Loss 5.3414
Iteration 391: Loss 5.7718
Iteration 392: Loss 6.1337
Iteration 393: Loss 5.6610
Iteration 394: Loss 5.6932
Iteration 395: Loss 5.6817
Iteration 396: Loss 5.6173
Iteration 397: Loss 5.7313
Iteration 398: Loss 5.7474
Iteration 399: Loss 5.3984
Iteration 400: Loss 5.7035
Iteration 401: Loss 5.8669
Iteration 402: Loss 6.1669
Iteration 403: Loss 6.0642
Iteration 404: Loss 5.4817
Iteration 405: Loss 5.2971
Iteration 406: Loss 5.8141
Iteration 407: Loss 5.6664
Iteration 408: Loss 5.8889
Iteration 409: Loss 5.9535
Iteration 410: Loss 5.7058
Iteration 411: Loss 5.9045
Iteration 412: Loss 5.9578
Iteration 413: Loss 5.9195
Iteration 414: Loss 6.3151
Iteration 415: Loss 6.0946
Iteration 416: Loss 5.4465
Iteration 417: Loss 5.9168
Iteration 418: Loss 5.8440
Iteration 419: Loss 5.9299
Iteration 420: Loss 5.8122
Iteration 421: Loss 5.8011
Iteration 422: Loss 5.8455
Iteration 423: Loss 6.0624
Iteration 424: Loss 5.5623
Iteration 425: Loss 6.0568
Iteration 426: Loss 5.6787
Iteration 427: Loss 5.7727
Iteration 428: Loss 5.8701
Iteration 429: Loss 5.4476
Iteration 430: Loss 5.6071
Iteration 431: Loss 5.7784
Iteration 432: Loss 5.3101
Iteration 433: Loss 5.8475
Iteration 434: Loss 5.4541
Iteration 435: Loss 5.7878
Iteration 436: Loss 5.9949
Iteration 437: Loss 5.9882
Iteration 438: Loss 5.8802
Iteration 439: Loss 5.4170
Iteration 440: Loss 5.8370
Iteration 441: Loss 5.8505
Iteration 442: Loss 5.7782
Iteration 443: Loss 5.9003
Iteration 444: Loss 5.6680
Iteration 445: Loss 5.9078
Iteration 446: Loss 5.7328
Iteration 447: Loss 6.0488
Iteration 448: Loss 5.9889
Iteration 449: Loss 5.9727
Iteration 450: Loss 6.0011
Iteration 451: Loss 5.4980
Iteration 452: Loss 5.7884
Iteration 453: Loss 5.8643
Iteration 454: Loss 5.7758
Iteration 455: Loss 6.0732
Iteration 456: Loss 6.0065
Iteration 457: Loss 5.8291
Iteration 458: Loss 5.6330
Iteration 459: Loss 5.9031
Iteration 460: Loss 5.7830
Iteration 461: Loss 5.9042
Iteration 462: Loss 5.6593
Iteration 463: Loss 5.3910
Iteration 464: Loss 5.8703
Iteration 465: Loss 5.6638
Iteration 466: Loss 5.9135
Iteration 467: Loss 5.9821
Iteration 468: Loss 5.4780
Iteration 469: Loss 5.5471
Iteration 470: Loss 5.9573
Iteration 471: Loss 5.7299
Iteration 472: Loss 5.7145
Iteration 473: Loss 5.7508
Iteration 474: Loss 5.4600
Iteration 475: Loss 5.7602
Iteration 476: Loss 5.8245
Iteration 477: Loss 5.7053
Iteration 478: Loss 5.7073
Iteration 479: Loss 5.9089
Iteration 480: Loss 5.8930
Iteration 481: Loss 5.7863
Iteration 482: Loss 5.7885
Iteration 483: Loss 5.8093
Iteration 484: Loss 5.9084
Iteration 485: Loss 5.9043
Iteration 486: Loss 5.5332
Iteration 487: Loss 5.9018
Iteration 488: Loss 5.6655
Iteration 489: Loss 5.8293
Iteration 490: Loss 5.5595
Iteration 491: Loss 5.7892
Iteration 492: Loss 5.8613
Iteration 493: Loss 5.2132
Iteration 494: Loss 5.5206
Iteration 495: Loss 5.5790
Iteration 496: Loss 6.0345
Iteration 497: Loss 5.8701
Iteration 498: Loss 5.8049
Iteration 499: Loss 5.6616
Step 500: Train Loss 5.7068, Val Loss 5.3418
Iteration 500: Loss 5.8903
Iteration 501: Loss 5.6914
Iteration 502: Loss 5.7648
Iteration 503: Loss 5.6524
Iteration 504: Loss 5.8016
Iteration 505: Loss 5.8929
Iteration 506: Loss 5.8938
Iteration 507: Loss 5.6954
Iteration 508: Loss 5.6448
Iteration 509: Loss 5.7194
Iteration 510: Loss 5.8338
Iteration 511: Loss 5.8316
Iteration 512: Loss 5.7591
Iteration 513: Loss 5.5553
Iteration 514: Loss 5.5861
Iteration 515: Loss 5.7947
Iteration 516: Loss 5.3810
Iteration 517: Loss 5.3595
Iteration 518: Loss 5.5905
Iteration 519: Loss 5.6317
Iteration 520: Loss 5.6249
Iteration 521: Loss 5.6125
Iteration 522: Loss 5.5932
Iteration 523: Loss 5.8924
Iteration 524: Loss 5.3990
Iteration 525: Loss 5.6801
Iteration 526: Loss 5.6631
Iteration 527: Loss 5.6738
Iteration 528: Loss 5.6448
Iteration 529: Loss 5.3024
Iteration 530: Loss 5.6864
Iteration 531: Loss 5.4632
Iteration 532: Loss 5.7597
Iteration 533: Loss 5.6227
Iteration 534: Loss 5.5971
Iteration 535: Loss 5.6876
Iteration 536: Loss 5.7508
Iteration 537: Loss 5.8279
Iteration 538: Loss 5.6160
Iteration 539: Loss 5.8868
Iteration 540: Loss 5.5615
Iteration 541: Loss 5.5534
Iteration 542: Loss 5.8749
Iteration 543: Loss 5.7720
Iteration 544: Loss 5.8313
Iteration 545: Loss 5.6556
Iteration 546: Loss 5.5508
Iteration 547: Loss 5.7140
Iteration 548: Loss 5.7218
Iteration 549: Loss 5.5724
Iteration 550: Loss 5.5341
Iteration 551: Loss 5.7769
Iteration 552: Loss 5.2819
Iteration 553: Loss 5.9268
Iteration 554: Loss 5.3182
Iteration 555: Loss 5.3483
Iteration 556: Loss 5.4718
Iteration 557: Loss 5.6187
Iteration 558: Loss 5.5794
Iteration 559: Loss 5.5356
Iteration 560: Loss 5.7775
Iteration 561: Loss 5.9596
Iteration 562: Loss 5.6168
Iteration 563: Loss 5.2581
Iteration 564: Loss 5.8201
Iteration 565: Loss 5.7699
Iteration 566: Loss 5.4494
Iteration 567: Loss 5.4891
Iteration 568: Loss 5.4241
Iteration 569: Loss 5.6108
Iteration 570: Loss 5.9199
Iteration 571: Loss 5.5345
Iteration 572: Loss 5.5504
Iteration 573: Loss 5.7323
Iteration 574: Loss 5.5476
Iteration 575: Loss 5.5520
Iteration 576: Loss 5.3294
Iteration 577: Loss 5.5408
Iteration 578: Loss 5.8894
Iteration 579: Loss 5.3455
Iteration 580: Loss 5.3470
Iteration 581: Loss 5.6522
Iteration 582: Loss 5.5267
Iteration 583: Loss 5.2727
Iteration 584: Loss 5.7927
Iteration 585: Loss 5.8570
Iteration 586: Loss 5.7268
Iteration 587: Loss 5.7490
Iteration 588: Loss 5.5492
Iteration 589: Loss 5.4149
Iteration 590: Loss 5.2706
Iteration 591: Loss 5.7813
Iteration 592: Loss 5.8794
Iteration 593: Loss 5.3499
Iteration 594: Loss 5.5800
Iteration 595: Loss 5.7040
Iteration 596: Loss 5.4595
Iteration 597: Loss 5.4802
Iteration 598: Loss 5.7836
Iteration 599: Loss 5.6968
Iteration 600: Loss 5.2939
Iteration 601: Loss 5.5940
Iteration 602: Loss 5.7877
Iteration 603: Loss 5.2368
Iteration 604: Loss 5.7088
Iteration 605: Loss 5.4188
Iteration 606: Loss 5.7950
Iteration 607: Loss 5.7711
Iteration 608: Loss 5.6238
Iteration 609: Loss 5.4473
Iteration 610: Loss 5.6463
Iteration 611: Loss 5.1486
Iteration 612: Loss 5.4915
Iteration 613: Loss 5.3632
Iteration 614: Loss 5.5121
Iteration 615: Loss 5.7390
Iteration 616: Loss 5.4217
Iteration 617: Loss 5.6307
Iteration 618: Loss 5.6970
Iteration 619: Loss 5.7292
Iteration 620: Loss 5.8277
Iteration 621: Loss 5.9018
Iteration 622: Loss 5.5269
Iteration 623: Loss 5.7616
Iteration 624: Loss 5.6806
Iteration 625: Loss 5.1227
Iteration 626: Loss 5.5163
Iteration 627: Loss 5.3461
Iteration 628: Loss 5.7069
Iteration 629: Loss 5.2609
Iteration 630: Loss 5.6359
Iteration 631: Loss 5.5213
Iteration 632: Loss 5.5217
Iteration 633: Loss 5.6121
Iteration 634: Loss 5.4862
Iteration 635: Loss 5.6495
Iteration 636: Loss 5.2024
Iteration 637: Loss 5.6529
Iteration 638: Loss 5.3647
Iteration 639: Loss 5.4296
Iteration 640: Loss 5.6742
Iteration 641: Loss 5.4725
Iteration 642: Loss 5.3679
Iteration 643: Loss 5.6943
Iteration 644: Loss 5.6684
Iteration 645: Loss 5.9585
Iteration 646: Loss 5.5705
Iteration 647: Loss 5.5707
Iteration 648: Loss 5.7409
Iteration 649: Loss 5.7685
Iteration 650: Loss 5.6270
Iteration 651: Loss 5.4303
Iteration 652: Loss 5.5495
Iteration 653: Loss 5.5334
Iteration 654: Loss 5.8123
Iteration 655: Loss 5.4358
Iteration 656: Loss 5.3590
Iteration 657: Loss 5.2358
Iteration 658: Loss 5.3862
Iteration 659: Loss 5.4128
Iteration 660: Loss 5.3672
Iteration 661: Loss 5.4616
Iteration 662: Loss 5.5329
Iteration 663: Loss 5.3901
Iteration 664: Loss 5.4454
Iteration 665: Loss 5.8389
Iteration 666: Loss 5.4199
Iteration 667: Loss 5.2431
Iteration 668: Loss 5.8860
Iteration 669: Loss 5.7505
Iteration 670: Loss 5.6818
Iteration 671: Loss 5.5699
Iteration 672: Loss 5.6773
Iteration 673: Loss 5.6715
Iteration 674: Loss 5.9418
Iteration 675: Loss 5.2360
Iteration 676: Loss 5.5946
Iteration 677: Loss 5.9225
Iteration 678: Loss 5.4628
Iteration 679: Loss 5.8014
Iteration 680: Loss 5.7004
Iteration 681: Loss 5.6966
Iteration 682: Loss 5.2782
Iteration 683: Loss 5.6330
Iteration 684: Loss 5.7280
Iteration 685: Loss 5.7876
Iteration 686: Loss 5.5214
Iteration 687: Loss 5.6180
Iteration 688: Loss 5.6957
Iteration 689: Loss 5.6881
Iteration 690: Loss 5.3729
Iteration 691: Loss 5.6800
Iteration 692: Loss 5.7450
Iteration 693: Loss 5.0386
Iteration 694: Loss 5.5365
Iteration 695: Loss 5.4605
Iteration 696: Loss 5.5017
Iteration 697: Loss 5.3826
Iteration 698: Loss 5.6114
Iteration 699: Loss 5.2997
Iteration 700: Loss 5.2922
Iteration 701: Loss 5.4081
Iteration 702: Loss 5.8846
Iteration 703: Loss 5.4839
Iteration 704: Loss 5.2974
Iteration 705: Loss 5.4763
Iteration 706: Loss 5.6962
Iteration 707: Loss 5.3186
Iteration 708: Loss 5.1237
Iteration 709: Loss 5.0732
Iteration 710: Loss 5.7435
Iteration 711: Loss 5.4864
Iteration 712: Loss 5.5810
Iteration 713: Loss 5.4121
Iteration 714: Loss 5.6537
Iteration 715: Loss 5.3157
Iteration 716: Loss 5.3858
Iteration 717: Loss 5.7448
Iteration 718: Loss 5.2801
Iteration 719: Loss 5.6101
Iteration 720: Loss 5.6087
Iteration 721: Loss 5.6218
Iteration 722: Loss 5.4270
Iteration 723: Loss 5.4200
Iteration 724: Loss 5.1089
Iteration 725: Loss 5.5788
Iteration 726: Loss 5.5977
Iteration 727: Loss 5.6252
Iteration 728: Loss 5.6236
Iteration 729: Loss 5.5303
Iteration 730: Loss 5.4610
Iteration 731: Loss 5.4097
Iteration 732: Loss 5.4742
Iteration 733: Loss 5.2249
Iteration 734: Loss 5.2792
Iteration 735: Loss 5.4975
Iteration 736: Loss 5.3673
Iteration 737: Loss 5.5909
Iteration 738: Loss 5.5359
Iteration 739: Loss 5.6705
Iteration 740: Loss 5.4484
Iteration 741: Loss 5.1978
Iteration 742: Loss 5.4551
Iteration 743: Loss 6.1378
Iteration 744: Loss 5.7970
Iteration 745: Loss 5.8272
Iteration 746: Loss 5.3743
Iteration 747: Loss 5.3057
Iteration 748: Loss 5.4607
Iteration 749: Loss 5.5012
Step 750: Train Loss 5.5255, Val Loss 5.1924
Iteration 750: Loss 5.1813
Iteration 751: Loss 5.3691
Iteration 752: Loss 5.5053
Iteration 753: Loss 5.1460
Iteration 754: Loss 5.7274
Iteration 755: Loss 5.2759
Iteration 756: Loss 5.5912
Iteration 757: Loss 5.0800
Iteration 758: Loss 5.2671
Iteration 759: Loss 5.5059
Iteration 760: Loss 5.3012
Iteration 761: Loss 5.2174
Iteration 762: Loss 5.4357
Iteration 763: Loss 5.5191
Iteration 764: Loss 5.3074
Iteration 765: Loss 5.4252
Iteration 766: Loss 5.4460
Iteration 767: Loss 5.5541
Iteration 768: Loss 5.4262
Iteration 769: Loss 5.5236
Iteration 770: Loss 5.4558
Iteration 771: Loss 5.2840
Iteration 772: Loss 5.5191
Iteration 773: Loss 5.6297
Iteration 774: Loss 5.4723
Iteration 775: Loss 5.3688
Iteration 776: Loss 5.5464
Iteration 777: Loss 5.5344
Iteration 778: Loss 5.5987
Iteration 779: Loss 5.4213
Iteration 780: Loss 5.4034
Iteration 781: Loss 5.3874
Iteration 782: Loss 5.4193
Iteration 783: Loss 5.5919
Iteration 784: Loss 5.5372
Iteration 785: Loss 5.4918
Iteration 786: Loss 5.3774
Iteration 787: Loss 5.4392
Iteration 788: Loss 5.3858
Iteration 789: Loss 5.3999
Iteration 790: Loss 5.4091
Iteration 791: Loss 5.5458
Iteration 792: Loss 5.6190
Iteration 793: Loss 5.7204
Iteration 794: Loss 5.7749
Iteration 795: Loss 5.2559
Iteration 796: Loss 5.6050
Iteration 797: Loss 5.6220
Iteration 798: Loss 5.3589
Iteration 799: Loss 5.4941
Iteration 800: Loss 5.6611
Iteration 801: Loss 5.2077
Iteration 802: Loss 5.5522
Iteration 803: Loss 5.8683
Iteration 804: Loss 5.3441
Iteration 805: Loss 5.3776
Iteration 806: Loss 5.3475
Iteration 807: Loss 5.1160
Iteration 808: Loss 5.5722
Iteration 809: Loss 5.4183
Iteration 810: Loss 5.3377
Iteration 811: Loss 5.5520
Iteration 812: Loss 5.2947
Iteration 813: Loss 5.5838
Iteration 814: Loss 5.4093
Iteration 815: Loss 5.3921
Iteration 816: Loss 5.5011
Iteration 817: Loss 5.3797
Iteration 818: Loss 5.3954
Iteration 819: Loss 5.5276
Iteration 820: Loss 5.4758
Iteration 821: Loss 5.0905
Iteration 822: Loss 5.3306
Iteration 823: Loss 5.4523
Iteration 824: Loss 5.5338
Iteration 825: Loss 5.3669
Iteration 826: Loss 5.3095
Iteration 827: Loss 5.6806
Iteration 828: Loss 5.1573
Iteration 829: Loss 5.6108
Iteration 830: Loss 5.4230
Iteration 831: Loss 5.5341
Iteration 832: Loss 5.5661
Iteration 833: Loss 5.6932
Iteration 834: Loss 5.3877
Iteration 835: Loss 5.4360
Iteration 836: Loss 5.5878
Iteration 837: Loss 5.6206
Iteration 838: Loss 5.5352
Iteration 839: Loss 5.5314
Iteration 840: Loss 5.7077
Iteration 841: Loss 5.7006
Iteration 842: Loss 5.1455
Iteration 843: Loss 5.3144
Iteration 844: Loss 5.5105
Iteration 845: Loss 5.4385
Iteration 846: Loss 5.5278
Iteration 847: Loss 5.4356
Iteration 848: Loss 5.1539
Iteration 849: Loss 5.4128
Iteration 850: Loss 5.5915
Iteration 851: Loss 5.3094
Iteration 852: Loss 5.4525
Iteration 853: Loss 5.2947
Iteration 854: Loss 5.4300
Iteration 855: Loss 5.4215
Iteration 856: Loss 5.3376
Iteration 857: Loss 5.4784
Iteration 858: Loss 5.6280
Iteration 859: Loss 5.1741
Iteration 860: Loss 5.4500
Iteration 861: Loss 5.3175
Iteration 862: Loss 5.1105
Iteration 863: Loss 5.4740
Iteration 864: Loss 5.5110
Iteration 865: Loss 5.2298
Iteration 866: Loss 5.3312
Iteration 867: Loss 5.3208
Iteration 868: Loss 5.3208
Iteration 869: Loss 5.2209
Iteration 870: Loss 5.7124
Iteration 871: Loss 5.4319
Iteration 872: Loss 5.5039
Iteration 873: Loss 5.5750
Iteration 874: Loss 5.4418
Iteration 875: Loss 5.0624
Iteration 876: Loss 5.6219
Iteration 877: Loss 5.8468
Iteration 878: Loss 5.5299
Iteration 879: Loss 5.2839
Iteration 880: Loss 5.4886
Iteration 881: Loss 5.3118
Iteration 882: Loss 5.3238
Iteration 883: Loss 5.3187
Iteration 884: Loss 5.4302
Iteration 885: Loss 5.4975
Iteration 886: Loss 5.4703
Iteration 887: Loss 5.2007
Iteration 888: Loss 5.4804
Iteration 889: Loss 5.6379
Iteration 890: Loss 5.5736
Iteration 891: Loss 5.1306
Iteration 892: Loss 5.6558
Iteration 893: Loss 5.5764
Iteration 894: Loss 5.3306
Iteration 895: Loss 5.3864
Iteration 896: Loss 5.2313
Iteration 897: Loss 5.5433
Iteration 898: Loss 5.3461
Iteration 899: Loss 5.3605
Iteration 900: Loss 5.5200
Iteration 901: Loss 5.3436
Iteration 902: Loss 5.4972
Iteration 903: Loss 5.1037
Iteration 904: Loss 5.6522
Iteration 905: Loss 5.5368
Iteration 906: Loss 5.7185
Iteration 907: Loss 4.7774
Iteration 908: Loss 5.1192
Iteration 909: Loss 5.2712
Iteration 910: Loss 5.1583
Iteration 911: Loss 5.4023
Iteration 912: Loss 5.3440
Iteration 913: Loss 5.1294
Iteration 914: Loss 5.5252
Iteration 915: Loss 5.2610
Iteration 916: Loss 5.4023
Iteration 917: Loss 5.6897
Iteration 918: Loss 5.4049
Iteration 919: Loss 5.5310
Iteration 920: Loss 5.6583
Iteration 921: Loss 5.5787
Iteration 922: Loss 4.8202
Iteration 923: Loss 5.2310
Iteration 924: Loss 5.0286
Iteration 925: Loss 5.2130
Iteration 926: Loss 5.2598
Iteration 927: Loss 5.4277
Iteration 928: Loss 5.4442
Iteration 929: Loss 5.2123
Iteration 930: Loss 5.2160
Iteration 931: Loss 5.2891
Iteration 932: Loss 5.1584
Iteration 933: Loss 5.3461
Iteration 934: Loss 5.2926
Iteration 935: Loss 5.2707
Iteration 936: Loss 5.1285
Iteration 937: Loss 4.9770
Iteration 938: Loss 5.6184
Iteration 939: Loss 5.4784
Iteration 940: Loss 5.0893
Iteration 941: Loss 5.1960
Iteration 942: Loss 5.3682
Iteration 943: Loss 5.4511
Iteration 944: Loss 5.2453
Iteration 945: Loss 5.6395
Iteration 946: Loss 4.9005
Iteration 947: Loss 5.4698
Iteration 948: Loss 5.2293
Iteration 949: Loss 5.5544
Iteration 950: Loss 5.3682
Iteration 951: Loss 5.3245
Iteration 952: Loss 5.2390
Iteration 953: Loss 5.4726
Iteration 954: Loss 5.4807
Iteration 955: Loss 5.6928
Iteration 956: Loss 5.3558
Iteration 957: Loss 5.2589
Iteration 958: Loss 5.5530
Iteration 959: Loss 5.6095
Iteration 960: Loss 5.5542
Iteration 961: Loss 5.3274
Iteration 962: Loss 5.1370
Iteration 963: Loss 5.4734
Iteration 964: Loss 5.1541
Iteration 965: Loss 5.5330
Iteration 966: Loss 5.1271
Iteration 967: Loss 5.2570
Iteration 968: Loss 5.1217
Iteration 969: Loss 5.3034
Iteration 970: Loss 5.3367
Iteration 971: Loss 5.2025
Iteration 972: Loss 5.4157
Iteration 973: Loss 5.2151
Iteration 974: Loss 5.3815
Iteration 975: Loss 5.3092
Iteration 976: Loss 5.1460
Iteration 977: Loss 5.5241
Iteration 978: Loss 5.2858
Iteration 979: Loss 5.4402
Iteration 980: Loss 5.1887
Iteration 981: Loss 5.2881
Iteration 982: Loss 5.2316
Iteration 983: Loss 5.4207
Iteration 984: Loss 4.9670
Iteration 985: Loss 5.3185
Iteration 986: Loss 5.1470
Iteration 987: Loss 5.1369
Iteration 988: Loss 5.2956
Iteration 989: Loss 5.3971
Iteration 990: Loss 5.5777
Iteration 991: Loss 5.5038
Iteration 992: Loss 5.2064
Iteration 993: Loss 5.2040
Iteration 994: Loss 5.4153
Iteration 995: Loss 5.5020
Iteration 996: Loss 5.5823
Iteration 997: Loss 5.4231
Iteration 998: Loss 5.4307
Iteration 999: Loss 5.4071
Step 1000: Train Loss 5.3654, Val Loss 5.1688
Iteration 1000: Loss 5.7270
Iteration 1001: Loss 5.5016
Iteration 1002: Loss 5.1848
Iteration 1003: Loss 5.0602
Iteration 1004: Loss 5.4337
Iteration 1005: Loss 5.5672
Iteration 1006: Loss 5.4000
Iteration 1007: Loss 5.4239
Iteration 1008: Loss 5.4326
Iteration 1009: Loss 5.2336
Iteration 1010: Loss 5.3068
Iteration 1011: Loss 4.9696
Iteration 1012: Loss 5.4150
Iteration 1013: Loss 5.2189
Iteration 1014: Loss 5.5830
Iteration 1015: Loss 5.4362
Iteration 1016: Loss 5.1414
Iteration 1017: Loss 5.5779
Iteration 1018: Loss 5.4489
Iteration 1019: Loss 5.4672
Iteration 1020: Loss 5.3554
Iteration 1021: Loss 5.4644
Iteration 1022: Loss 5.7195
Iteration 1023: Loss 5.1511
Iteration 1024: Loss 5.3804
Iteration 1025: Loss 5.4116
Iteration 1026: Loss 5.7151
Iteration 1027: Loss 5.4651
Iteration 1028: Loss 5.3415
Iteration 1029: Loss 5.0237
Iteration 1030: Loss 5.0384
Iteration 1031: Loss 5.0149
Iteration 1032: Loss 5.2243
Iteration 1033: Loss 5.5800
Iteration 1034: Loss 5.5957
Iteration 1035: Loss 5.2892
Iteration 1036: Loss 5.4848
Iteration 1037: Loss 5.2368
Iteration 1038: Loss 5.4236
Iteration 1039: Loss 5.5641
Iteration 1040: Loss 5.0591
Iteration 1041: Loss 5.3638
Iteration 1042: Loss 5.4178
Iteration 1043: Loss 5.4767
Iteration 1044: Loss 5.6886
Iteration 1045: Loss 5.1593
Iteration 1046: Loss 5.1519
Iteration 1047: Loss 5.3283
Iteration 1048: Loss 5.4441
Iteration 1049: Loss 5.7457
Iteration 1050: Loss 5.1981
Iteration 1051: Loss 5.3458
Iteration 1052: Loss 5.3670
Iteration 1053: Loss 4.8858
Iteration 1054: Loss 5.2257
Iteration 1055: Loss 5.0167
Iteration 1056: Loss 5.1548
Iteration 1057: Loss 5.8058
Iteration 1058: Loss 4.8874
Iteration 1059: Loss 4.9321
Iteration 1060: Loss 5.0771
Iteration 1061: Loss 5.0267
Iteration 1062: Loss 5.4131
Iteration 1063: Loss 5.2548
Iteration 1064: Loss 5.0115
Iteration 1065: Loss 5.0338
Iteration 1066: Loss 5.0584
Iteration 1067: Loss 5.4584
Iteration 1068: Loss 5.3921
Iteration 1069: Loss 5.0846
Iteration 1070: Loss 5.0945
Iteration 1071: Loss 5.4476
Iteration 1072: Loss 5.7117
Iteration 1073: Loss 5.3513
Iteration 1074: Loss 5.0277
Iteration 1075: Loss 5.3185
Iteration 1076: Loss 5.1831
Iteration 1077: Loss 5.2589
Iteration 1078: Loss 4.9865
Iteration 1079: Loss 5.4787
Iteration 1080: Loss 5.1480
Iteration 1081: Loss 4.8791
Iteration 1082: Loss 5.1403
Iteration 1083: Loss 5.1155
Iteration 1084: Loss 5.5568
Iteration 1085: Loss 4.9807
Iteration 1086: Loss 5.3035
Iteration 1087: Loss 5.3458
Iteration 1088: Loss 5.4392
Iteration 1089: Loss 4.9660
Iteration 1090: Loss 5.7978
Iteration 1091: Loss 5.1011
Iteration 1092: Loss 5.2981
Iteration 1093: Loss 5.1246
Iteration 1094: Loss 4.9422
Iteration 1095: Loss 5.5796
Iteration 1096: Loss 5.4772
Iteration 1097: Loss 5.2259
Iteration 1098: Loss 5.2765
Iteration 1099: Loss 5.4198
Iteration 1100: Loss 5.4017
Iteration 1101: Loss 5.6203
Iteration 1102: Loss 5.6261
Iteration 1103: Loss 5.4772
Iteration 1104: Loss 5.3993
Iteration 1105: Loss 5.3014
Iteration 1106: Loss 5.3685
Iteration 1107: Loss 5.0897
Iteration 1108: Loss 5.1582
Iteration 1109: Loss 5.1715
Iteration 1110: Loss 5.1985
Iteration 1111: Loss 5.4077
Iteration 1112: Loss 5.3599
Iteration 1113: Loss 5.2171
Iteration 1114: Loss 5.2618
Iteration 1115: Loss 5.2797
Iteration 1116: Loss 5.3800
Iteration 1117: Loss 5.0692
Iteration 1118: Loss 5.3379
Iteration 1119: Loss 5.3775
Iteration 1120: Loss 4.8368
Iteration 1121: Loss 5.1222
Iteration 1122: Loss 4.9406
Iteration 1123: Loss 5.0371
Iteration 1124: Loss 5.3048
Iteration 1125: Loss 5.0934
Iteration 1126: Loss 5.4586
Iteration 1127: Loss 5.4531
Iteration 1128: Loss 5.3780
Iteration 1129: Loss 5.2100
Iteration 1130: Loss 5.4790
Iteration 1131: Loss 5.0005
Iteration 1132: Loss 4.8787
Iteration 1133: Loss 5.2338
Iteration 1134: Loss 5.4063
Iteration 1135: Loss 5.3156
Iteration 1136: Loss 4.8663
Iteration 1137: Loss 5.1349
Iteration 1138: Loss 5.0890
Iteration 1139: Loss 5.5188
Iteration 1140: Loss 5.4505
Iteration 1141: Loss 5.6030
Iteration 1142: Loss 5.3119
Iteration 1143: Loss 5.6183
Iteration 1144: Loss 5.1949
Iteration 1145: Loss 4.9077
Iteration 1146: Loss 5.3693
Iteration 1147: Loss 4.7168
Iteration 1148: Loss 5.0958
Iteration 1149: Loss 5.2535
Iteration 1150: Loss 5.3609
Iteration 1151: Loss 5.2849
Iteration 1152: Loss 4.9861
Iteration 1153: Loss 5.3234
Iteration 1154: Loss 5.8356
Iteration 1155: Loss 5.5665
Iteration 1156: Loss 5.0856
Iteration 1157: Loss 5.3454
Iteration 1158: Loss 5.1288
Iteration 1159: Loss 4.8863
Iteration 1160: Loss 5.0545
Iteration 1161: Loss 4.9347
Iteration 1162: Loss 5.3517
Iteration 1163: Loss 5.0072
Iteration 1164: Loss 5.2149
Iteration 1165: Loss 5.2737
Iteration 1166: Loss 5.2353
Iteration 1167: Loss 5.2065
Iteration 1168: Loss 5.3191
Iteration 1169: Loss 5.5318
Iteration 1170: Loss 5.1189
Iteration 1171: Loss 5.0838
Iteration 1172: Loss 5.1956
Iteration 1173: Loss 5.3763
Iteration 1174: Loss 5.1938
Iteration 1175: Loss 5.3691
Iteration 1176: Loss 5.1432
Iteration 1177: Loss 5.2188
Iteration 1178: Loss 5.4643
Iteration 1179: Loss 4.9251
Iteration 1180: Loss 4.9481
Iteration 1181: Loss 5.2777
Iteration 1182: Loss 5.0928
Iteration 1183: Loss 5.1219
Iteration 1184: Loss 5.4397
Iteration 1185: Loss 5.4196
Iteration 1186: Loss 5.4415
Iteration 1187: Loss 5.2357
Iteration 1188: Loss 5.3430
Iteration 1189: Loss 5.1281
Iteration 1190: Loss 4.9645
Iteration 1191: Loss 5.2341
Iteration 1192: Loss 5.2363
Iteration 1193: Loss 5.4662
Iteration 1194: Loss 5.2293
Iteration 1195: Loss 5.3470
Iteration 1196: Loss 5.1847
Iteration 1197: Loss 4.9674
Iteration 1198: Loss 5.4428
Iteration 1199: Loss 5.5936
Iteration 1200: Loss 5.0901
Iteration 1201: Loss 5.0851
Iteration 1202: Loss 5.3336
Iteration 1203: Loss 4.8693
Iteration 1204: Loss 5.5219
Iteration 1205: Loss 5.1526
Iteration 1206: Loss 5.8315
Iteration 1207: Loss 5.1513
Iteration 1208: Loss 5.0058
Iteration 1209: Loss 4.8705
Iteration 1210: Loss 4.7573
Iteration 1211: Loss 5.3399
Iteration 1212: Loss 4.8513
Iteration 1213: Loss 5.3931
Iteration 1214: Loss 5.4378
Iteration 1215: Loss 5.2041
Iteration 1216: Loss 5.1614
Iteration 1217: Loss 5.1834
Iteration 1218: Loss 4.9865
Iteration 1219: Loss 5.1876
Iteration 1220: Loss 5.3655
Iteration 1221: Loss 5.0754
Iteration 1222: Loss 5.1084
Iteration 1223: Loss 4.8937
Iteration 1224: Loss 5.2998
Iteration 1225: Loss 4.5157
Iteration 1226: Loss 4.9545
Iteration 1227: Loss 5.0535
Iteration 1228: Loss 5.1939
Iteration 1229: Loss 5.3691
Iteration 1230: Loss 4.9391
Iteration 1231: Loss 5.1446
Iteration 1232: Loss 4.9679
Iteration 1233: Loss 5.2780
Iteration 1234: Loss 5.0856
Iteration 1235: Loss 5.0796
Iteration 1236: Loss 5.3875
Iteration 1237: Loss 5.1716
Iteration 1238: Loss 5.1411
Iteration 1239: Loss 5.0955
Iteration 1240: Loss 5.2915
Iteration 1241: Loss 5.6548
Iteration 1242: Loss 5.4406
Iteration 1243: Loss 5.0190
Iteration 1244: Loss 5.0843
Iteration 1245: Loss 4.9603
Iteration 1246: Loss 5.0906
Iteration 1247: Loss 5.0202
Iteration 1248: Loss 5.2939
Iteration 1249: Loss 5.2619
Step 1250: Train Loss 5.2590, Val Loss 5.0344
Iteration 1250: Loss 5.4794
Iteration 1251: Loss 5.2637
Iteration 1252: Loss 5.2461
Iteration 1253: Loss 5.0048
Iteration 1254: Loss 4.9951
Iteration 1255: Loss 5.2566
Iteration 1256: Loss 5.3369
Iteration 1257: Loss 5.2196
Iteration 1258: Loss 5.3624
Iteration 1259: Loss 5.5232
Iteration 1260: Loss 5.1085
Iteration 1261: Loss 5.2991
Iteration 1262: Loss 5.3392
Iteration 1263: Loss 4.8615
Iteration 1264: Loss 5.1578
Iteration 1265: Loss 5.2342
Iteration 1266: Loss 5.0076
Iteration 1267: Loss 5.2297
Iteration 1268: Loss 5.3593
Iteration 1269: Loss 5.1528
Iteration 1270: Loss 5.5241
Iteration 1271: Loss 5.2941
Iteration 1272: Loss 5.2915
Iteration 1273: Loss 5.2351
Iteration 1274: Loss 5.0788
Iteration 1275: Loss 5.2471
Iteration 1276: Loss 5.0474
Iteration 1277: Loss 5.1958
Iteration 1278: Loss 5.3197
Iteration 1279: Loss 5.0913
Iteration 1280: Loss 5.3305
Iteration 1281: Loss 5.0985
Iteration 1282: Loss 5.2053
Iteration 1283: Loss 5.2056
Iteration 1284: Loss 5.3736
Iteration 1285: Loss 5.3699
Iteration 1286: Loss 4.9483
Iteration 1287: Loss 5.0477
Iteration 1288: Loss 5.1825
Iteration 1289: Loss 5.3553
Iteration 1290: Loss 4.9846
Iteration 1291: Loss 5.2895
Iteration 1292: Loss 5.0812
Iteration 1293: Loss 5.1859
Iteration 1294: Loss 5.4351
Iteration 1295: Loss 5.2811
Iteration 1296: Loss 5.0247
Iteration 1297: Loss 5.1559
Iteration 1298: Loss 5.2564
Iteration 1299: Loss 4.9601
Iteration 1300: Loss 5.3191
Iteration 1301: Loss 5.0171
Iteration 1302: Loss 4.7494
Iteration 1303: Loss 5.2139
Iteration 1304: Loss 5.5380
Iteration 1305: Loss 5.3288
Iteration 1306: Loss 5.3542
Iteration 1307: Loss 4.9409
Iteration 1308: Loss 5.2338
Iteration 1309: Loss 4.9700
Iteration 1310: Loss 5.5557
Iteration 1311: Loss 5.0875
Iteration 1312: Loss 5.0244
Iteration 1313: Loss 4.9997
Iteration 1314: Loss 5.2993
Iteration 1315: Loss 5.3092
Iteration 1316: Loss 5.2630
Iteration 1317: Loss 5.1867
Iteration 1318: Loss 5.3086
Iteration 1319: Loss 5.2427
Iteration 1320: Loss 4.9251
Iteration 1321: Loss 4.9701
Iteration 1322: Loss 5.2116
Iteration 1323: Loss 5.1804
Iteration 1324: Loss 5.3074
Iteration 1325: Loss 5.3122
Iteration 1326: Loss 5.1446
Iteration 1327: Loss 5.3049
Iteration 1328: Loss 4.7566
Iteration 1329: Loss 5.1972
Iteration 1330: Loss 5.0468
Iteration 1331: Loss 5.2790
Iteration 1332: Loss 5.0972
Iteration 1333: Loss 4.7501
Iteration 1334: Loss 5.3362
Iteration 1335: Loss 4.7460
Iteration 1336: Loss 4.8689
Iteration 1337: Loss 5.0448
Iteration 1338: Loss 5.3268
Iteration 1339: Loss 5.1026
Iteration 1340: Loss 5.1579
Iteration 1341: Loss 5.1485
Iteration 1342: Loss 5.1075
Iteration 1343: Loss 5.0201
Iteration 1344: Loss 5.2193
Iteration 1345: Loss 5.5542
Iteration 1346: Loss 5.2350
Iteration 1347: Loss 5.5515
Iteration 1348: Loss 5.2927
Iteration 1349: Loss 5.4263
Iteration 1350: Loss 5.1419
Iteration 1351: Loss 5.0205
Iteration 1352: Loss 5.1305
Iteration 1353: Loss 5.1021
Iteration 1354: Loss 5.2944
Iteration 1355: Loss 5.0158
Iteration 1356: Loss 5.0687
Iteration 1357: Loss 5.2487
Iteration 1358: Loss 4.7964
Iteration 1359: Loss 5.1603
Iteration 1360: Loss 5.0275
Iteration 1361: Loss 5.2727
Iteration 1362: Loss 4.9316
Iteration 1363: Loss 5.1495
Iteration 1364: Loss 5.0009
Iteration 1365: Loss 5.1849
Iteration 1366: Loss 5.3119
Iteration 1367: Loss 5.4627
Iteration 1368: Loss 4.5397
Iteration 1369: Loss 5.6720
Iteration 1370: Loss 4.8372
Iteration 1371: Loss 5.0846
Iteration 1372: Loss 5.0518
Iteration 1373: Loss 4.9423
Iteration 1374: Loss 5.0893
Iteration 1375: Loss 5.6594
Iteration 1376: Loss 5.3222
Iteration 1377: Loss 5.0143
Iteration 1378: Loss 5.2077
Iteration 1379: Loss 5.1946
Iteration 1380: Loss 5.1715
Iteration 1381: Loss 5.0932
Iteration 1382: Loss 5.0412
Iteration 1383: Loss 5.4362
Iteration 1384: Loss 4.9907
Iteration 1385: Loss 5.0045
Iteration 1386: Loss 5.3268
Iteration 1387: Loss 4.9647
Iteration 1388: Loss 4.7585
Iteration 1389: Loss 4.8772
Iteration 1390: Loss 5.0498
Iteration 1391: Loss 4.9735
Iteration 1392: Loss 4.9972
Iteration 1393: Loss 4.8101
Iteration 1394: Loss 5.0865
Iteration 1395: Loss 5.4554
Iteration 1396: Loss 5.3269
Iteration 1397: Loss 5.2605
Iteration 1398: Loss 4.9846
Iteration 1399: Loss 4.9025
Iteration 1400: Loss 5.0905
Iteration 1401: Loss 5.1954
Iteration 1402: Loss 5.0854
Iteration 1403: Loss 5.3194
Iteration 1404: Loss 5.1483
Iteration 1405: Loss 4.7917
Iteration 1406: Loss 5.4891
Iteration 1407: Loss 4.9363
Iteration 1408: Loss 5.0321
Iteration 1409: Loss 5.0380
Iteration 1410: Loss 5.4791
Iteration 1411: Loss 5.4447
Iteration 1412: Loss 5.3052
Iteration 1413: Loss 5.2239
Iteration 1414: Loss 5.3045
Iteration 1415: Loss 5.4625
Iteration 1416: Loss 5.2486
Iteration 1417: Loss 5.1612
Iteration 1418: Loss 5.2116
Iteration 1419: Loss 5.1807
Iteration 1420: Loss 5.2281
Iteration 1421: Loss 5.1058
Iteration 1422: Loss 5.0931
Iteration 1423: Loss 5.0155
Iteration 1424: Loss 5.3947
Iteration 1425: Loss 5.3354
Iteration 1426: Loss 5.2171
Iteration 1427: Loss 5.4454
Iteration 1428: Loss 5.0591
Iteration 1429: Loss 5.3296
Iteration 1430: Loss 5.0765
Iteration 1431: Loss 5.5000
Iteration 1432: Loss 5.1009
Iteration 1433: Loss 4.9018
Iteration 1434: Loss 5.0334
Iteration 1435: Loss 4.8472
Iteration 1436: Loss 5.4291
Iteration 1437: Loss 5.1245
Iteration 1438: Loss 5.1120
Iteration 1439: Loss 5.0232
Iteration 1440: Loss 5.2731
Iteration 1441: Loss 5.0006
Iteration 1442: Loss 5.4087
Iteration 1443: Loss 5.0043
Iteration 1444: Loss 5.3493
Iteration 1445: Loss 4.9598
Iteration 1446: Loss 5.0055
Iteration 1447: Loss 5.0012
Iteration 1448: Loss 4.9368
Iteration 1449: Loss 5.4098
Iteration 1450: Loss 5.2008
Iteration 1451: Loss 5.4841
Iteration 1452: Loss 5.2806
Iteration 1453: Loss 4.8311
Iteration 1454: Loss 4.7634
Iteration 1455: Loss 5.0874
Iteration 1456: Loss 5.2231
Iteration 1457: Loss 5.0504
Iteration 1458: Loss 5.3564
Iteration 1459: Loss 4.9600
Iteration 1460: Loss 5.3082
Iteration 1461: Loss 4.8309
Iteration 1462: Loss 5.0395
Iteration 1463: Loss 4.9224
Iteration 1464: Loss 5.2081
Iteration 1465: Loss 4.7771
Iteration 1466: Loss 5.3701
Iteration 1467: Loss 4.9178
Iteration 1468: Loss 5.1433
Iteration 1469: Loss 5.1257
Iteration 1470: Loss 5.4338
Iteration 1471: Loss 5.0312
Iteration 1472: Loss 4.9627
Iteration 1473: Loss 5.1716
Iteration 1474: Loss 5.3019
Iteration 1475: Loss 5.0559
Iteration 1476: Loss 5.4023
Iteration 1477: Loss 5.1477
Iteration 1478: Loss 5.2414
Iteration 1479: Loss 5.0935
Iteration 1480: Loss 5.2220
Iteration 1481: Loss 4.6176
Iteration 1482: Loss 5.4051
Iteration 1483: Loss 4.7595
Iteration 1484: Loss 5.2139
Iteration 1485: Loss 5.2026
Iteration 1486: Loss 5.3006
Iteration 1487: Loss 5.3094
Iteration 1488: Loss 4.8145
Iteration 1489: Loss 5.0319
Iteration 1490: Loss 4.9540
Iteration 1491: Loss 4.7865
Iteration 1492: Loss 5.5018
Iteration 1493: Loss 4.5390
Iteration 1494: Loss 4.9005
Iteration 1495: Loss 5.1439
Iteration 1496: Loss 5.0877
Iteration 1497: Loss 4.9861
Iteration 1498: Loss 5.2652
Iteration 1499: Loss 5.1539
Step 1500: Train Loss 5.1115, Val Loss 4.9417
Iteration 1500: Loss 5.1093
Iteration 1501: Loss 5.4550
Iteration 1502: Loss 5.1792
Iteration 1503: Loss 5.1285
Iteration 1504: Loss 5.1099
Iteration 1505: Loss 5.1120
Iteration 1506: Loss 5.4007
Iteration 1507: Loss 5.2285
Iteration 1508: Loss 4.8392
Iteration 1509: Loss 5.0240
Iteration 1510: Loss 5.1675
Iteration 1511: Loss 4.9700
Iteration 1512: Loss 5.1718
Iteration 1513: Loss 5.1922
Iteration 1514: Loss 5.5830
Iteration 1515: Loss 5.2543
Iteration 1516: Loss 5.3305
Iteration 1517: Loss 4.7139
Iteration 1518: Loss 5.2682
Iteration 1519: Loss 5.3163
Iteration 1520: Loss 5.2386
Iteration 1521: Loss 5.3077
Iteration 1522: Loss 4.8126
Iteration 1523: Loss 4.7126
Iteration 1524: Loss 5.1818
Iteration 1525: Loss 5.1192
Iteration 1526: Loss 5.1849
Iteration 1527: Loss 5.0316
Iteration 1528: Loss 5.4863
Iteration 1529: Loss 5.2092
Iteration 1530: Loss 4.9643
Iteration 1531: Loss 5.0194
Iteration 1532: Loss 5.0611
Iteration 1533: Loss 4.7720
Iteration 1534: Loss 4.9608
Iteration 1535: Loss 4.9983
Iteration 1536: Loss 4.9608
Iteration 1537: Loss 4.7948
Iteration 1538: Loss 5.0835
Iteration 1539: Loss 5.3449
Iteration 1540: Loss 5.3076
Iteration 1541: Loss 5.0085
Iteration 1542: Loss 5.1707
Iteration 1543: Loss 5.1401
Iteration 1544: Loss 5.3882
Iteration 1545: Loss 5.2253
Iteration 1546: Loss 5.3135
Iteration 1547: Loss 5.2262
Iteration 1548: Loss 5.1646
Iteration 1549: Loss 4.8887
Iteration 1550: Loss 5.0416
Iteration 1551: Loss 4.9205
Iteration 1552: Loss 5.0988
Iteration 1553: Loss 4.9854
Iteration 1554: Loss 5.3471
Iteration 1555: Loss 5.1669
Iteration 1556: Loss 5.1480
Iteration 1557: Loss 5.4453
Iteration 1558: Loss 5.5037
Iteration 1559: Loss 5.3371
Iteration 1560: Loss 5.2920
Iteration 1561: Loss 5.2501
Iteration 1562: Loss 5.1968
Iteration 1563: Loss 4.9910
Iteration 1564: Loss 5.2969
Iteration 1565: Loss 5.2672
Iteration 1566: Loss 5.1198
Iteration 1567: Loss 4.8867
Iteration 1568: Loss 5.3221
Iteration 1569: Loss 5.0080
Iteration 1570: Loss 5.3688
Iteration 1571: Loss 5.1053
Iteration 1572: Loss 4.8266
Iteration 1573: Loss 5.2596
Iteration 1574: Loss 5.1213
Iteration 1575: Loss 5.0699
Iteration 1576: Loss 5.2048
Iteration 1577: Loss 5.1074
Iteration 1578: Loss 5.1763
Iteration 1579: Loss 4.8973
Iteration 1580: Loss 4.7453
Iteration 1581: Loss 5.2065
Iteration 1582: Loss 5.3214
Iteration 1583: Loss 5.3566
Iteration 1584: Loss 5.1815
Iteration 1585: Loss 5.1900
Iteration 1586: Loss 5.2409
Iteration 1587: Loss 5.0793
Iteration 1588: Loss 5.1653
Iteration 1589: Loss 5.4559
Iteration 1590: Loss 4.8901
Iteration 1591: Loss 5.2945
Iteration 1592: Loss 4.8068
Iteration 1593: Loss 4.8369
Iteration 1594: Loss 4.8309
Iteration 1595: Loss 5.1850
Iteration 1596: Loss 4.9775
Iteration 1597: Loss 5.0373
Iteration 1598: Loss 5.0328
Iteration 1599: Loss 4.7552
Iteration 1600: Loss 5.1342
Iteration 1601: Loss 5.1701
Iteration 1602: Loss 5.1764
Iteration 1603: Loss 5.4303
Iteration 1604: Loss 5.1359
Iteration 1605: Loss 4.9116
Iteration 1606: Loss 5.0714
Iteration 1607: Loss 5.2221
Iteration 1608: Loss 5.1336
Iteration 1609: Loss 5.0725
Iteration 1610: Loss 4.8247
Iteration 1611: Loss 5.5655
Iteration 1612: Loss 5.0813
Iteration 1613: Loss 5.0045
Iteration 1614: Loss 4.9429
Iteration 1615: Loss 4.9831
Iteration 1616: Loss 4.8423
Iteration 1617: Loss 5.2904
Iteration 1618: Loss 4.9549
Iteration 1619: Loss 5.0203
Iteration 1620: Loss 5.2870
Iteration 1621: Loss 5.0593
Iteration 1622: Loss 5.2564
Iteration 1623: Loss 5.1573
Iteration 1624: Loss 5.2367
Iteration 1625: Loss 5.0045
Iteration 1626: Loss 5.0411
Iteration 1627: Loss 5.1916
Iteration 1628: Loss 5.0164
Iteration 1629: Loss 5.0812
Iteration 1630: Loss 5.0259
Iteration 1631: Loss 5.0270
Iteration 1632: Loss 5.1158
Iteration 1633: Loss 5.0323
Iteration 1634: Loss 5.1745
Iteration 1635: Loss 5.1233
Iteration 1636: Loss 5.1422
Iteration 1637: Loss 4.8993
Iteration 1638: Loss 4.9959
Iteration 1639: Loss 4.8889
Iteration 1640: Loss 5.0047
Iteration 1641: Loss 5.2155
Iteration 1642: Loss 5.2483
Iteration 1643: Loss 5.3455
Iteration 1644: Loss 5.0855
Iteration 1645: Loss 5.4208
Iteration 1646: Loss 5.0372
Iteration 1647: Loss 5.1360
Iteration 1648: Loss 4.9920
Iteration 1649: Loss 5.1181
Iteration 1650: Loss 4.8994
Iteration 1651: Loss 5.0195
Iteration 1652: Loss 5.1655
Iteration 1653: Loss 5.6062
Iteration 1654: Loss 5.1596
Iteration 1655: Loss 5.5041
Iteration 1656: Loss 4.6792
Iteration 1657: Loss 4.8074
Iteration 1658: Loss 5.3932
Iteration 1659: Loss 5.3989
Iteration 1660: Loss 5.1177
Iteration 1661: Loss 4.9118
Iteration 1662: Loss 5.2322
Iteration 1663: Loss 4.8655
Iteration 1664: Loss 5.4670
Iteration 1665: Loss 5.0856
Iteration 1666: Loss 5.1015
Iteration 1667: Loss 5.2305
Iteration 1668: Loss 4.9763
Iteration 1669: Loss 5.4733
Iteration 1670: Loss 5.3376
Iteration 1671: Loss 5.1028
Iteration 1672: Loss 5.2798
Iteration 1673: Loss 5.4217
Iteration 1674: Loss 5.2202
Iteration 1675: Loss 5.0367
Iteration 1676: Loss 5.2033
Iteration 1677: Loss 5.0475
Iteration 1678: Loss 5.2557
Iteration 1679: Loss 5.0252
Iteration 1680: Loss 5.2337
Iteration 1681: Loss 4.7256
Iteration 1682: Loss 5.3462
Iteration 1683: Loss 5.0996
Iteration 1684: Loss 4.8957
Iteration 1685: Loss 5.2046
Iteration 1686: Loss 5.1366
Iteration 1687: Loss 5.1298
Iteration 1688: Loss 4.5741
Iteration 1689: Loss 5.0752
Iteration 1690: Loss 5.4918
Iteration 1691: Loss 5.1724
Iteration 1692: Loss 4.9376
Iteration 1693: Loss 5.1853
Iteration 1694: Loss 4.7970
Iteration 1695: Loss 5.2122
Iteration 1696: Loss 5.2355
Iteration 1697: Loss 5.4013
Iteration 1698: Loss 4.8793
Iteration 1699: Loss 5.0266
Iteration 1700: Loss 5.3752
Iteration 1701: Loss 4.9838
Iteration 1702: Loss 4.8538
Iteration 1703: Loss 5.4094
Iteration 1704: Loss 4.5449
Iteration 1705: Loss 5.0978
Iteration 1706: Loss 4.8121
Iteration 1707: Loss 4.9320
Iteration 1708: Loss 4.8689
Iteration 1709: Loss 4.7965
Iteration 1710: Loss 5.0322
Iteration 1711: Loss 5.0373
Iteration 1712: Loss 5.3121
Iteration 1713: Loss 5.3062
Iteration 1714: Loss 4.8938
Iteration 1715: Loss 4.4299
Iteration 1716: Loss 5.3744
Iteration 1717: Loss 5.3204
Iteration 1718: Loss 5.0437
Iteration 1719: Loss 5.2170
Iteration 1720: Loss 5.2377
Iteration 1721: Loss 5.2084
Iteration 1722: Loss 5.1821
Iteration 1723: Loss 4.5827
Iteration 1724: Loss 5.0897
Iteration 1725: Loss 5.4054
Iteration 1726: Loss 5.4163
Iteration 1727: Loss 4.8906
Iteration 1728: Loss 4.8345
Iteration 1729: Loss 4.9488
Iteration 1730: Loss 4.9534
Iteration 1731: Loss 4.9281
Iteration 1732: Loss 4.8731
Iteration 1733: Loss 4.9073
Iteration 1734: Loss 5.0745
Iteration 1735: Loss 5.2330
Iteration 1736: Loss 5.0824
Iteration 1737: Loss 5.3436
Iteration 1738: Loss 5.3100
Iteration 1739: Loss 5.4556
Iteration 1740: Loss 4.8796
Iteration 1741: Loss 5.1427
Iteration 1742: Loss 5.0856
Iteration 1743: Loss 5.2060
Iteration 1744: Loss 5.3481
Iteration 1745: Loss 4.4986
Iteration 1746: Loss 4.8971
Iteration 1747: Loss 5.2095
Iteration 1748: Loss 4.9921
Iteration 1749: Loss 5.3966
Step 1750: Train Loss 5.0455, Val Loss 4.9713
Iteration 1750: Loss 5.1850
Iteration 1751: Loss 5.0196
Iteration 1752: Loss 5.0197
Iteration 1753: Loss 5.0446
Iteration 1754: Loss 4.9649
Iteration 1755: Loss 4.9015
Iteration 1756: Loss 4.9452
Iteration 1757: Loss 5.1997
Iteration 1758: Loss 4.7663
Iteration 1759: Loss 5.0228
Iteration 1760: Loss 5.2733
Iteration 1761: Loss 4.9041
Iteration 1762: Loss 5.4022
Iteration 1763: Loss 4.8199
Iteration 1764: Loss 5.0190
Iteration 1765: Loss 5.3656
Iteration 1766: Loss 5.2148
Iteration 1767: Loss 5.0395
Iteration 1768: Loss 4.9567
Iteration 1769: Loss 4.7531
Iteration 1770: Loss 4.9950
Iteration 1771: Loss 5.2086
Iteration 1772: Loss 5.2454
Iteration 1773: Loss 4.9258
Iteration 1774: Loss 5.2499
Iteration 1775: Loss 5.4167
Iteration 1776: Loss 4.9951
Iteration 1777: Loss 5.0367
Iteration 1778: Loss 5.1845
Iteration 1779: Loss 5.1763
Iteration 1780: Loss 5.2836
Iteration 1781: Loss 5.1125
Iteration 1782: Loss 5.0982
Iteration 1783: Loss 5.1947
Iteration 1784: Loss 5.1343
Iteration 1785: Loss 4.8677
Iteration 1786: Loss 5.0526
Iteration 1787: Loss 5.2863
Iteration 1788: Loss 5.1635
Iteration 1789: Loss 4.9809
Iteration 1790: Loss 5.3222
Iteration 1791: Loss 5.0883
Iteration 1792: Loss 5.0310
Iteration 1793: Loss 4.8731
Iteration 1794: Loss 5.0751
Iteration 1795: Loss 5.0098
Iteration 1796: Loss 5.0914
Iteration 1797: Loss 4.9671
Iteration 1798: Loss 4.7970
Iteration 1799: Loss 5.2630
Iteration 1800: Loss 4.8268
Iteration 1801: Loss 5.1427
Iteration 1802: Loss 5.0211
Iteration 1803: Loss 4.8355
Iteration 1804: Loss 4.8693
Iteration 1805: Loss 5.2134
Iteration 1806: Loss 4.8823
Iteration 1807: Loss 5.0953
Iteration 1808: Loss 5.3314
Iteration 1809: Loss 5.3983
Iteration 1810: Loss 5.1100
Iteration 1811: Loss 5.1415
Iteration 1812: Loss 4.9402
Iteration 1813: Loss 5.0330
Iteration 1814: Loss 5.0855
Iteration 1815: Loss 5.2131
Iteration 1816: Loss 4.9567
Iteration 1817: Loss 5.4675
Iteration 1818: Loss 5.1535
Iteration 1819: Loss 5.0848
Iteration 1820: Loss 5.0892
Iteration 1821: Loss 5.4682
Iteration 1822: Loss 4.9427
Iteration 1823: Loss 5.3419
Iteration 1824: Loss 5.2042
Iteration 1825: Loss 5.1071
Iteration 1826: Loss 5.0979
Iteration 1827: Loss 5.2697
Iteration 1828: Loss 5.1335
Iteration 1829: Loss 5.0792
Iteration 1830: Loss 5.0397
Iteration 1831: Loss 5.0092
Iteration 1832: Loss 4.9531
Iteration 1833: Loss 4.8868
Iteration 1834: Loss 5.1175
Iteration 1835: Loss 4.9303
Iteration 1836: Loss 5.0543
Iteration 1837: Loss 4.7625
Iteration 1838: Loss 4.8237
Iteration 1839: Loss 5.1151
Iteration 1840: Loss 5.3100
Iteration 1841: Loss 4.9037
Iteration 1842: Loss 5.0593
Iteration 1843: Loss 4.8314
Iteration 1844: Loss 4.8868
Iteration 1845: Loss 5.0702
Iteration 1846: Loss 4.8399
Iteration 1847: Loss 5.3070
Iteration 1848: Loss 5.0692
Iteration 1849: Loss 5.0372
Iteration 1850: Loss 4.8392
Iteration 1851: Loss 5.2489
Iteration 1852: Loss 4.9297
Iteration 1853: Loss 5.3018
Iteration 1854: Loss 4.9793
Iteration 1855: Loss 5.0599
Iteration 1856: Loss 4.8922
Iteration 1857: Loss 5.1447
Iteration 1858: Loss 4.9736
Iteration 1859: Loss 5.1450
Iteration 1860: Loss 4.9745
Iteration 1861: Loss 5.1881
Iteration 1862: Loss 5.0896
Iteration 1863: Loss 4.6998
Iteration 1864: Loss 4.9723
Iteration 1865: Loss 5.2413
Iteration 1866: Loss 4.9000
Iteration 1867: Loss 5.0913
Iteration 1868: Loss 4.9380
Iteration 1869: Loss 4.7053
Iteration 1870: Loss 5.5639
Iteration 1871: Loss 5.0917
Iteration 1872: Loss 5.2512
Iteration 1873: Loss 4.9066
Iteration 1874: Loss 5.1927
Iteration 1875: Loss 5.1705
Iteration 1876: Loss 4.9420
Iteration 1877: Loss 5.2918
Iteration 1878: Loss 5.1860
Iteration 1879: Loss 4.8429
Iteration 1880: Loss 5.3624
Iteration 1881: Loss 5.0105
Iteration 1882: Loss 5.2293
Iteration 1883: Loss 4.9546
Iteration 1884: Loss 4.9565
Iteration 1885: Loss 5.0095
Iteration 1886: Loss 5.1712
Iteration 1887: Loss 5.4197
Iteration 1888: Loss 4.8855
Iteration 1889: Loss 4.7969
Iteration 1890: Loss 5.0602
Iteration 1891: Loss 4.9252
Iteration 1892: Loss 5.3394
Iteration 1893: Loss 4.5645
Iteration 1894: Loss 4.9975
Iteration 1895: Loss 4.8197
Iteration 1896: Loss 5.3733
Iteration 1897: Loss 5.0044
Iteration 1898: Loss 4.5987
Iteration 1899: Loss 5.1532
Iteration 1900: Loss 5.1165
Iteration 1901: Loss 5.3090
Iteration 1902: Loss 5.2352
Iteration 1903: Loss 4.8420
Iteration 1904: Loss 4.9688
Iteration 1905: Loss 4.8856
Iteration 1906: Loss 4.7438
Iteration 1907: Loss 5.3748
Iteration 1908: Loss 4.8262
Iteration 1909: Loss 5.1803
Iteration 1910: Loss 4.8031
Iteration 1911: Loss 5.2723
Iteration 1912: Loss 5.2020
Iteration 1913: Loss 4.9657
Iteration 1914: Loss 5.1687
Iteration 1915: Loss 4.7873
Iteration 1916: Loss 5.1447
Iteration 1917: Loss 5.0636
Iteration 1918: Loss 5.4709
Iteration 1919: Loss 5.2402
Iteration 1920: Loss 4.7626
Iteration 1921: Loss 5.0581
Iteration 1922: Loss 5.1210
Iteration 1923: Loss 5.0740
Iteration 1924: Loss 5.1147
Iteration 1925: Loss 4.9669
Iteration 1926: Loss 5.0839
Iteration 1927: Loss 4.9163
Iteration 1928: Loss 4.8634
Iteration 1929: Loss 4.9691
Iteration 1930: Loss 5.2155
Iteration 1931: Loss 5.5434
Iteration 1932: Loss 4.9443
Iteration 1933: Loss 4.9075
Iteration 1934: Loss 5.3176
Iteration 1935: Loss 5.2814
Iteration 1936: Loss 4.9530
Iteration 1937: Loss 5.1703
Iteration 1938: Loss 5.1304
Iteration 1939: Loss 4.7015
Iteration 1940: Loss 4.9186
Iteration 1941: Loss 5.0390
Iteration 1942: Loss 5.3815
Iteration 1943: Loss 5.1143
Iteration 1944: Loss 4.9803
Iteration 1945: Loss 4.9582
Iteration 1946: Loss 5.2683
Iteration 1947: Loss 5.0160
Iteration 1948: Loss 4.8754
Iteration 1949: Loss 5.0601
Iteration 1950: Loss 4.7437
Iteration 1951: Loss 4.9368
Iteration 1952: Loss 5.2099
Iteration 1953: Loss 4.7534
Iteration 1954: Loss 5.0913
Iteration 1955: Loss 5.2530
Iteration 1956: Loss 4.9538
Iteration 1957: Loss 4.8629
Iteration 1958: Loss 4.9942
Iteration 1959: Loss 5.0025
Iteration 1960: Loss 4.8352
Iteration 1961: Loss 5.0440
Iteration 1962: Loss 4.8605
Iteration 1963: Loss 5.2914
Iteration 1964: Loss 5.1641
Iteration 1965: Loss 5.1204
Iteration 1966: Loss 5.2384
Iteration 1967: Loss 4.7703
Iteration 1968: Loss 4.9011
Iteration 1969: Loss 4.8554
Iteration 1970: Loss 4.8893
Iteration 1971: Loss 5.1977
Iteration 1972: Loss 5.1519
Iteration 1973: Loss 5.3816
Iteration 1974: Loss 4.8089
Iteration 1975: Loss 5.0502
Iteration 1976: Loss 5.4331
Iteration 1977: Loss 5.1838
Iteration 1978: Loss 4.9893
Iteration 1979: Loss 4.9754
Iteration 1980: Loss 5.0321
Iteration 1981: Loss 5.1889
Iteration 1982: Loss 4.9971
Iteration 1983: Loss 4.9831
Iteration 1984: Loss 5.0413
Iteration 1985: Loss 4.5757
Iteration 1986: Loss 4.7101
Iteration 1987: Loss 5.0575
Iteration 1988: Loss 5.0283
Iteration 1989: Loss 5.0208
Iteration 1990: Loss 4.9880
Iteration 1991: Loss 4.6991
Iteration 1992: Loss 5.0398
Iteration 1993: Loss 5.1739
Iteration 1994: Loss 5.1456
Iteration 1995: Loss 5.1179
Iteration 1996: Loss 4.9041
Iteration 1997: Loss 4.9333
Iteration 1998: Loss 4.8923
Iteration 1999: Loss 5.2054
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[106]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># New Dataset and Plots</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Load WikiText-2 dataset and prepare train.bin and val.bin</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">'data/wikitext2'</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">'data/wikitext2'</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Paths to input files</span>
<span class="n">train_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'wiki.train.txt'</span><span class="p">)</span>
<span class="n">val_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">'wiki.valid.txt'</span><span class="p">)</span>

<span class="c1"># Read the dataset</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">val_file_path</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1"># Encode with GPT-2 Byte Pair Encoding (BPE) using tiktoken</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>  <span class="c1"># Encode training data</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>      <span class="c1"># Encode validation data</span>

<span class="c1"># Convert to numpy arrays (saving as uint16 to conserve space)</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>

<span class="c1"># Save train.bin and val.bin</span>
<span class="n">train_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">))</span>
<span class="n">val_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">))</span>

<span class="c1"># Define the sizes of the dataset portions (10%, 25%, 50%, 100%)</span>
<span class="n">data_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">metrics_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Configuration for training</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">8</span>  <span class="c1"># Adjust to CPU-friendly settings</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>  <span class="c1"># Reduce the batch size for CPU</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># model</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># for pretraining 0 is good, for finetuning try 0.1+</span>
<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># do we use bias inside LayerNorm and Linear layers?</span>
<span class="c1"># adamw optimizer</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># max learning rate</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># total number of training iterations</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># clip gradients at this value, or disable if == 0.0</span>
<span class="c1"># learning rate decay settings</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># how many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># should be ~= max_iters per Chinchilla</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># minimum learning rate, should be ~= learning_rate/10 per Chinchilla</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">dtype</span> <span class="o">=</span> <span class="s1">'float16'</span>  <span class="c1"># Float32 for CPU</span>
<span class="nb">compile</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># No compilation since it's CPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Helper functions for metrics</span>
<span class="k">def</span> <span class="nf">calculate_perplexity</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_ngram_diversity</span><span class="p">(</span><span class="n">generated_text</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="sd">"""Calculate n-gram diversity by looking at unique n-grams in the generated text."""</span>
    <span class="n">ngrams</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">generated_text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span><span class="o">-</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">unique_ngrams</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">ngrams</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngrams</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_ngrams</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ngrams</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Main training function</span>
<span class="k">def</span> <span class="nf">train_on_dataset</span><span class="p">(</span><span class="n">portion</span><span class="p">):</span>
    <span class="n">portion_train_ids</span> <span class="o">=</span> <span class="n">train_ids</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span> <span class="o">*</span> <span class="n">portion</span><span class="p">)]</span>
    <span class="n">portion_val_ids</span> <span class="o">=</span> <span class="n">val_ids</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val_ids</span><span class="p">)</span> <span class="o">*</span> <span class="n">portion</span><span class="p">)]</span>
    
    <span class="c1"># Save the reduced dataset as train.bin and val.bin</span>
    <span class="n">portion_train_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'train_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">portion</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s1">.bin'</span><span class="p">))</span>
    <span class="n">portion_val_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'val_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">portion</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s1">.bin'</span><span class="p">))</span>

    <span class="c1"># Define the model</span>
    <span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="c1"># Loss tracking</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">perplexities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ngram_diversities</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'train_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">portion</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s1">.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'val_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">portion</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s1">.bin'</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="k">for</span> <span class="n">iter_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
        <span class="c1"># Fetch train batch</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>
        
        <span class="c1"># Forward and backward pass</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Log the loss</span>
        <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Iter </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Evaluate every eval_interval</span>
        <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'val'</span><span class="p">)</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">val_loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">)</span>
                <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">perplexity</span> <span class="o">=</span> <span class="n">calculate_perplexity</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">perplexities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">perplexity</span><span class="p">)</span>
                <span class="n">ngram_diversity</span> <span class="o">=</span> <span class="n">calculate_ngram_diversity</span><span class="p">(</span><span class="n">X_val</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="n">ngram_diversities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ngram_diversity</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Iter </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Perplexity: </span><span class="si">{</span><span class="n">perplexity</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, N-gram Diversity: </span><span class="si">{</span><span class="n">ngram_diversity</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Return metrics</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">'train_loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_losses</span><span class="p">),</span>
        <span class="s1">'val_loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">),</span>
        <span class="s1">'perplexity'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perplexities</span><span class="p">),</span>
        <span class="s1">'ngram_diversity'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ngram_diversities</span><span class="p">)</span>
    <span class="p">}</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Train on different portions and collect metrics</span>
<span class="k">for</span> <span class="n">portion</span> <span class="ow">in</span> <span class="n">data_sizes</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training on </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">portion</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">% of the dataset..."</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">train_on_dataset</span><span class="p">(</span><span class="n">portion</span><span class="p">)</span>
    <span class="n">metrics_dict</span><span class="p">[</span><span class="n">portion</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Plotting the results</span>
<span class="n">num_characters</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">portion</span><span class="p">)</span> <span class="k">for</span> <span class="n">portion</span> <span class="ow">in</span> <span class="n">data_sizes</span><span class="p">]</span>
<span class="n">perplexities</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics_dict</span><span class="p">[</span><span class="n">portion</span><span class="p">][</span><span class="s1">'perplexity'</span><span class="p">]</span> <span class="k">for</span> <span class="n">portion</span> <span class="ow">in</span> <span class="n">data_sizes</span><span class="p">]</span>
<span class="n">ngram_diversities</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics_dict</span><span class="p">[</span><span class="n">portion</span><span class="p">][</span><span class="s1">'ngram_diversity'</span><span class="p">]</span> <span class="k">for</span> <span class="n">portion</span> <span class="ow">in</span> <span class="n">data_sizes</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_characters</span><span class="p">,</span> <span class="n">perplexities</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Perplexity'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Characters'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Perplexity'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Perplexity vs Number of Characters'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">num_characters</span><span class="p">,</span> <span class="n">ngram_diversities</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'N-gram Diversity'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of Characters'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'N-gram Diversity'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'N-gram Diversity vs Number of Characters'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Training on 10% of the dataset...
number of parameters: 7.23M
Iter 0, Train Loss: 10.8464
Iter 0, Val Loss: 10.5753, Perplexity: 39154.3512, N-gram Diversity: 0.9438
Iter 10, Train Loss: 9.5087
Iter 20, Train Loss: 8.3506
Iter 30, Train Loss: 7.3708
Iter 40, Train Loss: 6.8974
Iter 50, Train Loss: 6.8300
Iter 50, Val Loss: 6.2335, Perplexity: 509.5530, N-gram Diversity: 0.9503
Iter 60, Train Loss: 6.6959
Iter 70, Train Loss: 6.5687
Iter 80, Train Loss: 6.5189
Iter 90, Train Loss: 6.3099
Iter 100, Train Loss: 6.1802
Iter 100, Val Loss: 5.9221, Perplexity: 373.1923, N-gram Diversity: 0.9451
Iter 110, Train Loss: 6.0404
Iter 120, Train Loss: 6.2965
Iter 130, Train Loss: 6.1358
Iter 140, Train Loss: 6.1952
Iter 150, Train Loss: 5.8777
Iter 150, Val Loss: 6.1754, Perplexity: 480.7520, N-gram Diversity: 0.9399
Iter 160, Train Loss: 6.0928
Iter 170, Train Loss: 5.8990
Iter 180, Train Loss: 5.5102
Iter 190, Train Loss: 6.1439
Iter 200, Train Loss: 6.0546
Iter 200, Val Loss: 5.8593, Perplexity: 350.4851, N-gram Diversity: 0.9634
Iter 210, Train Loss: 5.7767
Iter 220, Train Loss: 6.2290
Iter 230, Train Loss: 5.3619
Iter 240, Train Loss: 5.6356
Iter 250, Train Loss: 5.6138
Iter 250, Val Loss: 5.5623, Perplexity: 260.4090, N-gram Diversity: 0.9098
Iter 260, Train Loss: 6.1464
Iter 270, Train Loss: 5.7749
Iter 280, Train Loss: 5.6298
Iter 290, Train Loss: 5.7066
Iter 300, Train Loss: 5.8943
Iter 300, Val Loss: 5.3428, Perplexity: 209.1067, N-gram Diversity: 0.9464
Iter 310, Train Loss: 5.3277
Iter 320, Train Loss: 5.6182
Iter 330, Train Loss: 5.4129
Iter 340, Train Loss: 5.5013
Iter 350, Train Loss: 4.8760
Iter 350, Val Loss: 5.6225, Perplexity: 276.5678, N-gram Diversity: 0.9229
Iter 360, Train Loss: 5.0764
Iter 370, Train Loss: 5.4019
Iter 380, Train Loss: 5.2178
Iter 390, Train Loss: 5.4617
Iter 400, Train Loss: 5.3398
Iter 400, Val Loss: 5.4976, Perplexity: 244.1068, N-gram Diversity: 0.9072
Iter 410, Train Loss: 5.2383
Iter 420, Train Loss: 5.3255
Iter 430, Train Loss: 4.6830
Iter 440, Train Loss: 5.3907
Iter 450, Train Loss: 5.4921
Iter 450, Val Loss: 5.4898, Perplexity: 242.2183, N-gram Diversity: 0.8797
Iter 460, Train Loss: 5.0956
Iter 470, Train Loss: 5.2314
Iter 480, Train Loss: 5.0268
Iter 490, Train Loss: 5.4394
Iter 500, Train Loss: 4.8670
Iter 500, Val Loss: 5.1191, Perplexity: 167.1786, N-gram Diversity: 0.9190
Iter 510, Train Loss: 4.9646
Iter 520, Train Loss: 5.3635
Iter 530, Train Loss: 5.2008
Iter 540, Train Loss: 5.2874
Iter 550, Train Loss: 5.0414
Iter 550, Val Loss: 5.4148, Perplexity: 224.7009, N-gram Diversity: 0.9137
Iter 560, Train Loss: 5.2072
Iter 570, Train Loss: 4.9767
Iter 580, Train Loss: 5.2420
Iter 590, Train Loss: 5.1597
Iter 600, Train Loss: 5.2173
Iter 600, Val Loss: 5.5065, Perplexity: 246.2789, N-gram Diversity: 0.9242
Iter 610, Train Loss: 4.6833
Iter 620, Train Loss: 4.9671
Iter 630, Train Loss: 5.3269
Iter 640, Train Loss: 5.0008
Iter 650, Train Loss: 4.7305
Iter 650, Val Loss: 5.2536, Perplexity: 191.2628, N-gram Diversity: 0.9399
Iter 660, Train Loss: 4.9742
Iter 670, Train Loss: 4.5595
Iter 680, Train Loss: 4.7287
Iter 690, Train Loss: 5.0416
Iter 700, Train Loss: 4.5665
Iter 700, Val Loss: 5.6173, Perplexity: 275.1381, N-gram Diversity: 0.9778
Iter 710, Train Loss: 4.6555
Iter 720, Train Loss: 4.9136
Iter 730, Train Loss: 4.6027
Iter 740, Train Loss: 4.8005
Iter 750, Train Loss: 4.8540
Iter 750, Val Loss: 5.4860, Perplexity: 241.3020, N-gram Diversity: 0.9569
Iter 760, Train Loss: 4.9195
Iter 770, Train Loss: 4.7829
Iter 780, Train Loss: 4.8492
Iter 790, Train Loss: 5.1943
Iter 800, Train Loss: 4.5789
Iter 800, Val Loss: 5.8967, Perplexity: 363.8202, N-gram Diversity: 0.9621
Iter 810, Train Loss: 4.6684
Iter 820, Train Loss: 5.0323
Iter 830, Train Loss: 4.7756
Iter 840, Train Loss: 4.6833
Iter 850, Train Loss: 4.6640
Iter 850, Val Loss: 5.3908, Perplexity: 219.3722, N-gram Diversity: 0.9111
Iter 860, Train Loss: 4.7316
Iter 870, Train Loss: 4.9741
Iter 880, Train Loss: 4.7529
Iter 890, Train Loss: 4.9977
Iter 900, Train Loss: 4.5170
Iter 900, Val Loss: 5.7077, Perplexity: 301.1641, N-gram Diversity: 0.9621
Iter 910, Train Loss: 4.6417
Iter 920, Train Loss: 4.4547
Iter 930, Train Loss: 4.0464
Iter 940, Train Loss: 4.3558
Iter 950, Train Loss: 4.3654
Iter 950, Val Loss: 5.7068, Perplexity: 300.9029, N-gram Diversity: 0.9699
Iter 960, Train Loss: 4.7325
Iter 970, Train Loss: 4.6330
Iter 980, Train Loss: 4.4398
Iter 990, Train Loss: 4.2642
Iter 1000, Train Loss: 4.5937
Iter 1000, Val Loss: 5.4205, Perplexity: 225.9816, N-gram Diversity: 0.9176
Iter 1010, Train Loss: 4.6846
Iter 1020, Train Loss: 4.2485
Iter 1030, Train Loss: 4.1727
Iter 1040, Train Loss: 4.4552
Iter 1050, Train Loss: 4.3941
Iter 1050, Val Loss: 5.8329, Perplexity: 341.3527, N-gram Diversity: 0.9778
Iter 1060, Train Loss: 4.2195
Iter 1070, Train Loss: 4.6136
Iter 1080, Train Loss: 4.1455
Iter 1090, Train Loss: 4.4368
Iter 1100, Train Loss: 4.4481
Iter 1100, Val Loss: 5.0899, Perplexity: 162.3766, N-gram Diversity: 0.9150
Iter 1110, Train Loss: 4.1999
Iter 1120, Train Loss: 4.4061
Iter 1130, Train Loss: 4.3203
Iter 1140, Train Loss: 4.3419
Iter 1150, Train Loss: 4.0501
Iter 1150, Val Loss: 5.2192, Perplexity: 184.7813, N-gram Diversity: 0.9098
Iter 1160, Train Loss: 4.1862
Iter 1170, Train Loss: 4.5717
Iter 1180, Train Loss: 4.2406
Iter 1190, Train Loss: 4.3258
Iter 1200, Train Loss: 3.9437
Iter 1200, Val Loss: 5.2763, Perplexity: 195.6517, N-gram Diversity: 0.8784
Iter 1210, Train Loss: 4.3983
Iter 1220, Train Loss: 4.2229
Iter 1230, Train Loss: 4.2154
Iter 1240, Train Loss: 4.0046
Iter 1250, Train Loss: 4.2797
Iter 1250, Val Loss: 5.2338, Perplexity: 187.5080, N-gram Diversity: 0.9294
Iter 1260, Train Loss: 4.4482
Iter 1270, Train Loss: 3.9502
Iter 1280, Train Loss: 4.0296
Iter 1290, Train Loss: 4.2140
Iter 1300, Train Loss: 3.7686
Iter 1300, Val Loss: 5.5622, Perplexity: 260.3939, N-gram Diversity: 0.9556
Iter 1310, Train Loss: 4.1120
Iter 1320, Train Loss: 3.8815
Iter 1330, Train Loss: 3.9222
Iter 1340, Train Loss: 4.2050
Iter 1350, Train Loss: 4.1381
Iter 1350, Val Loss: 5.3615, Perplexity: 213.0439, N-gram Diversity: 0.9307
Iter 1360, Train Loss: 4.3577
Iter 1370, Train Loss: 4.2784
Iter 1380, Train Loss: 4.0279
Iter 1390, Train Loss: 3.9560
Iter 1400, Train Loss: 4.0351
Iter 1400, Val Loss: 5.5672, Perplexity: 261.7103, N-gram Diversity: 0.8993
Iter 1410, Train Loss: 3.8720
Iter 1420, Train Loss: 3.9299
Iter 1430, Train Loss: 4.0259
Iter 1440, Train Loss: 4.0955
Iter 1450, Train Loss: 3.7899
Iter 1450, Val Loss: 5.7526, Perplexity: 315.0063, N-gram Diversity: 0.9098
Iter 1460, Train Loss: 4.0252
Iter 1470, Train Loss: 4.0885
Iter 1480, Train Loss: 3.9368
Iter 1490, Train Loss: 4.1203
Iter 1500, Train Loss: 4.1030
Iter 1500, Val Loss: 5.6884, Perplexity: 295.4095, N-gram Diversity: 0.9660
Iter 1510, Train Loss: 3.7817
Iter 1520, Train Loss: 4.0329
Iter 1530, Train Loss: 3.8716
Iter 1540, Train Loss: 3.9034
Iter 1550, Train Loss: 3.7524
Iter 1550, Val Loss: 4.6313, Perplexity: 102.6464, N-gram Diversity: 0.8719
Iter 1560, Train Loss: 3.9588
Iter 1570, Train Loss: 3.7272
Iter 1580, Train Loss: 3.9158
Iter 1590, Train Loss: 3.8421
Iter 1600, Train Loss: 3.9070
Iter 1600, Val Loss: 5.4217, Perplexity: 226.2602, N-gram Diversity: 0.9085
Iter 1610, Train Loss: 3.7780
Iter 1620, Train Loss: 3.5533
Iter 1630, Train Loss: 3.9089
Iter 1640, Train Loss: 3.9835
Iter 1650, Train Loss: 4.0788
Iter 1650, Val Loss: 5.7579, Perplexity: 316.6839, N-gram Diversity: 0.8915
Iter 1660, Train Loss: 3.7461
Iter 1670, Train Loss: 4.0962
Iter 1680, Train Loss: 3.9857
Iter 1690, Train Loss: 4.1399
Iter 1700, Train Loss: 3.8019
Iter 1700, Val Loss: 5.0550, Perplexity: 156.8069, N-gram Diversity: 0.8392
Iter 1710, Train Loss: 4.2648
Iter 1720, Train Loss: 3.6172
Iter 1730, Train Loss: 4.0465
Iter 1740, Train Loss: 3.8893
Iter 1750, Train Loss: 4.0149
Iter 1750, Val Loss: 5.5332, Perplexity: 252.9633, N-gram Diversity: 0.9621
Iter 1760, Train Loss: 3.8099
Iter 1770, Train Loss: 3.2863
Iter 1780, Train Loss: 3.6993
Iter 1790, Train Loss: 3.7781
Iter 1800, Train Loss: 4.0841
Iter 1800, Val Loss: 5.4873, Perplexity: 241.6052, N-gram Diversity: 0.9033
Iter 1810, Train Loss: 3.5312
Iter 1820, Train Loss: 3.7419
Iter 1830, Train Loss: 3.8375
Iter 1840, Train Loss: 3.9627
Iter 1850, Train Loss: 3.4928
Iter 1850, Val Loss: 5.7638, Perplexity: 318.5560, N-gram Diversity: 0.9464
Iter 1860, Train Loss: 3.6145
Iter 1870, Train Loss: 3.7328
Iter 1880, Train Loss: 3.5245
Iter 1890, Train Loss: 3.5778
Iter 1900, Train Loss: 3.7505
Iter 1900, Val Loss: 5.5411, Perplexity: 254.9504, N-gram Diversity: 0.9516
Iter 1910, Train Loss: 3.7039
Iter 1920, Train Loss: 3.6766
Iter 1930, Train Loss: 3.6411
Iter 1940, Train Loss: 3.2369
Iter 1950, Train Loss: 3.8824
Iter 1950, Val Loss: 5.3121, Perplexity: 202.7767, N-gram Diversity: 0.8863
Iter 1960, Train Loss: 3.5946
Iter 1970, Train Loss: 3.8548
Iter 1980, Train Loss: 3.2938
Iter 1990, Train Loss: 3.6819
Training on 25% of the dataset...
number of parameters: 7.23M
Iter 0, Train Loss: 10.8360
Iter 0, Val Loss: 10.5202, Perplexity: 37058.1171, N-gram Diversity: 0.9242
Iter 10, Train Loss: 9.5595
Iter 20, Train Loss: 8.3082
Iter 30, Train Loss: 7.7057
Iter 40, Train Loss: 7.1183
Iter 50, Train Loss: 7.1287
Iter 50, Val Loss: 6.6060, Perplexity: 739.5137, N-gram Diversity: 0.9346
Iter 60, Train Loss: 6.5952
Iter 70, Train Loss: 6.5499
Iter 80, Train Loss: 6.7282
Iter 90, Train Loss: 6.7623
Iter 100, Train Loss: 6.4351
Iter 100, Val Loss: 5.9289, Perplexity: 375.7396, N-gram Diversity: 0.9464
Iter 110, Train Loss: 6.3526
Iter 120, Train Loss: 6.4310
Iter 130, Train Loss: 5.9650
Iter 140, Train Loss: 6.3958
Iter 150, Train Loss: 6.0297
Iter 150, Val Loss: 5.9880, Perplexity: 398.6070, N-gram Diversity: 0.9556
Iter 160, Train Loss: 6.3033
Iter 170, Train Loss: 6.2170
Iter 180, Train Loss: 5.9701
Iter 190, Train Loss: 6.4025
Iter 200, Train Loss: 5.9567
Iter 200, Val Loss: 5.8549, Perplexity: 348.9529, N-gram Diversity: 0.9608
Iter 210, Train Loss: 6.4646
Iter 220, Train Loss: 5.9137
Iter 230, Train Loss: 6.0977
Iter 240, Train Loss: 6.1621
Iter 250, Train Loss: 5.7640
Iter 250, Val Loss: 5.6077, Perplexity: 272.5094, N-gram Diversity: 0.9490
Iter 260, Train Loss: 5.5677
Iter 270, Train Loss: 5.9851
Iter 280, Train Loss: 5.5048
Iter 290, Train Loss: 5.8921
Iter 300, Train Loss: 5.9379
Iter 300, Val Loss: 5.4131, Perplexity: 224.3318, N-gram Diversity: 0.9346
Iter 310, Train Loss: 5.7681
Iter 320, Train Loss: 5.5677
Iter 330, Train Loss: 5.3816
Iter 340, Train Loss: 6.0935
Iter 350, Train Loss: 5.8356
Iter 350, Val Loss: 5.2465, Perplexity: 189.8999, N-gram Diversity: 0.9190
Iter 360, Train Loss: 5.7525
Iter 370, Train Loss: 5.9530
Iter 380, Train Loss: 5.7046
Iter 390, Train Loss: 5.8555
Iter 400, Train Loss: 5.7329
Iter 400, Val Loss: 5.2280, Perplexity: 186.4145, N-gram Diversity: 0.9412
Iter 410, Train Loss: 5.1865
Iter 420, Train Loss: 5.7882
Iter 430, Train Loss: 5.2250
Iter 440, Train Loss: 5.5333
Iter 450, Train Loss: 5.5978
Iter 450, Val Loss: 5.2841, Perplexity: 197.1791, N-gram Diversity: 0.9438
Iter 460, Train Loss: 5.5530
Iter 470, Train Loss: 5.5768
Iter 480, Train Loss: 5.6158
Iter 490, Train Loss: 5.3792
Iter 500, Train Loss: 5.5335
Iter 500, Val Loss: 5.6061, Perplexity: 272.0878, N-gram Diversity: 0.9739
Iter 510, Train Loss: 5.6554
Iter 520, Train Loss: 5.7146
Iter 530, Train Loss: 5.2900
Iter 540, Train Loss: 5.2810
Iter 550, Train Loss: 5.3887
Iter 550, Val Loss: 5.5750, Perplexity: 263.7437, N-gram Diversity: 0.9725
Iter 560, Train Loss: 5.3809
Iter 570, Train Loss: 5.6432
Iter 580, Train Loss: 5.6518
Iter 590, Train Loss: 5.0172
Iter 600, Train Loss: 5.4910
Iter 600, Val Loss: 5.1866, Perplexity: 178.8669, N-gram Diversity: 0.9556
Iter 610, Train Loss: 5.5946
Iter 620, Train Loss: 5.4813
Iter 630, Train Loss: 5.5410
Iter 640, Train Loss: 5.3342
Iter 650, Train Loss: 5.1157
Iter 650, Val Loss: 5.4361, Perplexity: 229.5492, N-gram Diversity: 0.9529
Iter 660, Train Loss: 5.0455
Iter 670, Train Loss: 5.4300
Iter 680, Train Loss: 5.2840
Iter 690, Train Loss: 5.2179
Iter 700, Train Loss: 5.3264
Iter 700, Val Loss: 5.8230, Perplexity: 337.9943, N-gram Diversity: 0.9699
Iter 710, Train Loss: 5.4231
Iter 720, Train Loss: 5.2884
Iter 730, Train Loss: 5.3371
Iter 740, Train Loss: 5.1256
Iter 750, Train Loss: 5.1504
Iter 750, Val Loss: 5.4370, Perplexity: 229.7444, N-gram Diversity: 0.9608
Iter 760, Train Loss: 5.0994
Iter 770, Train Loss: 5.2143
Iter 780, Train Loss: 5.0146
Iter 790, Train Loss: 5.3409
Iter 800, Train Loss: 4.9406
Iter 800, Val Loss: 4.9881, Perplexity: 146.6639, N-gram Diversity: 0.9556
Iter 810, Train Loss: 5.0178
Iter 820, Train Loss: 5.2507
Iter 830, Train Loss: 5.3234
Iter 840, Train Loss: 5.0641
Iter 850, Train Loss: 5.0500
Iter 850, Val Loss: 5.5088, Perplexity: 246.8670, N-gram Diversity: 0.9791
Iter 860, Train Loss: 5.3853
Iter 870, Train Loss: 4.9465
Iter 880, Train Loss: 4.7826
Iter 890, Train Loss: 5.0346
Iter 900, Train Loss: 5.2006
Iter 900, Val Loss: 4.9489, Perplexity: 141.0142, N-gram Diversity: 0.9137
Iter 910, Train Loss: 5.1586
Iter 920, Train Loss: 4.7956
Iter 930, Train Loss: 5.1160
Iter 940, Train Loss: 4.7413
Iter 950, Train Loss: 5.0488
Iter 950, Val Loss: 4.9719, Perplexity: 144.3058, N-gram Diversity: 0.9503
Iter 960, Train Loss: 5.0157
Iter 970, Train Loss: 5.0604
Iter 980, Train Loss: 4.8790
Iter 990, Train Loss: 5.2133
Iter 1000, Train Loss: 4.9600
Iter 1000, Val Loss: 4.9777, Perplexity: 145.1412, N-gram Diversity: 0.9490
Iter 1010, Train Loss: 5.0109
Iter 1020, Train Loss: 4.8750
Iter 1030, Train Loss: 4.9384
Iter 1040, Train Loss: 4.8919
Iter 1050, Train Loss: 5.0689
Iter 1050, Val Loss: 5.2893, Perplexity: 198.1972, N-gram Diversity: 0.9699
Iter 1060, Train Loss: 5.1032
Iter 1070, Train Loss: 5.2291
Iter 1080, Train Loss: 4.5974
Iter 1090, Train Loss: 5.1412
Iter 1100, Train Loss: 4.9920
Iter 1100, Val Loss: 5.0171, Perplexity: 150.9792, N-gram Diversity: 0.8915
Iter 1110, Train Loss: 4.9350
Iter 1120, Train Loss: 4.7777
Iter 1130, Train Loss: 5.1470
Iter 1140, Train Loss: 5.0103
Iter 1150, Train Loss: 4.8619
Iter 1150, Val Loss: 5.1291, Perplexity: 168.8684, N-gram Diversity: 0.9451
Iter 1160, Train Loss: 4.9651
Iter 1170, Train Loss: 5.1589
Iter 1180, Train Loss: 4.6869
Iter 1190, Train Loss: 4.9987
Iter 1200, Train Loss: 4.7959
Iter 1200, Val Loss: 5.1739, Perplexity: 176.6082, N-gram Diversity: 0.9608
Iter 1210, Train Loss: 4.9618
Iter 1220, Train Loss: 4.7433
Iter 1230, Train Loss: 5.1533
Iter 1240, Train Loss: 4.6221
Iter 1250, Train Loss: 4.6019
Iter 1250, Val Loss: 4.9427, Perplexity: 140.1459, N-gram Diversity: 0.9399
Iter 1260, Train Loss: 4.5305
Iter 1270, Train Loss: 4.8272
Iter 1280, Train Loss: 5.2671
Iter 1290, Train Loss: 5.0179
Iter 1300, Train Loss: 4.8457
Iter 1300, Val Loss: 5.0050, Perplexity: 149.1532, N-gram Diversity: 0.9647
Iter 1310, Train Loss: 4.7479
Iter 1320, Train Loss: 4.7545
Iter 1330, Train Loss: 4.8781
Iter 1340, Train Loss: 4.4214
Iter 1350, Train Loss: 4.8306
Iter 1350, Val Loss: 4.8576, Perplexity: 128.7210, N-gram Diversity: 0.9503
Iter 1360, Train Loss: 4.8472
Iter 1370, Train Loss: 4.9099
Iter 1380, Train Loss: 5.1278
Iter 1390, Train Loss: 4.7951
Iter 1400, Train Loss: 4.8040
Iter 1400, Val Loss: 5.1408, Perplexity: 170.8460, N-gram Diversity: 0.9150
Iter 1410, Train Loss: 4.8353
Iter 1420, Train Loss: 4.7772
Iter 1430, Train Loss: 4.8443
Iter 1440, Train Loss: 4.9558
Iter 1450, Train Loss: 4.4989
Iter 1450, Val Loss: 5.4058, Perplexity: 222.7002, N-gram Diversity: 0.9712
Iter 1460, Train Loss: 5.0337
Iter 1470, Train Loss: 4.4145
Iter 1480, Train Loss: 4.7303
Iter 1490, Train Loss: 4.8247
Iter 1500, Train Loss: 4.8270
Iter 1500, Val Loss: 5.2918, Perplexity: 198.6979, N-gram Diversity: 0.9268
Iter 1510, Train Loss: 4.7585
Iter 1520, Train Loss: 4.6722
Iter 1530, Train Loss: 4.3907
Iter 1540, Train Loss: 4.8022
Iter 1550, Train Loss: 4.4001
Iter 1550, Val Loss: 4.8850, Perplexity: 132.2855, N-gram Diversity: 0.9412
Iter 1560, Train Loss: 4.5280
Iter 1570, Train Loss: 4.5771
Iter 1580, Train Loss: 4.6037
Iter 1590, Train Loss: 4.5481
Iter 1600, Train Loss: 4.8286
Iter 1600, Val Loss: 4.5696, Perplexity: 96.5033, N-gram Diversity: 0.9085
Iter 1610, Train Loss: 4.9049
Iter 1620, Train Loss: 4.3815
Iter 1630, Train Loss: 4.7516
Iter 1640, Train Loss: 4.3477
Iter 1650, Train Loss: 4.4581
Iter 1650, Val Loss: 5.2357, Perplexity: 187.8561, N-gram Diversity: 0.9621
Iter 1660, Train Loss: 4.3902
Iter 1670, Train Loss: 4.7453
Iter 1680, Train Loss: 4.5093
Iter 1690, Train Loss: 4.2838
Iter 1700, Train Loss: 4.2920
Iter 1700, Val Loss: 4.9612, Perplexity: 142.7661, N-gram Diversity: 0.9386
Iter 1710, Train Loss: 4.3604
Iter 1720, Train Loss: 4.4298
Iter 1730, Train Loss: 4.3790
Iter 1740, Train Loss: 4.7976
Iter 1750, Train Loss: 4.4929
Iter 1750, Val Loss: 5.0667, Perplexity: 158.6573, N-gram Diversity: 0.9203
Iter 1760, Train Loss: 4.5100
Iter 1770, Train Loss: 4.4263
Iter 1780, Train Loss: 4.7925
Iter 1790, Train Loss: 4.5140
Iter 1800, Train Loss: 4.6384
Iter 1800, Val Loss: 5.3752, Perplexity: 215.9826, N-gram Diversity: 0.9895
Iter 1810, Train Loss: 4.3563
Iter 1820, Train Loss: 3.9772
Iter 1830, Train Loss: 4.2711
Iter 1840, Train Loss: 4.4729
Iter 1850, Train Loss: 4.4573
Iter 1850, Val Loss: 4.9463, Perplexity: 140.6478, N-gram Diversity: 0.9699
Iter 1860, Train Loss: 4.6592
Iter 1870, Train Loss: 4.4703
Iter 1880, Train Loss: 4.2776
Iter 1890, Train Loss: 4.5255
Iter 1900, Train Loss: 4.4256
Iter 1900, Val Loss: 4.9714, Perplexity: 144.2253, N-gram Diversity: 0.9294
Iter 1910, Train Loss: 4.2075
Iter 1920, Train Loss: 4.5643
Iter 1930, Train Loss: 4.3732
Iter 1940, Train Loss: 4.2386
Iter 1950, Train Loss: 4.2160
Iter 1950, Val Loss: 5.1091, Perplexity: 165.5267, N-gram Diversity: 0.9490
Iter 1960, Train Loss: 4.2927
Iter 1970, Train Loss: 4.6819
Iter 1980, Train Loss: 4.6052
Iter 1990, Train Loss: 4.4164
Training on 50% of the dataset...
number of parameters: 7.23M
Iter 0, Train Loss: 10.8457
Iter 0, Val Loss: 10.5129, Perplexity: 36785.5118, N-gram Diversity: 0.9647
Iter 10, Train Loss: 9.5889
Iter 20, Train Loss: 8.2452
Iter 30, Train Loss: 7.3856
Iter 40, Train Loss: 7.2617
Iter 50, Train Loss: 7.2547
Iter 50, Val Loss: 6.1232, Perplexity: 456.3424, N-gram Diversity: 0.9203
Iter 60, Train Loss: 6.6699
Iter 70, Train Loss: 6.4133
Iter 80, Train Loss: 6.2366
Iter 90, Train Loss: 6.4282
Iter 100, Train Loss: 6.3525
Iter 100, Val Loss: 5.9685, Perplexity: 390.9284, N-gram Diversity: 0.9542
Iter 110, Train Loss: 6.1938
Iter 120, Train Loss: 6.6313
Iter 130, Train Loss: 6.2432
Iter 140, Train Loss: 6.1566
Iter 150, Train Loss: 6.3778
Iter 150, Val Loss: 5.7552, Perplexity: 315.8159, N-gram Diversity: 0.9595
Iter 160, Train Loss: 6.1046
Iter 170, Train Loss: 6.1349
Iter 180, Train Loss: 6.3562
Iter 190, Train Loss: 6.1322
Iter 200, Train Loss: 6.0055
Iter 200, Val Loss: 5.6416, Perplexity: 281.9094, N-gram Diversity: 0.9333
Iter 210, Train Loss: 5.8457
Iter 220, Train Loss: 6.4894
Iter 230, Train Loss: 5.9892
Iter 240, Train Loss: 6.0359
Iter 250, Train Loss: 6.4008
Iter 250, Val Loss: 5.4368, Perplexity: 229.7003, N-gram Diversity: 0.9451
Iter 260, Train Loss: 5.7460
Iter 270, Train Loss: 5.6639
Iter 280, Train Loss: 6.0017
Iter 290, Train Loss: 5.8663
Iter 300, Train Loss: 5.8586
Iter 300, Val Loss: 5.1276, Perplexity: 168.6054, N-gram Diversity: 0.9007
Iter 310, Train Loss: 5.9406
Iter 320, Train Loss: 5.6662
Iter 330, Train Loss: 5.9187
Iter 340, Train Loss: 5.8526
Iter 350, Train Loss: 6.0139
Iter 350, Val Loss: 5.5741, Perplexity: 263.5205, N-gram Diversity: 0.9569
Iter 360, Train Loss: 5.9509
Iter 370, Train Loss: 5.7925
Iter 380, Train Loss: 5.5977
Iter 390, Train Loss: 5.8551
Iter 400, Train Loss: 5.4929
Iter 400, Val Loss: 5.3475, Perplexity: 210.0821, N-gram Diversity: 0.9503
Iter 410, Train Loss: 5.5663
Iter 420, Train Loss: 5.5272
Iter 430, Train Loss: 5.8625
Iter 440, Train Loss: 5.8548
Iter 450, Train Loss: 5.6605
Iter 450, Val Loss: 5.6113, Perplexity: 273.5129, N-gram Diversity: 0.9647
Iter 460, Train Loss: 5.4512
Iter 470, Train Loss: 5.5433
Iter 480, Train Loss: 5.6874
Iter 490, Train Loss: 5.5855
Iter 500, Train Loss: 5.7549
Iter 500, Val Loss: 5.4497, Perplexity: 232.6806, N-gram Diversity: 0.9765
Iter 510, Train Loss: 5.5452
Iter 520, Train Loss: 5.9644
Iter 530, Train Loss: 5.4622
Iter 540, Train Loss: 5.4279
Iter 550, Train Loss: 5.8048
Iter 550, Val Loss: 5.0896, Perplexity: 162.3280, N-gram Diversity: 0.9359
Iter 560, Train Loss: 5.8554
Iter 570, Train Loss: 5.6909
Iter 580, Train Loss: 5.5937
Iter 590, Train Loss: 5.7503
Iter 600, Train Loss: 5.5435
Iter 600, Val Loss: 5.1304, Perplexity: 169.0791, N-gram Diversity: 0.9085
Iter 610, Train Loss: 5.6949
Iter 620, Train Loss: 5.4316
Iter 630, Train Loss: 5.9622
Iter 640, Train Loss: 5.4954
Iter 650, Train Loss: 5.4118
Iter 650, Val Loss: 5.3098, Perplexity: 202.3168, N-gram Diversity: 0.9451
Iter 660, Train Loss: 5.3956
Iter 670, Train Loss: 5.6955
Iter 680, Train Loss: 5.6107
Iter 690, Train Loss: 5.6150
Iter 700, Train Loss: 5.7766
Iter 700, Val Loss: 5.2347, Perplexity: 187.6791, N-gram Diversity: 0.9634
Iter 710, Train Loss: 5.5699
Iter 720, Train Loss: 5.4563
Iter 730, Train Loss: 5.3089
Iter 740, Train Loss: 5.6538
Iter 750, Train Loss: 5.4458
Iter 750, Val Loss: 5.2723, Perplexity: 194.8717, N-gram Diversity: 0.9699
Iter 760, Train Loss: 5.3554
Iter 770, Train Loss: 5.5320
Iter 780, Train Loss: 5.4214
Iter 790, Train Loss: 5.4271
Iter 800, Train Loss: 5.6600
Iter 800, Val Loss: 5.3222, Perplexity: 204.8318, N-gram Diversity: 0.9529
Iter 810, Train Loss: 5.3069
Iter 820, Train Loss: 5.4326
Iter 830, Train Loss: 5.5724
Iter 840, Train Loss: 5.1426
Iter 850, Train Loss: 5.3549
Iter 850, Val Loss: 5.3843, Perplexity: 217.9485, N-gram Diversity: 0.9608
Iter 860, Train Loss: 5.1222
Iter 870, Train Loss: 5.0932
Iter 880, Train Loss: 4.7154
Iter 890, Train Loss: 5.5073
Iter 900, Train Loss: 5.3827
Iter 900, Val Loss: 5.0528, Perplexity: 156.4604, N-gram Diversity: 0.9373
Iter 910, Train Loss: 5.1792
Iter 920, Train Loss: 5.2989
Iter 930, Train Loss: 5.3212
Iter 940, Train Loss: 5.5209
Iter 950, Train Loss: 5.3034
Iter 950, Val Loss: 5.0502, Perplexity: 156.0604, N-gram Diversity: 0.9595
Iter 960, Train Loss: 5.0450
Iter 970, Train Loss: 5.4495
Iter 980, Train Loss: 4.6926
Iter 990, Train Loss: 4.9135
Iter 1000, Train Loss: 5.3647
Iter 1000, Val Loss: 4.9546, Perplexity: 141.8300, N-gram Diversity: 0.9425
Iter 1010, Train Loss: 5.3136
Iter 1020, Train Loss: 5.4026
Iter 1030, Train Loss: 5.3552
Iter 1040, Train Loss: 5.2594
Iter 1050, Train Loss: 5.0890
Iter 1050, Val Loss: 4.7888, Perplexity: 120.1541, N-gram Diversity: 0.9085
Iter 1060, Train Loss: 5.0518
Iter 1070, Train Loss: 5.1934
Iter 1080, Train Loss: 5.1152
Iter 1090, Train Loss: 5.0739
Iter 1100, Train Loss: 5.3624
Iter 1100, Val Loss: 5.1233, Perplexity: 167.8803, N-gram Diversity: 0.9425
Iter 1110, Train Loss: 5.0025
Iter 1120, Train Loss: 5.1760
Iter 1130, Train Loss: 5.1730
Iter 1140, Train Loss: 5.2340
Iter 1150, Train Loss: 5.0140
Iter 1150, Val Loss: 5.2752, Perplexity: 195.4215, N-gram Diversity: 0.9608
Iter 1160, Train Loss: 4.9677
Iter 1170, Train Loss: 5.2666
Iter 1180, Train Loss: 5.2680
Iter 1190, Train Loss: 5.3259
Iter 1200, Train Loss: 5.0991
Iter 1200, Val Loss: 4.6565, Perplexity: 105.2723, N-gram Diversity: 0.9346
Iter 1210, Train Loss: 5.2399
Iter 1220, Train Loss: 5.0996
Iter 1230, Train Loss: 5.1216
Iter 1240, Train Loss: 5.2584
Iter 1250, Train Loss: 5.1876
Iter 1250, Val Loss: 4.6733, Perplexity: 107.0515, N-gram Diversity: 0.9425
Iter 1260, Train Loss: 5.0369
Iter 1270, Train Loss: 5.0656
Iter 1280, Train Loss: 4.9884
Iter 1290, Train Loss: 4.9485
Iter 1300, Train Loss: 4.7722
Iter 1300, Val Loss: 4.9086, Perplexity: 135.4489, N-gram Diversity: 0.9490
Iter 1310, Train Loss: 5.2045
Iter 1320, Train Loss: 5.1003
Iter 1330, Train Loss: 5.0970
Iter 1340, Train Loss: 4.7546
Iter 1350, Train Loss: 5.1995
Iter 1350, Val Loss: 4.7411, Perplexity: 114.5578, N-gram Diversity: 0.9203
Iter 1360, Train Loss: 5.3461
Iter 1370, Train Loss: 4.9787
Iter 1380, Train Loss: 5.5285
Iter 1390, Train Loss: 4.8773
Iter 1400, Train Loss: 5.0190
Iter 1400, Val Loss: 4.8108, Perplexity: 122.8354, N-gram Diversity: 0.9399
Iter 1410, Train Loss: 4.9851
Iter 1420, Train Loss: 4.4365
Iter 1430, Train Loss: 5.0598
Iter 1440, Train Loss: 5.2705
Iter 1450, Train Loss: 5.0165
Iter 1450, Val Loss: 4.8855, Perplexity: 132.3622, N-gram Diversity: 0.9451
Iter 1460, Train Loss: 5.0708
Iter 1470, Train Loss: 5.1375
Iter 1480, Train Loss: 4.8926
Iter 1490, Train Loss: 5.0413
Iter 1500, Train Loss: 4.9108
Iter 1500, Val Loss: 4.9854, Perplexity: 146.2580, N-gram Diversity: 0.9503
Iter 1510, Train Loss: 4.8264
Iter 1520, Train Loss: 5.1440
Iter 1530, Train Loss: 5.1343
Iter 1540, Train Loss: 4.9929
Iter 1550, Train Loss: 4.9541
Iter 1550, Val Loss: 5.1610, Perplexity: 174.3302, N-gram Diversity: 0.9098
Iter 1560, Train Loss: 4.9210
Iter 1570, Train Loss: 5.0515
Iter 1580, Train Loss: 5.0719
Iter 1590, Train Loss: 4.8759
Iter 1600, Train Loss: 4.5535
Iter 1600, Val Loss: 4.8027, Perplexity: 121.8337, N-gram Diversity: 0.9542
Iter 1610, Train Loss: 4.9879
Iter 1620, Train Loss: 5.2004
Iter 1630, Train Loss: 5.0959
Iter 1640, Train Loss: 5.1260
Iter 1650, Train Loss: 4.7665
Iter 1650, Val Loss: 4.7148, Perplexity: 111.5884, N-gram Diversity: 0.9386
Iter 1660, Train Loss: 5.1851
Iter 1670, Train Loss: 5.3134
Iter 1680, Train Loss: 4.7723
Iter 1690, Train Loss: 4.9988
Iter 1700, Train Loss: 4.5704
Iter 1700, Val Loss: 5.0438, Perplexity: 155.0619, N-gram Diversity: 0.9634
Iter 1710, Train Loss: 4.9872
Iter 1720, Train Loss: 4.8373
Iter 1730, Train Loss: 4.7875
Iter 1740, Train Loss: 4.6757
Iter 1750, Train Loss: 4.9863
Iter 1750, Val Loss: 5.0104, Perplexity: 149.9626, N-gram Diversity: 0.9634
Iter 1760, Train Loss: 4.8496
Iter 1770, Train Loss: 4.9142
Iter 1780, Train Loss: 4.8784
Iter 1790, Train Loss: 4.6572
Iter 1800, Train Loss: 4.8736
Iter 1800, Val Loss: 4.7068, Perplexity: 110.6946, N-gram Diversity: 0.9556
Iter 1810, Train Loss: 4.7052
Iter 1820, Train Loss: 4.6460
Iter 1830, Train Loss: 4.8161
Iter 1840, Train Loss: 5.2364
Iter 1850, Train Loss: 4.7433
Iter 1850, Val Loss: 5.1210, Perplexity: 167.5008, N-gram Diversity: 0.9791
Iter 1860, Train Loss: 4.7923
Iter 1870, Train Loss: 4.7428
Iter 1880, Train Loss: 4.9481
Iter 1890, Train Loss: 4.8664
Iter 1900, Train Loss: 4.8355
Iter 1900, Val Loss: 4.9008, Perplexity: 134.3911, N-gram Diversity: 0.9569
Iter 1910, Train Loss: 4.9981
Iter 1920, Train Loss: 4.9084
Iter 1930, Train Loss: 4.7544
Iter 1940, Train Loss: 4.5298
Iter 1950, Train Loss: 4.8602
Iter 1950, Val Loss: 4.8494, Perplexity: 127.6607, N-gram Diversity: 0.9490
Iter 1960, Train Loss: 4.8853
Iter 1970, Train Loss: 4.6599
Iter 1980, Train Loss: 5.0606
Iter 1990, Train Loss: 4.5203
Training on 100% of the dataset...
number of parameters: 7.23M
Iter 0, Train Loss: 10.8255
Iter 0, Val Loss: 10.5707, Perplexity: 38974.1884, N-gram Diversity: 0.9346
Iter 10, Train Loss: 9.4696
Iter 20, Train Loss: 8.3641
Iter 30, Train Loss: 7.5434
Iter 40, Train Loss: 7.0809
Iter 50, Train Loss: 7.3050
Iter 50, Val Loss: 6.3836, Perplexity: 592.0371, N-gram Diversity: 0.9647
Iter 60, Train Loss: 7.1888
Iter 70, Train Loss: 6.5877
Iter 80, Train Loss: 6.7053
Iter 90, Train Loss: 6.8249
Iter 100, Train Loss: 6.3394
Iter 100, Val Loss: 5.8671, Perplexity: 353.2205, N-gram Diversity: 0.9712
Iter 110, Train Loss: 6.2427
Iter 120, Train Loss: 6.5057
Iter 130, Train Loss: 6.4333
Iter 140, Train Loss: 6.1574
Iter 150, Train Loss: 5.8275
Iter 150, Val Loss: 6.0120, Perplexity: 408.2912, N-gram Diversity: 0.9765
Iter 160, Train Loss: 6.6317
Iter 170, Train Loss: 6.5499
Iter 180, Train Loss: 6.3366
Iter 190, Train Loss: 5.6939
Iter 200, Train Loss: 6.3258
Iter 200, Val Loss: 6.0030, Perplexity: 404.6271, N-gram Diversity: 0.9699
Iter 210, Train Loss: 6.1125
Iter 220, Train Loss: 5.4090
Iter 230, Train Loss: 6.1601
Iter 240, Train Loss: 6.0781
Iter 250, Train Loss: 5.9973
Iter 250, Val Loss: 5.6956, Perplexity: 297.5527, N-gram Diversity: 0.9582
Iter 260, Train Loss: 6.1237
Iter 270, Train Loss: 6.2437
Iter 280, Train Loss: 6.1616
Iter 290, Train Loss: 5.7689
Iter 300, Train Loss: 6.1518
Iter 300, Val Loss: 5.2534, Perplexity: 191.2245, N-gram Diversity: 0.8993
Iter 310, Train Loss: 5.8603
Iter 320, Train Loss: 5.9573
Iter 330, Train Loss: 5.8949
Iter 340, Train Loss: 6.0361
Iter 350, Train Loss: 5.8447
Iter 350, Val Loss: 5.3095, Perplexity: 202.2539, N-gram Diversity: 0.9399
Iter 360, Train Loss: 5.9226
Iter 370, Train Loss: 6.0846
Iter 380, Train Loss: 5.8205
Iter 390, Train Loss: 5.7170
Iter 400, Train Loss: 6.2000
Iter 400, Val Loss: 5.2431, Perplexity: 189.2510, N-gram Diversity: 0.9346
Iter 410, Train Loss: 6.1370
Iter 420, Train Loss: 5.9254
Iter 430, Train Loss: 5.7761
Iter 440, Train Loss: 5.9161
Iter 450, Train Loss: 5.7116
Iter 450, Val Loss: 5.4960, Perplexity: 243.7045, N-gram Diversity: 0.9673
Iter 460, Train Loss: 5.5934
Iter 470, Train Loss: 5.7393
Iter 480, Train Loss: 5.4980
Iter 490, Train Loss: 5.3925
Iter 500, Train Loss: 5.4069
Iter 500, Val Loss: 5.4628, Perplexity: 235.7551, N-gram Diversity: 0.9595
Iter 510, Train Loss: 5.7650
Iter 520, Train Loss: 5.6131
Iter 530, Train Loss: 6.0185
Iter 540, Train Loss: 6.0854
Iter 550, Train Loss: 5.9238
Iter 550, Val Loss: 5.4726, Perplexity: 238.0708, N-gram Diversity: 0.9451
Iter 560, Train Loss: 5.5264
Iter 570, Train Loss: 5.9222
Iter 580, Train Loss: 5.5440
Iter 590, Train Loss: 5.1580
Iter 600, Train Loss: 5.3472
Iter 600, Val Loss: 5.4960, Perplexity: 243.7139, N-gram Diversity: 0.9817
Iter 610, Train Loss: 5.4771
Iter 620, Train Loss: 5.6248
Iter 630, Train Loss: 5.4340
Iter 640, Train Loss: 5.5130
Iter 650, Train Loss: 5.5062
Iter 650, Val Loss: 5.2694, Perplexity: 194.3044, N-gram Diversity: 0.9542
Iter 660, Train Loss: 5.5128
Iter 670, Train Loss: 5.7945
Iter 680, Train Loss: 5.6659
Iter 690, Train Loss: 5.6016
Iter 700, Train Loss: 5.6234
Iter 700, Val Loss: 5.1634, Perplexity: 174.7592, N-gram Diversity: 0.9490
Iter 710, Train Loss: 5.7100
Iter 720, Train Loss: 5.4827
Iter 730, Train Loss: 5.6186
Iter 740, Train Loss: 5.4398
Iter 750, Train Loss: 5.5080
Iter 750, Val Loss: 5.4295, Perplexity: 228.0291, N-gram Diversity: 0.9556
Iter 760, Train Loss: 5.2212
Iter 770, Train Loss: 5.6037
Iter 780, Train Loss: 5.8354
Iter 790, Train Loss: 5.4895
Iter 800, Train Loss: 5.3687
Iter 800, Val Loss: 5.1790, Perplexity: 177.5078, N-gram Diversity: 0.9673
Iter 810, Train Loss: 5.1273
Iter 820, Train Loss: 5.3595
Iter 830, Train Loss: 5.6087
Iter 840, Train Loss: 5.4849
Iter 850, Train Loss: 5.1303
Iter 850, Val Loss: 5.1288, Perplexity: 168.8218, N-gram Diversity: 0.9438
Iter 860, Train Loss: 5.4857
Iter 870, Train Loss: 5.2298
Iter 880, Train Loss: 5.3144
Iter 890, Train Loss: 5.6754
Iter 900, Train Loss: 5.3514
Iter 900, Val Loss: 4.9704, Perplexity: 144.0852, N-gram Diversity: 0.9529
Iter 910, Train Loss: 5.7436
Iter 920, Train Loss: 5.5678
Iter 930, Train Loss: 5.4870
Iter 940, Train Loss: 5.3584
Iter 950, Train Loss: 5.1847
Iter 950, Val Loss: 5.2911, Perplexity: 198.5565, N-gram Diversity: 0.9569
Iter 960, Train Loss: 5.4882
Iter 970, Train Loss: 5.4140
Iter 980, Train Loss: 5.2646
Iter 990, Train Loss: 5.5017
Iter 1000, Train Loss: 5.3321
Iter 1000, Val Loss: 4.9568, Perplexity: 142.1394, N-gram Diversity: 0.9542
Iter 1010, Train Loss: 5.2474
Iter 1020, Train Loss: 5.0911
Iter 1030, Train Loss: 5.6838
Iter 1040, Train Loss: 5.3888
Iter 1050, Train Loss: 5.2701
Iter 1050, Val Loss: 4.7228, Perplexity: 112.4809, N-gram Diversity: 0.9412
Iter 1060, Train Loss: 5.3229
Iter 1070, Train Loss: 5.6132
Iter 1080, Train Loss: 5.4591
Iter 1090, Train Loss: 5.6088
Iter 1100, Train Loss: 5.1618
Iter 1100, Val Loss: 4.9885, Perplexity: 146.7116, N-gram Diversity: 0.9294
Iter 1110, Train Loss: 5.3960
Iter 1120, Train Loss: 5.2474
Iter 1130, Train Loss: 5.7090
Iter 1140, Train Loss: 5.7621
Iter 1150, Train Loss: 5.0702
Iter 1150, Val Loss: 5.3224, Perplexity: 204.8762, N-gram Diversity: 0.9869
Iter 1160, Train Loss: 5.3517
Iter 1170, Train Loss: 4.9987
Iter 1180, Train Loss: 5.2677
Iter 1190, Train Loss: 5.1775
Iter 1200, Train Loss: 5.0684
Iter 1200, Val Loss: 4.6465, Perplexity: 104.2190, N-gram Diversity: 0.9451
Iter 1210, Train Loss: 5.0993
Iter 1220, Train Loss: 5.3495
Iter 1230, Train Loss: 5.3466
Iter 1240, Train Loss: 5.0275
Iter 1250, Train Loss: 5.1085
Iter 1250, Val Loss: 4.7457, Perplexity: 115.0928, N-gram Diversity: 0.9294
Iter 1260, Train Loss: 4.8398
Iter 1270, Train Loss: 5.4927
Iter 1280, Train Loss: 5.5218
Iter 1290, Train Loss: 5.1544
Iter 1300, Train Loss: 4.9699
Iter 1300, Val Loss: 5.0406, Perplexity: 154.5576, N-gram Diversity: 0.9307
Iter 1310, Train Loss: 5.0067
Iter 1320, Train Loss: 5.3930
Iter 1330, Train Loss: 5.5046
Iter 1340, Train Loss: 5.0138
Iter 1350, Train Loss: 5.3999
Iter 1350, Val Loss: 4.5808, Perplexity: 97.5928, N-gram Diversity: 0.9582
Iter 1360, Train Loss: 5.4769
Iter 1370, Train Loss: 5.3413
Iter 1380, Train Loss: 5.2843
Iter 1390, Train Loss: 4.8459
Iter 1400, Train Loss: 5.1248
Iter 1400, Val Loss: 5.0982, Perplexity: 163.7242, N-gram Diversity: 0.9595
Iter 1410, Train Loss: 5.3134
Iter 1420, Train Loss: 4.8152
Iter 1430, Train Loss: 4.9779
Iter 1440, Train Loss: 5.3268
Iter 1450, Train Loss: 5.2470
Iter 1450, Val Loss: 5.0966, Perplexity: 163.4727, N-gram Diversity: 0.9830
Iter 1460, Train Loss: 5.2773
Iter 1470, Train Loss: 5.1532
Iter 1480, Train Loss: 5.1459
Iter 1490, Train Loss: 5.1946
Iter 1500, Train Loss: 4.9500
Iter 1500, Val Loss: 4.6438, Perplexity: 103.9377, N-gram Diversity: 0.9268
Iter 1510, Train Loss: 5.1273
Iter 1520, Train Loss: 4.7496
Iter 1530, Train Loss: 5.3738
Iter 1540, Train Loss: 4.6828
Iter 1550, Train Loss: 5.0269
Iter 1550, Val Loss: 5.0661, Perplexity: 158.5527, N-gram Diversity: 0.9503
Iter 1560, Train Loss: 4.9998
Iter 1570, Train Loss: 5.1674
Iter 1580, Train Loss: 5.1636
Iter 1590, Train Loss: 5.1645
Iter 1600, Train Loss: 5.1033
Iter 1600, Val Loss: 4.4577, Perplexity: 86.2920, N-gram Diversity: 0.9346
Iter 1610, Train Loss: 5.0429
Iter 1620, Train Loss: 4.8174
Iter 1630, Train Loss: 4.8327
Iter 1640, Train Loss: 5.1129
Iter 1650, Train Loss: 5.4079
Iter 1650, Val Loss: 4.7330, Perplexity: 113.6327, N-gram Diversity: 0.9190
Iter 1660, Train Loss: 4.5422
Iter 1670, Train Loss: 5.1722
Iter 1680, Train Loss: 5.3168
Iter 1690, Train Loss: 4.8912
Iter 1700, Train Loss: 4.9267
Iter 1700, Val Loss: 4.5503, Perplexity: 94.6619, N-gram Diversity: 0.9399
Iter 1710, Train Loss: 5.3129
Iter 1720, Train Loss: 5.1086
Iter 1730, Train Loss: 5.1063
Iter 1740, Train Loss: 5.2860
Iter 1750, Train Loss: 4.9898
Iter 1750, Val Loss: 5.0189, Perplexity: 151.2463, N-gram Diversity: 0.9712
Iter 1760, Train Loss: 4.7907
Iter 1770, Train Loss: 4.9683
Iter 1780, Train Loss: 4.9339
Iter 1790, Train Loss: 4.9529
Iter 1800, Train Loss: 5.4180
Iter 1800, Val Loss: 4.6482, Perplexity: 104.3986, N-gram Diversity: 0.9438
Iter 1810, Train Loss: 4.7618
Iter 1820, Train Loss: 4.9684
Iter 1830, Train Loss: 5.1750
Iter 1840, Train Loss: 5.1037
Iter 1850, Train Loss: 5.2414
Iter 1850, Val Loss: 5.0898, Perplexity: 162.3526, N-gram Diversity: 0.9608
Iter 1860, Train Loss: 5.0727
Iter 1870, Train Loss: 5.2872
Iter 1880, Train Loss: 5.3699
Iter 1890, Train Loss: 4.9637
Iter 1900, Train Loss: 4.8643
Iter 1900, Val Loss: 5.2545, Perplexity: 191.4254, N-gram Diversity: 0.9752
Iter 1910, Train Loss: 4.8859
Iter 1920, Train Loss: 4.8483
Iter 1930, Train Loss: 4.9997
Iter 1940, Train Loss: 4.7281
Iter 1950, Train Loss: 5.1845
Iter 1950, Val Loss: 5.0953, Perplexity: 163.2559, N-gram Diversity: 0.9686
Iter 1960, Train Loss: 4.6781
Iter 1970, Train Loss: 4.6068
Iter 1980, Train Loss: 4.6598
Iter 1990, Train Loss: 4.9701
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
class="
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[111]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fine tune</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Load WikiText-2 dataset (train.bin and val.bin must be created beforehand)</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">'data/wikitext2'</span>
<span class="n">train_bin_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">)</span>
<span class="n">val_bin_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">)</span>

<span class="c1"># Load the dataset (same as in previous steps)</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">train_bin_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">val_bin_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>


<span class="c1"># Adjust the model configuration to match the checkpoint</span>
<span class="c1"># Model hyperparameters</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># Match the block size in the checkpoint</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Ensure bias is False to match the checkpoint</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span>  <span class="c1"># Number of iterations for fine-tuning</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span> <span class="c1"># max learning rate</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># total number of training iterations</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># clip gradients at this value, or disable if == 0.0</span>
<span class="c1"># learning rate decay settings</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># how many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">2000</span> <span class="c1"># should be ~= max_iters per Chinchilla</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-4</span> <span class="c1"># minimum learning rate, should be ~= learning_rate/10 per Chinchilla</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Load Pre-trained Shakespeare Model</span>
<span class="n">ckpt_path</span> <span class="o">=</span> <span class="s1">'out/ckpt.pt'</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Initialize the model with the adjusted config</span>
<span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Load the checkpoint weights (strict=True since we matched config)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">])</span>

<span class="c1"># Initialize the optimizer with a fresh state (skip loading optimizer state)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># Now can proceed with fine-tuning</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Model successfully loaded with adjusted configuration and fresh optimizer."</span><span class="p">)</span>
<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Fine-tune on the new dataset</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">train_ids</span> <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span> <span class="k">else</span> <span class="n">val_ids</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss tracking for comparison</span>
<span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">iter_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
        <span class="c1"># Get a batch of data</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">)</span>
        
        <span class="c1"># Forward pass and loss computation</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
        <span class="c1"># Optimizer step</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Track training loss</span>
        <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Iteration </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Train Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Evaluate on validation set every eval_interval iterations</span>
        <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'val'</span><span class="p">)</span>
                <span class="n">logits</span><span class="p">,</span> <span class="n">val_loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">)</span>
                <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Iteration </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                
            <span class="c1"># Save checkpoint after evaluation</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
                <span class="s1">'model'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">'optimizer'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">'train_loss'</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
                <span class="s1">'val_loss'</span><span class="p">:</span> <span class="n">val_losses</span>
            <span class="p">},</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">output_dir</span><span class="si">}</span><span class="s2">/fine_tuned_model_</span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">.ckpt"</span><span class="p">)</span>

<span class="c1"># Fine-tune the Shakespeare model on the new dataset</span>
<span class="n">train_model</span><span class="p">()</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Evaluate the fine-tuning: Generate text after fine-tuning</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">start_text</span><span class="o">=</span><span class="s2">""</span><span class="p">):</span>
    <span class="n">enc</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">"gpt2"</span><span class="p">)</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">enc</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">start_text</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Generate 100 tokens based on the fine-tuned model</span>
    <span class="n">generated</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    
    <span class="c1"># Decode back to readable text</span>
    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">generated_text</span>

<span class="c1"># After fine-tuning, generate text based on a prompt to see the model output</span>
<span class="n">start_text</span> <span class="o">=</span> <span class="s2">"The purpose of"</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Generated text after fine-tuning:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generate_text</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">start_text</span><span class="o">=</span><span class="n">start_text</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>number of parameters: 7.23M
Model successfully loaded with adjusted configuration and fresh optimizer.
Iteration 0: Train Loss: 5.1984
Iteration 0: Val Loss: 5.2716
Iteration 10: Train Loss: 5.3208
Iteration 20: Train Loss: 5.3867
Iteration 30: Train Loss: 5.5446
Iteration 40: Train Loss: 5.6389
Iteration 50: Train Loss: 5.3446
Iteration 50: Val Loss: 5.2410
Iteration 60: Train Loss: 5.3591
Iteration 70: Train Loss: 5.6091
Iteration 80: Train Loss: 5.8625
Iteration 90: Train Loss: 5.7171
Iteration 100: Train Loss: 5.3449
Iteration 100: Val Loss: 4.9660
Iteration 110: Train Loss: 5.9347
Iteration 120: Train Loss: 5.5471
Iteration 130: Train Loss: 5.7313
Iteration 140: Train Loss: 5.4395
Iteration 150: Train Loss: 5.6925
Iteration 150: Val Loss: 5.1786
Iteration 160: Train Loss: 5.5506
Iteration 170: Train Loss: 5.4853
Iteration 180: Train Loss: 5.5356
Iteration 190: Train Loss: 5.6383
Iteration 200: Train Loss: 5.7713
Iteration 200: Val Loss: 5.5056
Iteration 210: Train Loss: 5.7634
Iteration 220: Train Loss: 5.6983
Iteration 230: Train Loss: 5.6719
Iteration 240: Train Loss: 5.2195
Iteration 250: Train Loss: 5.5717
Iteration 250: Val Loss: 5.2523
Iteration 260: Train Loss: 5.6444
Iteration 270: Train Loss: 5.4024
Iteration 280: Train Loss: 5.2107
Iteration 290: Train Loss: 5.5653
Iteration 300: Train Loss: 5.2647
Iteration 300: Val Loss: 4.9123
Iteration 310: Train Loss: 5.3764
Iteration 320: Train Loss: 5.5190
Iteration 330: Train Loss: 5.3002
Iteration 340: Train Loss: 5.5694
Iteration 350: Train Loss: 5.4106
Iteration 350: Val Loss: 5.3342
Iteration 360: Train Loss: 5.0311
Iteration 370: Train Loss: 5.5111
Iteration 380: Train Loss: 5.4228
Iteration 390: Train Loss: 5.3795
Iteration 400: Train Loss: 5.8037
Iteration 400: Val Loss: 4.9386
Iteration 410: Train Loss: 5.3680
Iteration 420: Train Loss: 5.3928
Iteration 430: Train Loss: 5.3389
Iteration 440: Train Loss: 5.2417
Iteration 450: Train Loss: 5.6696
Iteration 450: Val Loss: 5.2092
Iteration 460: Train Loss: 5.5680
Iteration 470: Train Loss: 5.5984
Iteration 480: Train Loss: 5.3624
Iteration 490: Train Loss: 5.3864
Iteration 500: Train Loss: 5.2103
Iteration 500: Val Loss: 5.1801
Iteration 510: Train Loss: 5.1752
Iteration 520: Train Loss: 5.1021
Iteration 530: Train Loss: 5.2271
Iteration 540: Train Loss: 5.1406
Iteration 550: Train Loss: 5.5039
Iteration 550: Val Loss: 4.8520
Iteration 560: Train Loss: 5.4160
Iteration 570: Train Loss: 5.2527
Iteration 580: Train Loss: 5.0686
Iteration 590: Train Loss: 5.2050
Iteration 600: Train Loss: 5.1670
Iteration 600: Val Loss: 4.6655
Iteration 610: Train Loss: 5.2458
Iteration 620: Train Loss: 5.4917
Iteration 630: Train Loss: 5.1668
Iteration 640: Train Loss: 5.4378
Iteration 650: Train Loss: 5.0467
Iteration 650: Val Loss: 4.9134
Iteration 660: Train Loss: 5.0583
Iteration 670: Train Loss: 5.3384
Iteration 680: Train Loss: 5.1830
Iteration 690: Train Loss: 5.3243
Iteration 700: Train Loss: 5.5519
Iteration 700: Val Loss: 4.6602
Iteration 710: Train Loss: 5.1519
Iteration 720: Train Loss: 5.2517
Iteration 730: Train Loss: 5.5479
Iteration 740: Train Loss: 4.8300
Iteration 750: Train Loss: 5.2200
Iteration 750: Val Loss: 5.2112
Iteration 760: Train Loss: 5.1972
Iteration 770: Train Loss: 5.2952
Iteration 780: Train Loss: 5.0815
Iteration 790: Train Loss: 5.0875
Iteration 800: Train Loss: 4.7920
Iteration 800: Val Loss: 4.5389
Iteration 810: Train Loss: 5.3087
Iteration 820: Train Loss: 5.1749
Iteration 830: Train Loss: 5.1747
Iteration 840: Train Loss: 4.8641
Iteration 850: Train Loss: 5.1792
Iteration 850: Val Loss: 4.5581
Iteration 860: Train Loss: 5.1493
Iteration 870: Train Loss: 5.0613
Iteration 880: Train Loss: 5.3816
Iteration 890: Train Loss: 5.0833
Iteration 900: Train Loss: 4.9523
Iteration 900: Val Loss: 4.4919
Iteration 910: Train Loss: 5.0322
Iteration 920: Train Loss: 5.1941
Iteration 930: Train Loss: 5.2450
Iteration 940: Train Loss: 4.7896
Iteration 950: Train Loss: 5.1757
Iteration 950: Val Loss: 4.8143
Iteration 960: Train Loss: 5.0505
Iteration 970: Train Loss: 5.0156
Iteration 980: Train Loss: 4.9732
Iteration 990: Train Loss: 4.8786
Iteration 1000: Train Loss: 5.2669
Iteration 1000: Val Loss: 4.8553
Iteration 1010: Train Loss: 4.9935
Iteration 1020: Train Loss: 5.2168
Iteration 1030: Train Loss: 5.2579
Iteration 1040: Train Loss: 5.0913
Iteration 1050: Train Loss: 5.2794
Iteration 1050: Val Loss: 4.6395
Iteration 1060: Train Loss: 5.2068
Iteration 1070: Train Loss: 5.2241
Iteration 1080: Train Loss: 5.1511
Iteration 1090: Train Loss: 5.0812
Iteration 1100: Train Loss: 5.0844
Iteration 1100: Val Loss: 5.1170
Iteration 1110: Train Loss: 5.1939
Iteration 1120: Train Loss: 5.0737
Iteration 1130: Train Loss: 5.3372
Iteration 1140: Train Loss: 4.9381
Iteration 1150: Train Loss: 4.7883
Iteration 1150: Val Loss: 4.5997
Iteration 1160: Train Loss: 5.0672
Iteration 1170: Train Loss: 5.4448
Iteration 1180: Train Loss: 5.0648
Iteration 1190: Train Loss: 4.9743
Iteration 1200: Train Loss: 4.6116
Iteration 1200: Val Loss: 4.8205
Iteration 1210: Train Loss: 5.2453
Iteration 1220: Train Loss: 4.7412
Iteration 1230: Train Loss: 4.8684
Iteration 1240: Train Loss: 5.1760
Iteration 1250: Train Loss: 5.3189
Iteration 1250: Val Loss: 5.0830
Iteration 1260: Train Loss: 5.2602
Iteration 1270: Train Loss: 4.6341
Iteration 1280: Train Loss: 5.2059
Iteration 1290: Train Loss: 4.6825
Iteration 1300: Train Loss: 5.0866
Iteration 1300: Val Loss: 4.9743
Iteration 1310: Train Loss: 5.1249
Iteration 1320: Train Loss: 5.0175
Iteration 1330: Train Loss: 4.5174
Iteration 1340: Train Loss: 4.9588
Iteration 1350: Train Loss: 4.9621
Iteration 1350: Val Loss: 4.6097
Iteration 1360: Train Loss: 5.0133
Iteration 1370: Train Loss: 4.8175
Iteration 1380: Train Loss: 5.2172
Iteration 1390: Train Loss: 4.7302
Iteration 1400: Train Loss: 4.9993
Iteration 1400: Val Loss: 4.5459
Iteration 1410: Train Loss: 5.0840
Iteration 1420: Train Loss: 5.0240
Iteration 1430: Train Loss: 5.1066
Iteration 1440: Train Loss: 5.0478
Iteration 1450: Train Loss: 4.6883
Iteration 1450: Val Loss: 4.6908
Iteration 1460: Train Loss: 4.6297
Iteration 1470: Train Loss: 4.7381
Iteration 1480: Train Loss: 5.0102
Iteration 1490: Train Loss: 5.0545
Iteration 1500: Train Loss: 5.0442
Iteration 1500: Val Loss: 4.7355
Iteration 1510: Train Loss: 4.8490
Iteration 1520: Train Loss: 4.7744
Iteration 1530: Train Loss: 4.6408
Iteration 1540: Train Loss: 4.5655
Iteration 1550: Train Loss: 4.9006
Iteration 1550: Val Loss: 4.8906
Iteration 1560: Train Loss: 4.8619
Iteration 1570: Train Loss: 4.7300
Iteration 1580: Train Loss: 4.7964
Iteration 1590: Train Loss: 4.9122
Iteration 1600: Train Loss: 5.1016
Iteration 1600: Val Loss: 4.8598
Iteration 1610: Train Loss: 4.9264
Iteration 1620: Train Loss: 4.8799
Iteration 1630: Train Loss: 4.5715
Iteration 1640: Train Loss: 4.6946
Iteration 1650: Train Loss: 4.4759
Iteration 1650: Val Loss: 4.7600
Iteration 1660: Train Loss: 5.3415
Iteration 1670: Train Loss: 4.9768
Iteration 1680: Train Loss: 4.8765
Iteration 1690: Train Loss: 4.8574
Iteration 1700: Train Loss: 4.9180
Iteration 1700: Val Loss: 4.6761
Iteration 1710: Train Loss: 4.7242
Iteration 1720: Train Loss: 4.7494
Iteration 1730: Train Loss: 4.9355
Iteration 1740: Train Loss: 4.7282
Iteration 1750: Train Loss: 4.7378
Iteration 1750: Val Loss: 4.4823
Iteration 1760: Train Loss: 4.5994
Iteration 1770: Train Loss: 5.1252
Iteration 1780: Train Loss: 4.6363
Iteration 1790: Train Loss: 4.9492
Iteration 1800: Train Loss: 4.8451
Iteration 1800: Val Loss: 4.5595
Iteration 1810: Train Loss: 4.7570
Iteration 1820: Train Loss: 4.6422
Iteration 1830: Train Loss: 4.9111
Iteration 1840: Train Loss: 4.7313
Iteration 1850: Train Loss: 4.6365
Iteration 1850: Val Loss: 4.6089
Iteration 1860: Train Loss: 4.8570
Iteration 1870: Train Loss: 4.7519
Iteration 1880: Train Loss: 4.9028
Iteration 1890: Train Loss: 4.9786
Iteration 1900: Train Loss: 4.7612
Iteration 1900: Val Loss: 4.7270
Iteration 1910: Train Loss: 4.8063
Iteration 1920: Train Loss: 5.1502
Iteration 1930: Train Loss: 4.9250
Iteration 1940: Train Loss: 4.6597
Iteration 1950: Train Loss: 4.8417
Iteration 1950: Val Loss: 4.8027
Iteration 1960: Train Loss: 4.7347
Iteration 1970: Train Loss: 5.0726
Iteration 1980: Train Loss: 5.0349
Iteration 1990: Train Loss: 4.7310
Generated text after fine-tuning:
The purpose of Vikings by 1976 , &lt;unk&gt; Drew , from April 22 , 1991 , 1968 and the Browns 6 January . Sesbitt wrote that &#34; The episode should include the dancers but ]gisc hastily as some episodes , &#34; a jobling &#34; , argue that says that Busch or evidence , youramins was &#34; a certain hate firmly conservative &#34; . &#34; In addition to sad , the &lt;unk&gt; whiteihara declined to behavior , which the word mutualistic dog , &lt;unk&gt; himself applied for magic
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[124]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fine-tune with plot</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">GPTConfig</span><span class="p">,</span> <span class="n">GPT</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>

<span class="c1"># Define the directory containing the WikiText-2 dataset</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s1">'data/wikitext2'</span>
<span class="n">train_bin_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'train.bin'</span><span class="p">)</span>
<span class="n">val_bin_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'val.bin'</span><span class="p">)</span>

<span class="n">train_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">train_bin_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">val_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">val_bin_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>

<span class="c1"># Model hyperparameters</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># Match the block size in the checkpoint</span>
<span class="n">n_layer</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_head</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_embd</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Ensure bias is False to match the checkpoint</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># Fine-tune on fewer iterations for faster experimentation</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>  <span class="c1"># Max learning rate</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">1e-1</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># Clip gradients at this value</span>
<span class="n">decay_lr</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Whether to decay the learning rate</span>
<span class="n">warmup_iters</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># How many steps to warm up for</span>
<span class="n">lr_decay_iters</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># Adjust to match max_iters</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-6</span>  <span class="c1"># Minimum learning rate</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Load Pre-trained Shakespeare Model</span>
<span class="n">ckpt_path</span> <span class="o">=</span> <span class="s1">'out/ckpt.pt'</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Initialize the model with the adjusted config</span>
<span class="n">gptconf</span> <span class="o">=</span> <span class="n">GPTConfig</span><span class="p">(</span><span class="n">n_layer</span><span class="o">=</span><span class="n">n_layer</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="n">n_head</span><span class="p">,</span> <span class="n">n_embd</span><span class="o">=</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT</span><span class="p">(</span><span class="n">gptconf</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Load the checkpoint weights</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">])</span>

<span class="c1"># Initialize the optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Function to get a batch of data</span>
<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">data_subset</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data_subset</span> <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s1">'train'</span> <span class="k">else</span> <span class="n">val_ids</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ix</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Function to calculate the loss</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">evaluate_loss</span><span class="p">(</span><span class="n">data_subset</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">eval_interval</span><span class="p">):</span>
        <span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'val'</span><span class="p">,</span> <span class="n">data_subset</span><span class="p">)</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">Y_val</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Fine-tuning function</span>
<span class="k">def</span> <span class="nf">fine_tune</span><span class="p">(</span><span class="n">data_subset</span><span class="p">,</span> <span class="n">proportion_name</span><span class="p">):</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">iter_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iters</span><span class="p">):</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">data_subset</span><span class="p">)</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Track training loss</span>
        <span class="k">if</span> <span class="n">iter_num</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">proportion_name</span><span class="si">}</span><span class="s2"> - Iteration </span><span class="si">{</span><span class="n">iter_num</span><span class="si">}</span><span class="s2">: Train Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Return the last recorded training loss</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Experiment with different proportions of the dataset</span>
<span class="n">proportions</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">prop</span> <span class="ow">in</span> <span class="n">proportions</span><span class="p">:</span>
    <span class="c1"># Slice the training data based on the proportion</span>
    <span class="n">train_subset</span> <span class="o">=</span> <span class="n">train_ids</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span> <span class="o">*</span> <span class="n">prop</span><span class="p">)]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Fine-tuning on </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">prop</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">% of the dataset"</span><span class="p">)</span>
    <span class="n">final_loss</span> <span class="o">=</span> <span class="n">fine_tune</span><span class="p">(</span><span class="n">train_subset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">prop</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">final_loss</span><span class="p">)</span>

<span class="c1"># -----------------------------------------------------------------------------</span>
<span class="c1"># Plot character proportion vs. final loss</span>

<span class="n">proportions_percent</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">proportions</span><span class="p">]</span>  <span class="c1"># Convert proportions to percentages</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">proportions_percent</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Proportion of WikiText-2 Dataset Used (%)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Final Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Dataset Size vs. Final Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Training complete."</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>number of parameters: 7.23M

Fine-tuning on 25% of the dataset
25% - Iteration 0: Train Loss: 5.3057
25% - Iteration 10: Train Loss: 5.4673
25% - Iteration 20: Train Loss: 5.0113
25% - Iteration 30: Train Loss: 5.0332
25% - Iteration 40: Train Loss: 5.2630
25% - Iteration 50: Train Loss: 5.1698
25% - Iteration 60: Train Loss: 5.2154
25% - Iteration 70: Train Loss: 5.4060
25% - Iteration 80: Train Loss: 5.0978
25% - Iteration 90: Train Loss: 5.0623
25% - Iteration 100: Train Loss: 5.2048
25% - Iteration 110: Train Loss: 5.4148
25% - Iteration 120: Train Loss: 5.2000
25% - Iteration 130: Train Loss: 5.0087
25% - Iteration 140: Train Loss: 4.9982
25% - Iteration 150: Train Loss: 5.0975
25% - Iteration 160: Train Loss: 4.9916
25% - Iteration 170: Train Loss: 4.4230
25% - Iteration 180: Train Loss: 5.4673
25% - Iteration 190: Train Loss: 5.3917
25% - Iteration 200: Train Loss: 5.1423
25% - Iteration 210: Train Loss: 5.0210
25% - Iteration 220: Train Loss: 4.7675
25% - Iteration 230: Train Loss: 4.7455
25% - Iteration 240: Train Loss: 5.0150
25% - Iteration 250: Train Loss: 5.1658
25% - Iteration 260: Train Loss: 5.2855
25% - Iteration 270: Train Loss: 5.0480
25% - Iteration 280: Train Loss: 4.7757
25% - Iteration 290: Train Loss: 4.9621
25% - Iteration 300: Train Loss: 5.1677
25% - Iteration 310: Train Loss: 5.2845
25% - Iteration 320: Train Loss: 5.2471
25% - Iteration 330: Train Loss: 4.7265
25% - Iteration 340: Train Loss: 5.5953
25% - Iteration 350: Train Loss: 5.2644
25% - Iteration 360: Train Loss: 4.8658
25% - Iteration 370: Train Loss: 5.4352
25% - Iteration 380: Train Loss: 4.8685
25% - Iteration 390: Train Loss: 5.0577
25% - Iteration 400: Train Loss: 4.9254
25% - Iteration 410: Train Loss: 5.2907
25% - Iteration 420: Train Loss: 5.0605
25% - Iteration 430: Train Loss: 4.8422
25% - Iteration 440: Train Loss: 5.3357
25% - Iteration 450: Train Loss: 4.9103
25% - Iteration 460: Train Loss: 5.2766
25% - Iteration 470: Train Loss: 5.0929
25% - Iteration 480: Train Loss: 5.3235
25% - Iteration 490: Train Loss: 4.9449

Fine-tuning on 50% of the dataset
50% - Iteration 0: Train Loss: 5.3930
50% - Iteration 10: Train Loss: 5.0138
50% - Iteration 20: Train Loss: 5.2607
50% - Iteration 30: Train Loss: 5.0261
50% - Iteration 40: Train Loss: 5.4343
50% - Iteration 50: Train Loss: 5.0138
50% - Iteration 60: Train Loss: 5.2681
50% - Iteration 70: Train Loss: 5.0642
50% - Iteration 80: Train Loss: 5.2204
50% - Iteration 90: Train Loss: 5.0359
50% - Iteration 100: Train Loss: 5.2895
50% - Iteration 110: Train Loss: 4.9235
50% - Iteration 120: Train Loss: 5.3697
50% - Iteration 130: Train Loss: 4.9894
50% - Iteration 140: Train Loss: 4.9547
50% - Iteration 150: Train Loss: 5.3627
50% - Iteration 160: Train Loss: 5.3313
50% - Iteration 170: Train Loss: 5.3277
50% - Iteration 180: Train Loss: 4.9013
50% - Iteration 190: Train Loss: 4.8447
50% - Iteration 200: Train Loss: 5.4575
50% - Iteration 210: Train Loss: 4.8396
50% - Iteration 220: Train Loss: 5.1530
50% - Iteration 230: Train Loss: 5.1605
50% - Iteration 240: Train Loss: 4.9210
50% - Iteration 250: Train Loss: 5.0626
50% - Iteration 260: Train Loss: 5.3830
50% - Iteration 270: Train Loss: 5.2512
50% - Iteration 280: Train Loss: 5.2734
50% - Iteration 290: Train Loss: 5.1310
50% - Iteration 300: Train Loss: 5.2885
50% - Iteration 310: Train Loss: 5.0659
50% - Iteration 320: Train Loss: 4.7255
50% - Iteration 330: Train Loss: 5.1844
50% - Iteration 340: Train Loss: 5.2275
50% - Iteration 350: Train Loss: 4.8167
50% - Iteration 360: Train Loss: 5.1053
50% - Iteration 370: Train Loss: 4.6595
50% - Iteration 380: Train Loss: 5.2328
50% - Iteration 390: Train Loss: 5.2843
50% - Iteration 400: Train Loss: 4.9762
50% - Iteration 410: Train Loss: 4.9316
50% - Iteration 420: Train Loss: 4.9863
50% - Iteration 430: Train Loss: 5.3081
50% - Iteration 440: Train Loss: 5.0671
50% - Iteration 450: Train Loss: 5.3842
50% - Iteration 460: Train Loss: 5.1677
50% - Iteration 470: Train Loss: 5.1595
50% - Iteration 480: Train Loss: 5.1273
50% - Iteration 490: Train Loss: 4.7823

Fine-tuning on 75% of the dataset
75% - Iteration 0: Train Loss: 5.5179
75% - Iteration 10: Train Loss: 5.4259
75% - Iteration 20: Train Loss: 5.1226
75% - Iteration 30: Train Loss: 5.2932
75% - Iteration 40: Train Loss: 5.0386
75% - Iteration 50: Train Loss: 5.2563
75% - Iteration 60: Train Loss: 5.6256
75% - Iteration 70: Train Loss: 5.6457
75% - Iteration 80: Train Loss: 5.4431
75% - Iteration 90: Train Loss: 5.4035
75% - Iteration 100: Train Loss: 5.3437
75% - Iteration 110: Train Loss: 5.1761
75% - Iteration 120: Train Loss: 5.2520
75% - Iteration 130: Train Loss: 5.1618
75% - Iteration 140: Train Loss: 5.1193
75% - Iteration 150: Train Loss: 5.1288
75% - Iteration 160: Train Loss: 5.3329
75% - Iteration 170: Train Loss: 5.0523
75% - Iteration 180: Train Loss: 5.5578
75% - Iteration 190: Train Loss: 5.1577
75% - Iteration 200: Train Loss: 5.6520
75% - Iteration 210: Train Loss: 5.2295
75% - Iteration 220: Train Loss: 5.7286
75% - Iteration 230: Train Loss: 5.5400
75% - Iteration 240: Train Loss: 5.0999
75% - Iteration 250: Train Loss: 5.1768
75% - Iteration 260: Train Loss: 5.1221
75% - Iteration 270: Train Loss: 5.2760
75% - Iteration 280: Train Loss: 5.7020
75% - Iteration 290: Train Loss: 5.5906
75% - Iteration 300: Train Loss: 5.3335
75% - Iteration 310: Train Loss: 5.2398
75% - Iteration 320: Train Loss: 5.5316
75% - Iteration 330: Train Loss: 5.2659
75% - Iteration 340: Train Loss: 5.1177
75% - Iteration 350: Train Loss: 5.5474
75% - Iteration 360: Train Loss: 5.4261
75% - Iteration 370: Train Loss: 5.0821
75% - Iteration 380: Train Loss: 5.0811
75% - Iteration 390: Train Loss: 5.6907
75% - Iteration 400: Train Loss: 5.2416
75% - Iteration 410: Train Loss: 5.4125
75% - Iteration 420: Train Loss: 5.4920
75% - Iteration 430: Train Loss: 4.8667
75% - Iteration 440: Train Loss: 5.2610
75% - Iteration 450: Train Loss: 5.0057
75% - Iteration 460: Train Loss: 5.2152
75% - Iteration 470: Train Loss: 4.9891
75% - Iteration 480: Train Loss: 5.3891
75% - Iteration 490: Train Loss: 5.4044

Fine-tuning on 100% of the dataset
100% - Iteration 0: Train Loss: 5.7250
100% - Iteration 10: Train Loss: 5.1670
100% - Iteration 20: Train Loss: 5.2825
100% - Iteration 30: Train Loss: 5.3179
100% - Iteration 40: Train Loss: 5.5819
100% - Iteration 50: Train Loss: 5.5689
100% - Iteration 60: Train Loss: 5.3957
100% - Iteration 70: Train Loss: 5.4478
100% - Iteration 80: Train Loss: 5.4125
100% - Iteration 90: Train Loss: 5.5715
100% - Iteration 100: Train Loss: 5.2602
100% - Iteration 110: Train Loss: 5.1697
100% - Iteration 120: Train Loss: 5.4754
100% - Iteration 130: Train Loss: 5.6072
100% - Iteration 140: Train Loss: 5.6608
100% - Iteration 150: Train Loss: 5.6679
100% - Iteration 160: Train Loss: 5.8551
100% - Iteration 170: Train Loss: 5.3774
100% - Iteration 180: Train Loss: 5.1019
100% - Iteration 190: Train Loss: 4.9265
100% - Iteration 200: Train Loss: 5.3200
100% - Iteration 210: Train Loss: 4.9938
100% - Iteration 220: Train Loss: 5.6269
100% - Iteration 230: Train Loss: 5.5623
100% - Iteration 240: Train Loss: 5.3454
100% - Iteration 250: Train Loss: 5.6950
100% - Iteration 260: Train Loss: 5.2584
100% - Iteration 270: Train Loss: 5.0586
100% - Iteration 280: Train Loss: 5.3243
100% - Iteration 290: Train Loss: 5.5466
100% - Iteration 300: Train Loss: 5.2981
100% - Iteration 310: Train Loss: 5.3926
100% - Iteration 320: Train Loss: 5.0570
100% - Iteration 330: Train Loss: 5.3067
100% - Iteration 340: Train Loss: 5.6500
100% - Iteration 350: Train Loss: 5.3647
100% - Iteration 360: Train Loss: 5.6034
100% - Iteration 370: Train Loss: 4.8290
100% - Iteration 380: Train Loss: 5.4335
100% - Iteration 390: Train Loss: 5.0934
100% - Iteration 400: Train Loss: 6.0626
100% - Iteration 410: Train Loss: 5.2011
100% - Iteration 420: Train Loss: 5.2262
100% - Iteration 430: Train Loss: 5.2135
100% - Iteration 440: Train Loss: 5.0822
100% - Iteration 450: Train Loss: 4.5290
100% - Iteration 460: Train Loss: 5.1979
100% - Iteration 470: Train Loss: 5.6150
100% - Iteration 480: Train Loss: 5.2072
100% - Iteration 490: Train Loss: 5.6801
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWUElEQVR4nOzdeVhU9eLH8ffMsO+yCYgL4oKKu7lkpWYq2m5labnUrSxve7Z5b6ll+2a72S29adlqu/uSWeauGYqKiuLCKgoIAgNzfn/4kxu5AAqcAT6v55nncc6cmfnMl5GZD+ec77EYhmEgIiIiIiIiZ2Q1O4CIiIiIiIizU3ESEREREREph4qTiIiIiIhIOVScREREREREyqHiJCIiIiIiUg4VJxERERERkXKoOImIiIiIiJRDxUlERERERKQcKk4iIiIiIiLlUHESkVpr5syZWCyW0ouHhwdhYWH069eP559/nvT09HN+7G3btjFp0iT27t1bdYHPw6pVq5g0aRJHjx6t8H0WLlzIwIEDiYiIwN3dnYiICPr27csLL7xQZr1mzZoxZsyYqg3shMaMGVPm/fLXy48//lj6fqrun3l54z1p0qQz5vzrpW/fvuedxWKxMGnSpHO6b9++faskw7k+d2xsrCnPLSL1l4vZAUREzteMGTOIiYnBbreTnp7Or7/+yosvvsgrr7zC559/zmWXXVbpx9y2bRuTJ0+mb9++NGvWrOpDV9KqVauYPHkyY8aMISAgoNz1p02bxt133811113H22+/TWBgIPv372fVqlV89dVXPP7446XrfvPNN/j5+VVjeufh6enJsmXLTll+8v3z+++/Ex4ebkKy/7n99tuJi4srvZ6SksLQoUO59957GTFiROnyqviZ/f7770RGRp7Tfd99993zfn4RkdpExUlEar3Y2Fi6detWev26667jwQcf5KKLLmLo0KEkJibSsGFDExPWvOeff55LLrmEr776qszykSNH4nA4yizr3LlzTUYzldVqpWfPnme8PSQkpAbTnF5kZGSZMnNyC1iTJk3Omt1ut2OxWHBxqfhH+9kerzxt27Y95/uKiNRG2lVPROqkJk2a8Oqrr5Kbm8v7779funz9+vXcdNNNNGvWDE9PT5o1a8bw4cPZt29f6TozZ87khhtuAKBfv36lu0bNnDkTgMWLF3P11VcTGRmJh4cHLVq0YOzYsWRmZpbJkJGRwZ133knjxo1xd3cnJCSE3r17s2TJkjLrLVmyhP79++Pn54eXlxe9e/dm6dKlpbdPmjSJRx55BICoqKjSPD///PMZX//hw4fPuOXEai37q//vu4717dv3jLuHnRwDgNTUVMaOHUtkZCRubm5ERUUxefJkiouLz5gL4JprrqFp06anFDiAHj160KVLl9LrX375JT169MDf3x8vLy+aN2/ObbfddtbHP1en21Xv5C5h69at4+KLLy7N8MILL5TJX1BQwMMPP0ynTp3w9/cnMDCQXr168d1331VL1p9//hmLxcKsWbN4+OGHadSoEe7u7uzatYuMjAzGjRtH27Zt8fHxITQ0lEsvvZSVK1ee8jh/31Xv5BgsX76cu+++m+DgYIKCghg6dCiHDh0qc9+/76q3d+9eLBYLr7zyCq+99hpRUVH4+PjQq1cvVq9efcpzf/DBB7Rq1Qp3d3fatm3Lp59+ypgxY6psC6/D4eCll14iJiYGd3d3QkNDGTVqFAcOHCiz3qZNm7jiiisIDQ0t3aX18ssvL7NeTb4PRcR5aYuTiNRZQ4YMwWaz8csvv5Qu27t3L61bt+amm24iMDCQlJQU3nvvPS644AK2bdtGcHAwl19+Oc899xwTJkzgnXfeKf0iHx0dDcDu3bvp1asXt99+O/7+/uzdu5fXXnuNiy66iD///BNXV1fgxNadjRs38uyzz9KqVSuOHj3Kxo0bOXz4cGme2bNnM2rUKK6++mr++9//4urqyvvvv8+gQYNYuHAh/fv35/bbbycrK4u33nqLuXPnlhais/3Fv1evXnz99ddMmjSJa6+9ltjYWGw2W4XG7d133yUnJ6fMsieffJLly5fTunVr4ERp6t69O1arlaeeeoro6Gh+//13pkyZwt69e5kxY8YZH/+2227j6quvZtmyZWV2o9y+fTtr167lzTffBE7sRnbjjTdy4403MmnSJDw8PNi3b99pd7WrjL8XO4vFctaxSU1N5eabb+bhhx9m4sSJfPPNNzzxxBNEREQwatQoAAoLC8nKymL8+PE0atSIoqIilixZwtChQ5kxY0bpelXtiSeeoFevXkybNg2r1UpoaCgZGRkATJw4kbCwMI4dO8Y333xD3759Wbp0aYWOS7r99tu5/PLL+fTTT9m/fz+PPPIIt9xyS4XG/p133iEmJoapU6cCJ947Q4YMISkpCX9/fwCmT5/O2LFjue6663j99dfJzs5m8uTJFBYWnvNY/N3dd9/N9OnTueeee7jiiivYu3cvTz75JD///DMbN24kODiYvLw8BgwYQFRUFO+88w4NGzYkNTWV5cuXk5ubC1Tf+1BEaiFDRKSWmjFjhgEY69atO+M6DRs2NNq0aXPG24uLi41jx44Z3t7exhtvvFG6/MsvvzQAY/ny5WfN4HA4DLvdbuzbt88AjO+++670Nh8fH+OBBx44433z8vKMwMBA48orryyzvKSkxOjYsaPRvXv30mUvv/yyARhJSUlnzXPSrl27jNjYWAMwAMPT09Po37+/8fbbbxtFRUVl1m3atKkxevToMz7WyeeePn166bKxY8caPj4+xr59+8qs+8orrxiAsXXr1jM+nt1uNxo2bGiMGDGizPJHH33UcHNzMzIzM8s81tGjRyv0msszevTo0vH466V3796GYfzv/fTXMe7Tp48BGGvWrCnzWG3btjUGDRp0xucqLi427Ha78Y9//MPo3LlzmdvKG++/S0pKMgDj5ZdfLl22fPlyAzAuueSScu9/Mkv//v2Na6+9tsxtgDFx4sTS6yfHYNy4cWXWe+mllwzASElJKV3Wp08fo0+fPqfkbN++vVFcXFy6fO3atQZgzJkzxzCME+/vsLAwo0ePHmWeY9++fYarq6vRtGnTcl9Tnz59jHbt2p3x9oSEhNO+jjVr1hiAMWHCBMMwDGP9+vUGYHz77bdnfKyqfh+KSO2lXfVEpE4zDKPM9WPHjvHYY4/RokULXFxccHFxwcfHh7y8PBISEir0mOnp6dx11100btwYFxcXXF1dadq0KUCZx+jevTszZ85kypQprF69GrvdXuZxVq1aRVZWFqNHj6a4uLj04nA4iIuLY926deTl5Z3T646OjuaPP/5gxYoVTJ48mcsuu4x169Zxzz330KtXLwoKCir0OHPmzOHRRx/l3//+N3fccUfp8h9//JF+/foRERFRJvvgwYMBWLFixRkf08XFhVtuuYW5c+eSnZ0NQElJCbNmzeLqq68mKCgIgAsuuACAYcOG8cUXX3Dw4MFzGou/8vT0ZN26dWUuH3744VnvExYWRvfu3css69ChQ5ndO+HE7ly9e/fGx8en9H3x4YcfVvh9dS6uu+660y6fNm0aXbp0wcPDozTL0qVLK5zlqquuKnO9Q4cOAKe85tO5/PLLy2zB+/t9d+zYQWpqKsOGDStzvyZNmtC7d+8K5SvP8uXLAU6ZvbB79+60adOmdFfYFi1a0KBBAx577DGmTZvGtm3bTnms6ngfikjtpOIkInVWXl4ehw8fJiIionTZiBEjePvtt7n99ttZuHAha9euZd26dYSEhHD8+PFyH9PhcDBw4EDmzp3Lo48+ytKlS1m7dm3pMRx/fYzPP/+c0aNH85///IdevXoRGBjIqFGjSE1NBSAtLQ2A66+/HldX1zKXF198EcMwyMrKOufXb7VaueSSS3jqqaf4/vvvOXToEDfeeCMbNmzgo48+Kvf+y5cvZ8yYMYwaNYpnnnmmzG1paWn88MMPp+Ru164dwCnHe/3dbbfdRkFBAZ999hlwYur0lJQUbr311tJ1LrnkEr799luKi4sZNWoUkZGRxMbGMmfOnMoORSmr1Uq3bt3KXE7ufngmJ4vcX7m7u5f5Wc+dO5dhw4bRqFEjZs+eze+//866detKX2d1Od1xbK+99hp33303PXr04Ouvv2b16tWsW7eOuLi4Cr3H4dTX7O7uDlCh+5d335O7qp5uwpaqmsTl5HOcbnwiIiJKb/f392fFihV06tSJCRMm0K5dOyIiIpg4cWLpHzqq430oIrWTjnESkTrrp59+oqSkpPSYjuzsbH788UcmTpxYZjruk8enVER8fDx//PEHM2fOZPTo0aXLd+3adcq6wcHBTJ06lalTp5KcnMz333/P448/Tnp6OgsWLCA4OBiAt95664yzm1XlbIDe3t488cQTfP7558THx5913S1btnDNNdfQp08fPvjgg1NuDw4OpkOHDjz77LOnvf9fy+rptG3blu7duzNjxgzGjh3LjBkziIiIYODAgWXWu/rqq7n66qspLCxk9erVPP/884wYMYJmzZrRq1evcl5xzZk9ezZRUVF8/vnnWCyW0uVVeczO6fz1uf6apW/fvrz33ntllp88ZsdsJ4vVyT8c/NXJPypU1XOkpKScMt36oUOHSv/vAbRv357PPvsMwzDYsmULM2fO5Omnn8bT07P090RteR+KSPXSFicRqZOSk5MZP348/v7+jB07FjjxJdMwjNK/gJ/0n//8h5KSkjLLzvQX9pNfVP/+GH+due90mjRpwj333MOAAQPYuHEjAL179yYgIIBt27adshXk5MXNze2sec4kJSXltMtP7qp1tmKTnJzM4MGDad68OV9//XXpZBd/dcUVVxAfH090dPRpc5dXnABuvfVW1qxZw6+//soPP/zA6NGjzzhJg7u7O3369OHFF18ETsyE5kwsFgtubm5likxqamq1zapXXpa/vz+3bNnC77//XuNZTqd169aEhYXxxRdflFmenJzMqlWrquQ5Lr30UuBEifyrdevWkZCQQP/+/U+5j8VioWPHjrz++usEBASU/j/9K2d/H4pI9dIWJxGp9eLj40uPsUlPT2flypXMmDEDm83GN998U3puHj8/Py655BJefvllgoODadasGStWrODDDz885aSysbGxwInZv3x9ffHw8CAqKoqYmBiio6N5/PHHMQyDwMBAfvjhBxYvXlzm/tnZ2fTr148RI0YQExODr68v69atY8GCBQwdOhQAHx8f3nrrLUaPHk1WVhbXX3996axof/zxBxkZGaVbDdq3bw/AG2+8wejRo3F1daV169b4+vqedkzatWtH//79GTx4MNHR0RQUFLBmzRpeffVVGjZsyD/+8Y8zjufgwYM5evQob7/9Nlu3bi1zW3R0NCEhITz99NMsXryYCy+8kPvuu4/WrVtTUFDA3r17mTdvHtOmTSv3xKrDhw/noYceYvjw4RQWFp5yPMpTTz3FgQMH6N+/P5GRkRw9epQ33ngDV1dX+vTpU7qei4sLffr0KTOFe0274oormDt3LuPGjeP6669n//79PPPMM4SHh5OYmFjjWZ555hkmTpxInz592LFjB08//TRRUVHlThVfE6xWK5MnT2bs2LFcf/313HbbbRw9epTJkycTHh5+ynT5Z5KTk3PKecrgxLm4+vTpw5133slbb72F1Wpl8ODBpbPqNW7cmAcffBA4cazeu+++yzXXXEPz5s0xDIO5c+dy9OhRBgwYAFT8fSgi9YCZM1OIiJyPkzOAnby4ubkZoaGhRp8+fYznnnvOSE9PP+U+Bw4cMK677jqjQYMGhq+vrxEXF2fEx8efdqazqVOnGlFRUYbNZjMAY8aMGYZhGMa2bduMAQMGGL6+vkaDBg2MG264wUhOTi4zQ1lBQYFx1113GR06dDD8/PwMT09Po3Xr1sbEiRONvLy8Ms+zYsUK4/LLLzcCAwMNV1dXo1GjRsbll19ufPnll2XWe+KJJ4yIiAjDarWWO+Pf+++/bwwdOtRo3ry54eXlZbi5uRnR0dHGXXfdZezfv7/Mun9/7Zxm5rmTl5NjYBiGkZGRYdx3331GVFSU4erqagQGBhpdu3Y1/vWvfxnHjh07Y7a/GjFiRJmZ7f7qxx9/NAYPHmw0atSo9Gc7ZMgQY+XKlWXWA8rM7nYmo0ePNry9vc94+5lm1Tvd7G2jR48+Zfa3F154wWjWrJnh7u5utGnTxvjggw+MiRMnGn//qK3KWfX+/h4xDMMoLCw0xo8fbzRq1Mjw8PAwunTpYnz77benzcwZZtX7+0yVJ5/vr++5M82q99ecZ3oewzCM6dOnGy1atDDc3NyMVq1aGR999JFx9dVXnzIL4emcnO3wdJeTmUpKSowXX3zRaNWqleHq6moEBwcbt9xyS5n3//bt243hw4cb0dHRhqenp+Hv7290797dmDlzZuk6FX0fikjdZzGMv005JSIiIlLDjh49SqtWrbjmmmuYPn262XFERE6hXfVERESkRqWmpvLss8/Sr18/goKC2LdvH6+//jq5ubncf//9ZscTETktFScRERGpUe7u7uzdu5dx48aRlZWFl5cXPXv2ZNq0aaVT2ouIOBvtqiciIiIiIlIOTUcuIiIiIiJSDhUnERERERGRcqg4iYiIiIiIlKPeTQ7hcDg4dOgQvr6+Zc7wLiIiIiIi9YthGOTm5hIREVHuCbjrXXE6dOgQjRs3NjuGiIiIiIg4if379xMZGXnWdepdcfL19QVODI6fn5/JaWo3u93OokWLGDhwIK6urmbHqTc07jVPY24Ojbs5NO7m0LibQ+NuDmca95ycHBo3blzaEc6m3hWnk7vn+fn5qTidJ7vdjpeXF35+fqa/6esTjXvN05ibQ+NuDo27OTTu5tC4m8MZx70ih/BocggREREREZFyqDiJiIiIiIiUQ8VJRERERESkHPXuGKeKMAyD4uJiSkpKzI7i1Ox2Oy4uLhQUFNS7sbLZbLi4uGhKexEREZF6QsXpb4qKikhJSSE/P9/sKE7PMAzCwsLYv39/vSwQXl5ehIeH4+bmZnYUEREREalmKk5/4XA4SEpKwmazERERgZubW70sBBXlcDg4duwYPj4+5Z4wrC4xDIOioiIyMjJISkqiZcuW9er1i4iIiNRHKk5/UVRUhMPhoHHjxnh5eZkdx+k5HA6Kiorw8PCod8XB09MTV1dX9u3bVzoGIiIiIlJ31a9vuxVU30qAnBu9T0RERETqD33zExERERERKYeKk4iIiIiISDlUnKpJicPg992H+W7zQX7ffZgSh2F2pErr27cvDzzwQIXX37t3LxaLhc2bN1dbJhERERERM2hyiGqwID6FyT9sIyW7oHRZuL8HE69sS1xseJU/X3kz/40ePZqZM2dW+nHnzp2Lq6trhddv3LgxKSkpBAcHV/q5KmPv3r1ERUWxadMmOnXqVK3PJSIiIiICKk5VbkF8CnfP3sjfty+lZhdw9+yNvHdLlyovTykpKaX//vzzz3nqqafYsWNH6TJPT88y69vt9goVosDAwErlsNlshIWFVeo+IiIiIiK1gXbVK4dhGOQXFVfokltgZ+L3W08pTUDpsknfbyO3wF6hxzOMiu3eFxYWVnrx9/fHYrGUXi8oKCAgIIAvvviCvn374uHhwezZszl8+DDDhw8nMjISLy8v2rdvz5w5c8o87t931WvWrBnPPfcct912G76+vjRr1qzMlqy/76r3888/Y7FYWLp0Kd26dcPLy4sLL7ywTKkDmDJlCqGhofj6+nL77bfz+OOPn9eWpMLCQu677z5CQ0Px8PDgoosuYt26daW3HzlyhJtvvpmQkBA8PT1p2bIlM2bMAE5MSX/PPfcQHh6Oh4cHzZo14/nnnz/nLCIiIiLyPyUOgzVJWWzItLAmKatWHc6iLU7lOG4voe1TC6vksQwgNaeA9pMWVWj9bU8Pwsutan5Ejz32GK+++iozZszA3d2dgoICunbtymOPPYafnx8//fQTI0eOpHnz5vTo0eOMj/Pqq6/yzDPPMGHCBL788ksefvhhBg4cSNu2bc94n3/961+8+uqrhISEcNddd3Hbbbfx22+/AfDJJ5/w7LPP8u6779K7d28+++wzXn31VaKios75tT766KN8/fXX/Pe//6Vp06a89NJLDBo0iF27dhEYGMiTTz7Jtm3bmD9/PsHBwezatYvjx48D8Oabb/L999/zxRdf0KRJE/bv38/+/fvPOYuIiIiInFD2cBYbHyeur9bDWaqailM98cADDzB06NAyy8aPH1/673vvvZcFCxbw5ZdfnrU4DRkyhHHjxgEnCsrrr7/Ozz//fNbi9Oyzz9KnTx8AHn/8cS6//HIKCgrw8PDgrbfe4h//+Ae33norAE899RSLFi3i2LFj5/Q68/LyeO+995g5cyaDBw8G4IMPPmDx4sV8+OGHPPLIIyQnJ9O5c2e6desGnNiSdlJycjItW7bkoosuwmKx0LRp03PKISIiIiL/Y8bhLFVNxakcnq42tj09qELrrk3KYsyMdeWuN/PWC+geVf7xQ56utgo9b0WcLAknlZSU8MILL/D5559z8OBBCgsLKSwsxNvb+6yP06FDh9J/WywWQkNDycjIqPB9wsNP/IdIT0+nSZMm7Nixo7SIndS9e3eWLVtWodf1d7t378Zut9O7d+/SZa6urnTv3p2EhAQA7r77bq677jo2btzIwIEDueaaa7jwwgsBGDNmDAMGDKB169bExcVxxRVXMHDgwHPKIiIiIiInds+b/MO2Mx7OYgEm/7CNAW3DsFnPPumZmXSMUzksFgtebi4VulzcMoRwfw/O9OO2cGJ2vYtbhlTo8cqbLa8y/l6IXn31VV5//XUeffRRli1bxubNmxk0aBBFRUVnfZy/TyphsVhwOBwVvs/J1/TX+/z9dVb02K7TOXnf0z3myWWDBw9m3759PPDAAxw6dIj+/fuXbn3r0qULSUlJPPPMMxw/fpxhw4Zx/fXXn3MeERERkfpubVJWmdmm/84AUrILWJuUVXOhzoGKUxWyWS1MvPLELmt/rzwnr0+8sq1TNOmVK1dy9dVXc8stt9CxY0eaN29OYmJijedo3bo1a9euLbNs/fr15/x4LVq0wM3NjV9//bV0md1uZ/369bRp06Z0WUhICGPGjGH27NlMnTqV6dOnl97m5+fHjTfeyAcffMDnn3/O119/TVaWc/9HFhEREXFWB4/mV2i99NwzlytnoF31qlhcbDjv3dLllPM4hTnZgW8tWrTg66+/ZtWqVTRo0IDXXnuN1NTUMuWiJtx7773ccccddOvWjQsvvJDPP/+cLVu20Lx583Lv+/fZ+QDatm3L3XffzSOPPEJgYCBNmjThpZdeIj8/n3/84x/AieOounbtSrt27SgsLOTHH38sfd2vv/464eHhdOrUCavVypdffklYWBgBAQFV+rpFRERE6jqHw+CHLYd4Yd72Cq0f6utRzYnOj4pTNYiLDWdA2zDWJmWRnltAqK8H3aMCnWJL00lPPvkkSUlJDBo0CC8vL+68806uueYasrOzazTHzTffzJ49exg/fjwFBQUMGzaMMWPGnLIV6nRuuummU5YlJSXxwgsv4HA4GDlyJLm5uXTr1o2FCxfSoEEDANzc3HjiiSfYu3cvnp6eXHzxxXz22WcA+Pj48OKLL5KYmIjNZuOCCy5g3rx5WK3aOCsiIiJSUat2Z/L8vO38efDEd0urBc4087iFExsZKjIHgJksxvkcUFIL5eTk4O/vT3Z2Nn5+fmVuKygoICkpiaioKDw8nLvxOgOHw0FOTg5+fn5VWiwGDBhAWFgYs2bNqrLHrA5mvV/sdjvz5s1jyJAhFTqRsZw/jbk5NO7m0LibQ+NuDo171duZlssL87ezbHs6AD7uLtzdN5rIBp488NlmgDKTRJzcrGDWrHpn6wZ/py1OYqr8/HymTZvGoEGDsNlszJkzhyVLlrB48WKzo4mIiIhIBaXlFPDaop18uWE/DgNcrBZu7tGE+/q3JMjHHQB3F6vTH85yNipOYiqLxcK8efOYMmUKhYWFtG7dmq+//prLLrvM7GgiIiIiUo5jhcVMX7GbD1YmcdxeAsDg2DAejYshKrjsrM4nD2f5fVc6i1auYeDFPejVItSpDmc5GxUnMZWnpydLliwxO4aIiIiIVIK9xMFn6/bzxpKdZB47cTqbrk0bMGFIG7o2bXDG+9msFnpEBXI4waCHk80BUB4VJxERERERqRDDMFi0LY0XF2xnT0YeAFHB3jwW15pB7cKq9DykzkbF6TTq2XwZco70PhEREZH6ZGPyEZ6fl8C6vUcACPJ24/7LWjK8exNcbXV/BmIVp784OZtKfn4+np6eJqcRZ5eff+JkbpqFR0REROqyvZl5vLxwBz/9mQKAh6uV2y9qztg+zfH1qD/fg1Sc/sJmsxEQEEB6+onpE728vOr05sbz5XA4KCoqoqCgoF6d58gwDPLz80lPTycgIACbzWZ2JBEREZEql5VXxJtLE/lkzT7sJQYWC9zQNZIHB7Qi3L/+bWRQcfqbsLAwgNLyJGdmGAbHjx/H09OzXhbMgICA0veLiIiISF1RYC/ho9+SeG/5bnILiwHo0yqEJ4bEEBN29nMd1WUqTn9jsVgIDw8nNDQUu91udhynZrfb+eWXX7jkkkvq3e5qrq6u2tIkIiIidUqJw+CbTQd5ddGO0nMttYvw44nBbbioZbDJ6cyn4nQGNptNX4zLYbPZKC4uxsPDo94VJxEREZG6ZGViBs/N205CSg4AjQI8GT+oFVd3bIS1Fk0ZXp1UnERERERE6qlth3J4fn4CKxMzAfD1cOGefi0YfWEzPFy1EeGvVJxEREREROqZQ0eP8+qinczddADDAFebhZE9m3HvpS1o4O1mdjynpOIkIiIiIlJP5BTYee/n3Xz0axKFxQ4ArugQzqODYmgS5GVyOuem4iQiIiIiUscVFTv4ZM0+3lyayJH8ExOgdW8WyITL29CpcYC54WoJFScRERERkTrKMAzmx6fy0oLt7D2cD0B0iDePD27DZW1C6+UpZc6VipOIiIiISB20fm8Wz85LYFPyUQCCfdx5cEBLbuzWGBeb1dxwtZCKk4iIiIhIHbI74xgvLdjOwq1pAHi62rjzkubceUlzvN319f9caeREREREROqAzGOFvLEkkU/XJlPiMLBa4MYLmvDgZS0J9fMwO16tp+IkIiIiIlKL5RcV8+HKJKat2E1eUQkAl7UJ5bG4GFo29DU5Xd2h4iQiIiIiUguVOAy+2rCf1xbvJC2nEIAOkf48MbgNvaKDTE5X96g4iYiIiIjUIoZh8POODJ6fn8DOtGMANA705JFBMVzRPhyrVTPlVQcVJxERERGRWiL+YDbPzUtg1e7DAPh7unLvpS0Y2asp7i42k9PVbSpOIiIiIiJO7sCRfF5ZuINvNx8CwM3Fyq0XNmNc3xb4e7manK5+UHESEREREXFS2fl23vl5FzN/20tRiQOAazpFMH5QayIbeJmcrn5RcRIRERERcTKFxSXM+n0fby3bRfZxOwAXRgcxYUgbYhv5m5yuflJxEhERERFxEg6HwQ9bDvHywh0cOHIcgNYNfXl8SAx9W4VgsWjiB7OoOImIiIiIOIHVew7z3LwEthzIBiDU152HB7bi+q6NsWmmPNOpOImIiIiImCgxLZcX5m9n6fZ0ALzdbNzVJ5p/XByFl5u+rjsL/SREREREREyQnlPA60t28vm6/TgMsFktjOjehPsva0mwj7vZ8eRvrGY++aRJk7BYLGUuYWFhZ71PYWEh//rXv2jatCnu7u5ER0fz0Ucf1VBiEREREZHzk1dYzOuLd9L3lZ+Zs/ZEaRrUriGLHryEZ66JVWlyUqZvcWrXrh1LliwpvW6znf3EXcOGDSMtLY0PP/yQFi1akJ6eTnFxcXXHFBERERE5L8UlDj5fv5/XFyeSeawQgM5NApgwpA0XNAs0OZ2Ux/Ti5OLiUu5WppMWLFjAihUr2LNnD4GBJ95czZo1q8Z0IiIiIiLnxzAMliSk88L8BHZn5AHQNMiLx+JiGBwbppnyagnTi1NiYiIRERG4u7vTo0cPnnvuOZo3b37adb///nu6devGSy+9xKxZs/D29uaqq67imWeewdPT87T3KSwspLCwsPR6Tk4OAHa7HbvdXvUvqB45OX4ax5qlca95GnNzaNzNoXE3h8bdHDUx7n8cyObFhTtZt/cIAA28XLmnXzQ3dYvEzcVaL/eccqb3e2UyWAzDMKoxy1nNnz+f/Px8WrVqRVpaGlOmTGH79u1s3bqVoKCgU9aPi4vj559/5rLLLuOpp54iMzOTcePGcemll57xOKdJkyYxefLkU5Z/+umneHnpbMsiIiIiUvUyC+DHZCubDp+YUsDVYtAnwuCyCAeepm+6kJPy8/MZMWIE2dnZ+Pn5nXVdU4vT3+Xl5REdHc2jjz7KQw89dMrtAwcOZOXKlaSmpuLvf+KMyXPnzuX6668nLy/vtFudTrfFqXHjxmRmZpY7OHJ2drudxYsXM2DAAFxdXc2OU29o3GuextwcGndzaNzNoXE3R3WM+5H8It79eQ+frN2PvcTAYoFrO0XwQP8WhPt7VMlz1HbO9H7PyckhODi4QsXJqfqut7c37du3JzEx8bS3h4eH06hRo9LSBNCmTRsMw+DAgQO0bNnylPu4u7vj7n7qzCSurq6m/6DqCo2lOTTuNU9jbg6Nuzk07ubQuJujKsa9wF7CzFV7eWf5LnILTux+d0mrEB6Pi6FthP5YfzrO8H6vzPM7VXEqLCwkISGBiy+++LS39+7dmy+//JJjx47h4+MDwM6dO7FarURGRtZkVBERERERHA6Dbzcf5NVFOzl49DgAbcL9mDAkhotbhpicTqqSqedxGj9+PCtWrCApKYk1a9Zw/fXXk5OTw+jRowF44oknGDVqVOn6I0aMICgoiFtvvZVt27bxyy+/8Mgjj3DbbbedcXIIEREREZHq8GtiJle89SsPffEHB48eJ9zfg1dv6MiP916k0lQHmbrF6cCBAwwfPpzMzExCQkLo2bMnq1evpmnTpgCkpKSQnJxcur6Pjw+LFy/m3nvvpVu3bgQFBTFs2DCmTJli1ksQERERkXomISWHF+ZvZ8XODAB83V24u180t/WOwsP17OckldrL1OL02WefnfX2mTNnnrIsJiaGxYsXV1MiEREREZHTS80u4NVFO/hq4wEMA1ysFm7p2ZT7+rck0NvN7HhSzZzqGCcREREREWeTW2Bn2ordfPhrEgV2BwCXtw/nkUGtaRbsbXI6qSkqTiIiIiIip2EvcTBnbTJvLEnkcF4RABc0a8CEIW3o3KSByemkpqk4iYiIiIj8hWEYLNyayosLdpCUmQdA8xBvHo+LYUDbhlgsFpMTihlUnERERERE/t+GfVk8N287G/YdASDYx437L2vFTRc0xtVm6oTUYjIVJxERERGp95Iy83hx/nYWbE0FwNPVxh0XR3Fnn2h83PWVWVScRERERKQeO2aHp39MYM66AxQ7DKwWGNatMQ8OaEVDPw+z44kTUXESERERkXrneFEJH/yyh3c22Sgs2Q/ApTGhPBYXQ+swX5PTiTNScRIRERGReqPEYfD1xgO8tmgnqTkFgIV2Eb786/K2XBgdbHY8cWIqTiIiIiJS5xmGwYqdGbwwfzvbU3MBaBTgwaXBefx7ZE/c3XUCWzk7FScRERERqdPiD2bzwvzt/LorEwA/DxfuvbQlw7tFsHTxQqxWTS8u5VNxEhEREZE66eDR47y6cAffbD6IYYCbzcroC5vyz34tCPByw263mx1RahEVJxERERGpU7KP23n3513M+G0vRcUOAK7qGMEjg1rTONDL5HRSW6k4iYiIiEidUFTsYNbqfby1LJGj+Se2JvVsHsiEIW3oEBlgbjip9VScRERERKRWMwyDH7ek8PLCHSRn5QPQMtSHJ4bE0K91KBaLjmGS86fiJCIiIiK11tqkLJ6dl8Af+48CEOrrzkMDWnF910hcbFZzw0mdouIkIiIiIrXOrvRjvDB/O0sS0gDwcrMx9pJo7rgkCi83fcWVqqd3lYiIiIjUGum5BUxdksjn6/ZT4jCwWS3cdEFjHrisFSG+7mbHkzpMxUlEREREnF5eYTEfrNzD9F/2kF9UAsCAtg15LC6GFqE+JqeT+kDFSUREREScVnGJgy83HOC1xTvJyC0EoGPjACYMjqFH8yCT00l9ouIkIiIiIk7HMAyWbU/nhfnbSUw/BkCTQC8ejWvN5e3DNVOe1DgVJxERERFxKlsOHOW5eQms3pMFQICXK/dd2pJbejbFzUUz5Yk5VJxERERExCnsz8rn5YU7+P6PQwC4uVi5rXcUd/eNxt/T1eR0Ut+pOImIiIiIqY7mF/H2sl18/Ps+ikocWCxwbedGPDywNY0CPM2OJwKoOImIiIiISQrsJXz8+17eXraLnIJiAC5qEczjg2OIbeRvcjqRslScRERERKRGORwG3/9xiJcX7uDg0eMAxIT58sSQNlzSMlgTP4hTUnESERERkRqzalcmz81PIP5gDgBhfh48PLAVQ7tEYrOqMInzUnESERERkWq3My2X5+clsHxHBgA+7i7c3Tea23pH4elmMzmdSPlUnERERESk2qTlFPDaop18uWE/DgNcrBZu6dmUey9tQZCPu9nxRCpMxUlEREREqtyxwmLeX7GbD1buocDuAGBwbBiPxsUQFextcjqRylNxEhEREZEqYy9x8NnaZKYuSeRwXhEAXZs2YMKQNnRt2sDkdCLnTsVJRERERM6bYRgs2pbGi/O3syczD4CoYG8ei2vNoHZhmilPaj0VJxERERE5LxuTj/D8vATW7T0CQJC3G/df1pLh3ZvgarOanE6kaqg4iYiIiMg52ZuZx0sLtzPvz1QAPFyt3H5Rc8b2aY6vh6vJ6USqloqTiIiIiFRKVl4Rby5N5JM1+7CXGFgscEPXSB4a0Jowfw+z44lUCxUnEREREamQAnsJH/2WxHvLd5NbWAxA39YhPD44hpgwP5PTiVQvFScREREROasSh8E3mw7y6qIdpGQXANAuwo8JQ9rQu0WwyelEaoaKk4iIiIic0S87M3h+/nYSUnIAaBTgyfhBrbi6YyOsVs2UJ/WHipOIiIiInGLboRyen5/AysRMAHw9XLinXwtGX9gMD1ebyelEap6Kk4iIiIiUOnT0OK8u2sncTQcwDHC1WRjVqxn39GtBA283s+OJmEbFSURERETIKbDz3s+7+ejXJAqLHQBc2TGCRwa2pkmQl8npRMyn4iQiIiJSjxUVO/hkzT7eXJrIkXw7AN2jApkwpA2dGgeYG07Eiag4iYiIiNRDhmEw789UXlq4nX2H8wGIDvHmicFt6N8mFItFEz+I/JWKk4iIiEg9s25vFs/+lMDm/UcBCPZx58EBLbmxW2NcbFZzw4k4KRUnERERkXpid8YxXpy/nUXb0gDwdLVx5yXNufOS5ni762uhyNnof4iIiIhIHZeRW8gbS3cyZ+1+ShwGVgvceEETHrysJaF+HmbHE6kVVJxERERE6qj8omI+XJnEtBW7ySsqAeCyNqE8PjiGFqG+JqcTqV1UnERERETqmBKHwVcb9vPa4p2k5RQC0DHSnyeGtKFn8yCT04nUTipOIiIiInWEYRj8vCOD5+cnsDPtGACNAz15ZFAMV7QPx2rVTHki50rFSURERKQO+PNANs/NS+D3PYcB8Pd05d5LWzCyV1PcXWwmpxOp/VScRERERGqx/Vn5vLJoB99tPgSAm4uVWy9sxri+LfD3cjU5nUjdoeIkIiIiUgtl59t55+ddzPxtL0UlDgCu6RTB+EGtiWzgZXI6kbpHxUlERESkFiksLmHW7/t4a9kuso/bAbgwOogJQ9oQ28jf5HQidZeKk4iIiEgt4HAY/LDlEC8v3MGBI8cBaN3Ql8eHxNC3VQgWiyZ+EKlOKk4iIiIiTu733Yd5fn4CWw5kA9DQz52HB7Tmuq6R2DRTnkiNUHESERERcVKJabm8MH87S7enA+DtZuPuvtHcdlEUXm76GidSk/Q/TkRERMTJpOcU8PqSnXy+bj8OA2xWCyO6N+H+y1oS7ONudjyReknFSURERMRJ5BUW89HPSXzwyx6O20sAGNSuIY/GxRAd4mNyOpH6TcVJRERExGTFJQ5+TbXwzNRfyTxWBECXJgFMGNKGbs0CTU4nIqDiJCIiImIawzBYkpDO8/MS2JNpA4poFuTFY3ExxMWGaaY8ESei4iQiIiJigs37j/LcvATWJmUB4O1i8NCgNozsFYWbi9XkdCLydypOIiIiIjVo3+E8Xlq4g5+2pADg7mLl1gub0ux4Itf1bIKrSpOIU1JxEhEREakBR/KKeHNZIrNX78NeYmCxwHVdInl4YCuCvVyYNy/R7IgichYqTiIiIiLVqMBewsxVe3ln+S5yC4oBuKRVCI/HxdA2wg8Au91uZkQRqQAVJxEREZFq4HAYfLv5IK8s3MGh7AIA2oT7MWFIDBe3DDE5nYhUloqTiIiISBX7NTGT5+YlsC0lB4AIfw8eHtiaazo3wmbVTHkitZGKk4iIiEgVSUjJ4YX521mxMwMAX3cXxvVrwa29m+HhajM5nYicDxUnERERkfOUkn2c1xbt5KuNBzAMcLVZuKVnU+69tCWB3m5mxxORKqDiJCIiInKOcgvsTFuxmw9/TaLA7gDg8vbhPBrXmqZB3ianE5GqpOIkIiIiUkn2EgefrknmjaWJZOUVAXBBswZMGNKGzk0amJxORKqDipOIiIhIBRmGwYL4VF5auIOkzDwAmod483hcDAPaNsRi0cQPInWVipOIiIhIBWzYl8Vz87azYd8RAIJ93HjgslbceEFjXG1Wk9OJSHVTcRIRERE5iz0Zx3hpwQ4WbE0FwNPVxh2XNOfOS5rj466vUiL1hf63i4iIiJxG5rFC3lyayKdrkil2GFgtMKxbYx4c0IqGfh5mxxORGqbiJCIiIvIXx4tK+PDXPUxbsYdjhcUAXBoTyuODY2jV0NfkdCJiFhUnEREREaDEYfD1hgO8ungHaTmFAMQ28mPCkDZcGB1scjoRMZuKk4iIiNRrhmGwYmcGL8zfzvbUXAAaBXjyaFxrruwQgdWqmfJERMVJRERE6rH4g9k8Pz+B33YdBsDPw4V7L23JyF5N8XC1mZxORJyJipOIiIjUOweO5PPaop18s/kghgFuNiujL2zKP/u1IMDLzex4IuKEVJxERESk3sg+bufd5buYsWovRcUOAK7uFMH4ga1pHOhlcjoRcWYqTiIiIlLnFRaXMHt1Mm8tS+Rovh2Ans0DmTCkDR0iA8wNJyK1goqTiIiI1HolDoO1SVmk5xYQ6utB96hAbFYLhmHw45YUXlq4nf1ZxwFoGerDE0Ni6Nc6FItFEz+ISMWoOImIiEittiA+hck/bCMlu6B0Wbi/B8O7N2FpQhp/HMgGINTXnYcGtOL6rpG42KxmxRWRWkrFSURERGqtBfEp3D17I8bflqdkF/Da4p0AeLnZGHtJNHdcEoWXm776iMi5MfXPLZMmTcJisZS5hIWFVei+v/32Gy4uLnTq1Kl6Q4qIiIhTKnEYTP5h2yml6a+83Gwse7gv91/WUqVJRM6L6b9B2rVrx5IlS0qv22zlnzMhOzubUaNG0b9/f9LS0qoznoiIiDiptUlZZXbPO538ohKSMvMI8/eooVQiUleZXpxcXFwqvJXppLFjxzJixAhsNhvffvtt9QQTERERp5aee/bSVNn1RETOxvTilJiYSEREBO7u7vTo0YPnnnuO5s2bn3H9GTNmsHv3bmbPns2UKVPKffzCwkIKCwtLr+fk5ABgt9ux2+3n/wLqsZPjp3GsWRr3mqcxN4fG3Ry1adyDvCr2NSbIy8XpX09tGve6RONuDmca98pksBiGcbZdg6vV/Pnzyc/Pp1WrVqSlpTFlyhS2b9/O1q1bCQoKOmX9xMRELrroIlauXEmrVq2YNGkS3377LZs3bz7jc0yaNInJkyefsvzTTz/Fy0snuhMREamtHAb8e72NvGKA000rbhDgBhO7lGDVrOMichr5+fmMGDGC7Oxs/Pz8zrquqcXp7/Ly8oiOjubRRx/loYceKnNbSUkJPXv25B//+Ad33XUXQIWK0+m2ODVu3JjMzMxyB0fOzm63s3jxYgYMGICrq6vZceoNjXvN05ibQ+Nujto07nsy8rj63d8pKHacctvJnvTWTR0Z1K5hzQY7B7Vp3OsSjbs5nGncc3JyCA4OrlBxMn1Xvb/y9vamffv2JCYmnnJbbm4u69evZ9OmTdxzzz0AOBwODMPAxcWFRYsWcemll55yP3d3d9zd3U9Z7urqavoPqq7QWJpD417zNObm0Libw9nHPbfAzrg5mykodhAd4k1eYQmpOf87linM34OJV7YlLjbcxJSV5+zjXldp3M3hDONemed3quJUWFhIQkICF1988Sm3+fn58eeff5ZZ9u6777Js2TK++uoroqKiaiqmiIiImMjhMHjw883szsgjzM+Dz+7sRaC3G2uTskjPLSDU14PuUYHYtH+eiFQhU4vT+PHjufLKK2nSpAnp6elMmTKFnJwcRo8eDcATTzzBwYMH+fjjj7FarcTGxpa5f2hoKB4eHqcsFxERkbpr6pKdLElIx83FyvRRXQnxPbFnSa/oU4+PFhGpKqYWpwMHDjB8+HAyMzMJCQmhZ8+erF69mqZNmwKQkpJCcnKymRFFRETEiSyIT+HNZbsAeP7a9nSIDDA3kIjUG6YWp88+++yst8+cOfOst0+aNIlJkyZVXSARERFxWjtSc3noiz8AuK13FNd1jTQ5kYjUJ1azA4iIiIiU52h+EXd8vJ78ohIujA5iwpAYsyOJSD2j4iQiIiJOrbjEwb1zNpGclU9kA0/eHtEFF5u+wohIzdJvHREREXFqLy3cwcrETDxdbXwwqhuB3m5mRxKRekjFSURERJzWt5sOMv2XPQC8ckNH2oTr5PUiYg4VJxEREXFK8QezeezrLQCM6xvN5R1q18lsRaRuUXESERERp5N5rJA7P15PYbGDfq1DeHhga7MjiUg9p+IkIiIiTsVe4mDcJxs5lF1A82Bvpt7UGZvVYnYsEannVJxERETEqTzz4zbWJmXh4+7C9FFd8fd0NTuSiIiKk4iIiDiPz9cl8/Hv+wB4/cZOtAj1NTmRiMgJKk4iIiLiFDYmH+HJb7cC8NCAVgxo29DkRCIi/1Pp4rR//34OHDhQen3t2rU88MADTJ8+vUqDiYiISP2RllPAXbM2UFTiIK5dGPf0a2F2JBGRMipdnEaMGMHy5csBSE1NZcCAAaxdu5YJEybw9NNPV3lAERERqdsKi0sYO2sD6bmFtGrowyvDOmLVZBAi4mQqXZzi4+Pp3r07AF988QWxsbGsWrWKTz/9lJkzZ1Z1PhEREanDDMPgyW/j2bz/KH4eLnwwqhs+7i5mxxIROUWli5Pdbsfd3R2AJUuWcNVVVwEQExNDSkpK1aYTERGROm3W6n18sf4AVgu8PaILTYO8zY4kInJalS5O7dq1Y9q0aaxcuZLFixcTFxcHwKFDhwgKCqrygCIiIlI3rd5zmKd/2AbA44NjuKRViMmJRETOrNLF6cUXX+T999+nb9++DB8+nI4dOwLw/fffl+7CJyIiInI2B47kM+6TjRQ7DK7uFMEdFzc3O5KIyFlVeifivn37kpmZSU5ODg0aNChdfuedd+Ll5VWl4URERKTuOV50YjKIrLwi2kX48cLQDlgsmgxCRJxbpbc4HT9+nMLCwtLStG/fPqZOncqOHTsIDQ2t8oAiIiJSdxiGwWNfb2HroRyCvN2YPqobnm42s2OJiJSr0sXp6quv5uOPPwbg6NGj9OjRg1dffZVrrrmG9957r8oDioiISN3xwco9fP/HIVysFt65uQuNAjzNjiQiUiGVLk4bN27k4osvBuCrr76iYcOG7Nu3j48//pg333yzygOKiIhI3bBiZwYvzN8OwFNXtqVnc00qJSK1R6WLU35+Pr6+vgAsWrSIoUOHYrVa6dmzJ/v27avygCIiIlL77c3M495PN+IwYFi3SEb2bGp2JBGRSql0cWrRogXffvst+/fvZ+HChQwcOBCA9PR0/Pz8qjygiIiI1G7HCou5c9Z6cgqK6dwkgGeuidVkECJS61S6OD311FOMHz+eZs2a0b17d3r16gWc2PrUuXPnKg8oIiIitZfDYfDwF5vZmXaMUF93pt3SFXcXTQYhIrVPpacjv/7667noootISUkpPYcTQP/+/bn22murNJyIiIjUbm8v38XCrWm42axMG9mVhn4eZkcSETknlS5OAGFhYYSFhXHgwAEsFguNGjXSyW9FRESkjMXb0nht8U4AplwTS5cmDcq5h4iI86r0rnoOh4Onn34af39/mjZtSpMmTQgICOCZZ57B4XBUR0YRERGpZXal5/Lg55sBGNWrKcMuaGxuIBGR81TpLU7/+te/+PDDD3nhhRfo3bs3hmHw22+/MWnSJAoKCnj22WerI6eIiIjUEtnH7dzx8QaOFRbTIyqQJ69oa3YkEZHzVuni9N///pf//Oc/XHXVVaXLOnbsSKNGjRg3bpyKk4iISD1W4jC4/7NNJGXm0SjAk3dv7oKrrdI7uIiIOJ1K/ybLysoiJibmlOUxMTFkZWVVSSgRERGpnV5dtIOfd2Tg4Wrl/ZFdCfJxNzuSiEiVqHRx6tixI2+//fYpy99+++0ys+yJiIhI/fLjlkO8+/NuAF68rgOxjfxNTiQiUnUqvaveSy+9xOWXX86SJUvo1asXFouFVatWsX//fubNm1cdGUVERMTJbTuUwyNfbgHgzkuac3WnRiYnEhGpWpXe4tSnTx927tzJtddey9GjR8nKymLo0KHs2LGDiy++uDoyioiIiBPLyivizlnrOW4v4eKWwTwWd+ou/SIitd05nccpIiLilEkg9u/fz2233cZHH31UJcFERETE+RWXOLjn040cOHKcJoFevDW8MzarxexYIiJVrsqmucnKyuK///1vVT2ciIiI1ALPzdvOqt2H8XKz8cGobgR4uZkdSUSkWmh+UBERETknX284wEe/JQHw2rCOtA7zNTmRiEj1UXESERGRSvtj/1Ge+OZPAO67tAVxseEmJxIRqV4qTiIiIlIp6bkFjJ21gaJiB5e1CeWBy1qZHUlEpNpVeHKIoUOHnvX2o0ePnm8WERERcXJFxQ7Gzd5Iak4B0SHevH5jJ6yaDEJE6oEKFyd//7OfxM7f359Ro0addyARERFxXpN+2Mr6fUfw9XDhg1Hd8PVwNTuSiEiNqHBxmjFjRnXmEBERESf3yZp9fLomGYsF3rypM81DfMyOJCJSY3SMk4iIiJRr/d4sJn2/FYDxA1vTLybU5EQiIjVLxUlERETOKiX7OHfN3oi9xODy9uGM6xttdiQRkRqn4iQiIiJnVGAvYeysDWQeKyQmzJeXb+iAxaLJIESk/lFxEhERkdMyDIMJ3/zJlgPZBHi58sGobni5VfjwaBGROkXFSURERE5rxm97mbvxIDarhXdGdKFxoJfZkURETFPpPxt9//33p11usVjw8PCgRYsWREVFnXcwERERMc+q3Yd5dl4CABOGtKF3i2CTE4mImKvSxemaa67BYrFgGEaZ5SeXWSwWLrroIr799lsaNGhQZUFFRESkZhwugImfb6HEYTC0SyNu693M7EgiIqar9K56ixcv5oILLmDx4sVkZ2eTnZ3N4sWL6d69Oz/++CO//PILhw8fZvz48dWRV0RERKpRflEx/9lh4+hxOx0i/Xnu2vaaDEJEhHPY4nT//fczffp0LrzwwtJl/fv3x8PDgzvvvJOtW7cydepUbrvttioNKiIiItXLMAwen7uVQ/kWgrzdeH9kVzxcbWbHEhFxCpXe4rR79278/PxOWe7n58eePXsAaNmyJZmZmeefTkRERGrMeyt2M39rGjaLwdvDOxLu72l2JBERp1Hp4tS1a1ceeeQRMjIySpdlZGTw6KOPcsEFFwCQmJhIZGRk1aUUERGRarV8ezovL9wBwHVRDro11XHKIiJ/Veld9T788EOuvvpqIiMjady4MRaLheTkZJo3b853330HwLFjx3jyySerPKyIiIhUvT0Zx7jvs00YBtx0QSS9XPaaHUlExOlUuji1bt2ahIQEFi5cyM6dOzEMg5iYGAYMGIDVemID1jXXXFPVOUVERKQa5BbYuXPWBnILiunWtAFPDolhyaK9ZscSEXE653T6b4vFQlxcHHFxcVWdR0RERGqIw2Hw4Oeb2ZV+jDA/D969pQtuLpXei19EpF44p+K0dOlSli5dSnp6Og6Ho8xtH330UZUEExERkeo1dWkiSxLScXOx8v7IroT6emC3282OJSLilCpdnCZPnszTTz9Nt27dCA8P17kdREREaqEF8Sm8uTQRgOevbU/HxgHmBhIRcXKVLk7Tpk1j5syZjBw5sjryiIiISDXbkZrLQ1/8AcCtvZtxXVfNhCsiUp5K78hcVFRU5uS3IiIiUnsczS/izlnryS8q4cLoIP41pI3ZkUREaoVKF6fbb7+dTz/9tDqyiIiISDUqcRjcO2cT+w7nE9nAk7dHdMHFpskgREQqotK76hUUFDB9+nSWLFlChw4dcHV1LXP7a6+9VmXhREREpOq8tGA7KxMz8XS1MX1kNwK93cyOJCJSa1S6OG3ZsoVOnToBEB8fX+Y2TRQhIiLinL7bfJD3f9kDwMs3dKBthJ/JiUREapdKF6fly5dXRw4RERGpJvEHs3n0qy0A3N03mis6RJicSESk9tGOzSIiInVY5rFCxs7aQGGxg76tQxg/sLXZkUREaqUKbXEaOnQoM2fOxM/Pj6FDh5513blz51ZJMBERETk/9hIH//xkIwePHicq2Js3buqMzard6kVEzkWFipO/v3/p8Uv+/v7VGkhERESqxpQft7EmKQsfdxc+GNUVf0/X8u8kIiKnVaHiNGPGjNP+W0RERJzTF+v289/f9wHw+o2daBHqa3IiEZHaTcc4iYiI1DEbk4/w729PzHz74GWtGNC2ocmJRERqv0oXp7S0NEaOHElERAQuLi7YbLYyFxERETFPWk4Bd83aQFGJg0HtGnLvpS3MjiQiUidUejryMWPGkJyczJNPPkl4eLjO3SQiIuIkCotLuGv2BtJzC2nV0IdXh3XCqskgRESqRKWL06+//srKlStLT4IrIiIi5jMMg6e+3cqm5KP4ebgwfWQ3fNwr/TEvIiJnUOld9Ro3boxhGNWRRURERM7R7NX7+Hz9fqwWeGtEF5oFe5sdSUSkTql0cZo6dSqPP/44e/furYY4IiIiUllr9hxm8g/bAHgsLoY+rUJMTiQiUvdUehv+jTfeSH5+PtHR0Xh5eeHqWvacEFlZWVUWTkRERM7u4NHjjPtkI8UOg6s6RnDnJc3NjiQiUidVujhNnTq1GmKIiIhIZR0vKuHOj9dzOK+IdhF+vHhdB03aJCJSTSpdnEaPHl0dOURERKQSDMPg8blb2Hooh0BvN94f2RVPN50WRESkulSoOOXk5ODn51f677M5uZ6IiIhUn/+sTOK7zYewWS28e3MXIht4mR1JRKROq1BxatCgASkpKYSGhhIQEHDa3QAMw8BisVBSUlLlIUVEROR/ftmZwfPzEwB46oq29GweZHIiEZG6r0LFadmyZQQGBgKwfPnyag0kIiIiZ7bvcB73ztmEw4Bh3SIZ1aup2ZFEROqFChWnPn36nPbfIiIiUnPyCou54+P1ZB+306lxAM9cE6vJIEREasg5n1I8Pz+f5ORkioqKyizv0KHDeYcSERGRshwOg4e/+IOdaccI8XXn/ZFdcXfRZBAiIjWl0sUpIyODW2+9lfnz55/2dh3jJCIiUvXeWb6LBVtTcbNZmXZLVxr6eZgdSUSkXrFW9g4PPPAAR44cYfXq1Xh6erJgwQL++9//0rJlS77//vvqyCgiIlKvLdmWxquLdwLwzDXt6Nq0gcmJRETqn0oXp2XLlvH6669zwQUXYLVaadq0KbfccgsvvfQSzz//fKUea9KkSVgsljKXsLCwM64/d+5cBgwYQEhICH5+fvTq1YuFCxdW9iWIiIjUGrvSj/HA55sBGNWrKTde0MTcQCIi9VSli1NeXh6hoaEABAYGkpGRAUD79u3ZuHFjpQO0a9eOlJSU0suff/55xnV/+eUXBgwYwLx589iwYQP9+vXjyiuvZNOmTZV+XhEREWeXfdzOnR+v51hhMd2jAnnyirZmRxIRqbcqfYxT69at2bFjB82aNaNTp068//77NGvWjGnTphEeHl75AC4uZ93K9FdTp04tc/25557ju+++44cffqBz586Vfm4RERFnVeIweOCzTezJzCPC34N3b+6Cq63Sf+8UEZEqUuni9MADD5CSkgLAxIkTGTRoEJ988glubm7MnDmz0gESExOJiIjA3d2dHj168Nxzz9G8efMK3dfhcJCbm1t6jqnTKSwspLCwsPR6Tk4OAHa7HbvdXum88j8nx0/jWLM07jVPY26O+j7ury1OZPmODNxdrLwzvBP+7tYaGYv6Pu5m0bibQ+NuDmca98pksBiGYZzPk+Xn57N9+3aaNGlCcHBwpe47f/588vPzadWqFWlpaUyZMoXt27ezdetWgoLKPwv6yy+/zAsvvEBCQkLp7oN/N2nSJCZPnnzK8k8//RQvL69K5RUREakJmw5bmLnzxFTjI1uU0C3kvD6qRUTkDPLz8xkxYgTZ2dn4+fmddd1KFSe73U7r1q358ccfadu26vezzsvLIzo6mkcffZSHHnrorOvOmTOH22+/ne+++47LLrvsjOudbotT48aNyczMLHdw5OzsdjuLFy9mwIABuLq6mh2n3tC41zyNuTnq67hvT81l2PQ1HLc7+Efvpjwe17pGn7++jrvZNO7m0Libw5nGPScnh+Dg4AoVp0rtqufq6kphYWG1naXc29ub9u3bk5iYeNb1Pv/8c/7xj3/w5ZdfnrU0Abi7u+Pu7n7KcldXV9N/UHWFxtIcGveapzE3R30a9yN5RYybs5njdgcXtwzmiSFtcTHpuKb6NO7ORONuDo27OZxh3Cvz/JX+bXzvvffy4osvUlxcXNm7lquwsJCEhISzTjIxZ84cxowZw6effsrll19e5RlERETMUFzi4J45G9mfdZwmgV68NbyzaaVJREROVeEtTsnJyURGRrJmzRqWLl3KokWLaN++Pd7e3mXWmzt3boWffPz48Vx55ZU0adKE9PR0pkyZQk5ODqNHjwbgiSee4ODBg3z88cfAidI0atQo3njjDXr27ElqaioAnp6e+Pv7V/h5RUREnM3z87fz267DeLnZ+GBUNwK83MyOJCIif1Hh4hQVFUVKSgoBAQFcd911VfLkBw4cYPjw4WRmZhISEkLPnj1ZvXo1TZs2BSAlJYXk5OTS9d9//32Ki4v55z//yT//+c/S5aNHjz6nGf1EREScwdcbDvDhr0kAvDasI63DfE1OJCIif1fh4nRyDokZM2ZU2ZN/9tlnZ73972Xo559/rrLnFhERcQZbDhzliW9OnPz93ktbEBdb+XMiiohI9dPO0yIiIibJyC1k7KwNFBU7uKxNKA9e1srsSCIicgaVmlXvP//5Dz4+Pmdd57777juvQCIiIvVBUbGDcZ9sICW7gOgQb16/sRNWa/XMWisiIuevUsVp2rRp2Gy2M95usVhUnERERCpg8g9bWbf3CL7uLkwf1Q1fD02FLCLizCpVnNavX09oaGh1ZREREakXPl2TzCdrkrFY4I3hnYgOOfveHCIiYr4KH+NUXSe9FRERqU/W781i4vfxAIwf2JpLYxqanEhERCqiwsXp5Kx6IiIicm5Sso9z1+yN2EsMhrQPY1zfaLMjiYhIBVW4OE2cOLHciSFERETk9ArsJdw1awOZxwqJCfPl5es7am8OEZFapMLHOE2cOLE6c4iIiNRZhmHwr2/i+eNANgFernwwqhve7pU6zFhEREym8ziJiIhUs5mr9vL1xgNYLfDOiC40DvQyO5KIiFSSipOIiEg1WrUrkyk/JQAwYUgbercINjmRiIicCxUnERGRarI/K59/frqREofB0M6N+MdFUWZHEhGRc6TiJCIiUg3yi4q5c9YGjuTb6RDpz3ND22syCBGRWqxCR6Z27ty5wr/sN27ceF6BREREajvDMHj0qy0kpOQQ7OPGtFu64uFqMzuWiIichwoVp2uuuaaaY4iIiNQd01bs4cctKbhYLbx3S1ciAjzNjiQiIuepQsVJU5GLiIhUzPId6by0cDsAk65qxwXNAk1OJCIiVUHHOImIiFSRPRnHuG/OJgwDhndvwi09m5odSUREqkilz75XUlLC66+/zhdffEFycjJFRUVlbs/KyqqycCIiIrVFboGdO2dtILegmK5NGzD5qnZmRxIRkSpU6S1OkydP5rXXXmPYsGFkZ2fz0EMPMXToUKxWK5MmTaqGiCIiIs7N4TB48PM/2JV+jIZ+7rx3SxfcXLRTh4hIXVLp3+qffPIJH3zwAePHj8fFxYXhw4fzn//8h6eeeorVq1dXR0YRERGn9sbSRJYkpOHmYuX9kd0I9fUwO5KIiFSxShen1NRU2rdvD4CPjw/Z2dkAXHHFFfz0009Vm05ERMTJLYhP5Y2liQA8d217OjUOMDeQiIhUi0oXp8jISFJSUgBo0aIFixYtAmDdunW4u7tXbToREREntjMtl4e/2AzArb2bcX3XSHMDiYhItal0cbr22mtZunQpAPfffz9PPvkkLVu2ZNSoUdx2221VHlBERMQZZefbufPj9eQVldCreRAThrQxO5KIiFSjSs+q98ILL5T++/rrrycyMpJVq1bRokULrrrqqioNJyIi4oxKHAb3zNnI3sP5NArw5J2bu+Bq02QQIiJ1WaWL09/17NmTnj17VkUWERGRWuGlhdtZmZiJh6uV6aO6EujtZnYkERGpZudUnHbu3MnPP/9Meno6DoejzG1PPfVUlQQTERFxRt9tPsj7K/YA8PL1HWkX4W9yIhERqQmVLk4ffPABd999N8HBwYSFhWGxWEpvs1gsKk4iIlJnxR/M5rGvtwBwd99oruwYYXIiERGpKZUuTlOmTOHZZ5/lscceq448IiIiTunwsULGztpAgd1B39YhjB/Y2uxIIiJSgyp9JOuRI0e44YYbqiOLiIiIU7KXOPjnpxs5ePQ4UcHevHFTZ2xWS/l3FBGROqPSxemGG24oPXeTiIhIffDsTwms3pOFt5uN6SO74u/panYkERGpYZXeVa9FixY8+eSTrF69mvbt2+PqWvbD47777quycCIiImb7Yv1+Zq7aC8DrN3aiZUNfcwOJiIgpKl2cpk+fjo+PDytWrGDFihVlbrNYLCpOIiJSZ2xKPsK/v4kH4IHLWjKwXZjJiURExCyVLk5JSUnVkUNERMSppOcUcNfsDRSVOBjYtiH3XdrS7EgiImIineZcRETkbwqLS7hr9gbScgppGerDazd2wqrJIERE6rUKbXF66KGHeOaZZ/D29uahhx4667qvvfZalQQTERExg2EYTPxuKxuTj+Ln4cIHo7rh435O54sXEZE6pEKfBJs2bcJut5f++0z+ejJcERGR2mj26n18tm4/Vgu8NaILzYK9zY4kIiJOoELFafny5ezZswd/f3+WL19e3ZlERERMsWbPYSb/sA2AR+Ni6NMqxOREIiLiLCp8jFPLli3JyMgovX7jjTeSlpZWLaFERERq2sGjxxn3yUaKHQZXdYxg7CXNzY4kIiJOpMLFyTCMMtfnzZtHXl5elQcSERGpaQX2EsbOWs/hvCLahvvx4nUdtPu5iIiUoVn1RESkXjMMg8e/3kL8wRwCvd2YPqornm42s2OJiIiTqXBxslgsp/z1TX+NExGR2u7DX5P4dvMhbFYL74zoQmQDL7MjiYiIE6rw/KqGYTBmzBjc3d0BKCgo4K677sLbu+xsQ3Pnzq3ahCIiItVkZWIGz81LAODJy9vQKzrI5EQiIuKsKlycRo8eXeb6LbfcUuVhREREasq+w3nc8+kmHAbc0DWS0Rc2MzuSiIg4sQoXpxkzZlRnDhERkRqTV1jMnR9vIPu4nY6NA3jmmljtfi4iImelySFERKReMQyD8V/+wY60XEJ83Zk+siserpoMQkREzk7FSURE6pV3lu9ifnwqrjYL027pSkM/D7MjiYhILaDiJCIi9cbShDReXbwTgGeujqVr0wYmJxIRkdpCxUlEROqFXenHuP+zzRgGjOzZlJu6NzE7koiI1CIqTiIiUuflFNi58+P1HCsspnuzQJ68oq3ZkUREpJZRcRIRkTqtxGHwwGeb2ZOZR4S/B+/e0gU3F338iYhI5eiTQ0RE6rTXF+9k2fZ03F2svD+yG8E+7mZHEhGRWkjFSURE6qx5f6bw9vJdALx4XQfaR/qbnEhERGorFScREamTElJyePiLPwC44+IoruncyOREIiJSm6k4iYhInXMkr4g7Z63nuL2Ei1sG81hcjNmRRESkllNxEhGROqW4xME9czayP+s4TQK9eGt4Z1xs+rgTEZHzo08SERGpU16Yv53fdh3Gy83G9FFdCfByMzuSiIjUASpOIiJSZ8zdeID//JoEwKs3dCQmzM/kRCIiUleoOImISJ2w5cBRHp/7JwD3XtqCwe3DTU4kIiJ1iYqTiIjUehm5hYydtYGiYgf9Y0J58LJWZkcSEZE6RsVJRERqtaJiB+M+2UBKdgHNQ7x5/aZOWK0Ws2OJiEgdo+IkIiK12tM/bmXd3iP4urvwwahu+Hm4mh1JRETqIBUnERGpteasTWb26mQsFnhjeCeiQ3zMjiQiInWUipOIiNRKG/Zl8dR38QCMH9iaS2MampxIRETqMhUnERGpdVKzC7hr9kbsJQZD2ocxrm+02ZFERKSOU3ESEZFapcBewtjZG8jILSQmzJeXr++IxaLJIEREpHqpOImISK1hGAb//jaeP/YfJcDLlekju+Ht7mJ2LBERqQdUnEREpNaYuWovX204gNUCbw/vQpMgL7MjiYhIPaHiJCIitcKq3ZlM+SkBgAlD2nBRy2CTE4mISH2i4iQiIk5vf1Y+//xkIyUOg2s7N+IfF0WZHUlEROoZFScREXFqx4tKuHPWBo7k22nfyJ/nh7bXZBAiIlLjVJxERMRpGQY88c1WElJyCPZx4/2RXfFwtZkdS0RE6iFNRSQiIk5r2SELPyWn4mK18O7NXYkI8DQ7koiI1FPa4iQiIk7pl8RMfkg+8TE18ap2dI8KNDmRiIjUZypOIiLidJIy83jgiy0YWLixWyNu6dHE7EgiIlLPqTiJiIhTOVZYzB0frye3oJhmPgZPXt5Gk0GIiIjpVJxERMRpOBwGD36+mV3px2jo685trUtwd9FHlYiImE+fRiIi4jTeXJbI4m1puNmsvDOiE/5uZicSERE5QcVJREScwsKtqUxdkgjAs9fG0jHS3+REIiIi/6PiJCIiptuZlstDn28GYMyFzbihW2NzA4mIiPyNipOIiJgqO9/OnR+vJ6+ohF7Ng/jX5W3MjiQiInIKFScRETFNicPgvs82sfdwPo0CPHnn5i642vTRJCIizkefTiIiYpqXF+5gxc4MPFytTB/VlUBvzQYhIiLOScVJRERM8f0fh5i2YjcAL1/fkXYRmgxCREScl4qTiIjUuK2Hsnn0qz8AuKtPNFd2jDA5kYiIyNmZWpwmTZqExWIpcwkLCzvrfVasWEHXrl3x8PCgefPmTJs2rYbSiohIVTh8rJA7P95Agd1Bn1YhPDKotdmRREREyuVidoB27dqxZMmS0us2m+2M6yYlJTFkyBDuuOMOZs+ezW+//ca4ceMICQnhuuuuq4m4IiJyHuwlDv756UYOHj1OsyAv3rypMzarxexYIiIi5TK9OLm4uJS7lemkadOm0aRJE6ZOnQpAmzZtWL9+Pa+88oqKk4hILfDsTwms3pOFt5uN6aO64e/lanYkERGRCjG9OCUmJhIREYG7uzs9evTgueeeo3nz5qdd9/fff2fgwIFllg0aNIgPP/wQu92Oq+upH8CFhYUUFhaWXs/JyQHAbrdjt9ur8JXUPyfHT+NYszTuNU9jXjW+2niQmav2AvDK9e2JCvQ465hq3M2hcTeHxt0cGndzONO4VyaDxTAMoxqznNX8+fPJz8+nVatWpKWlMWXKFLZv387WrVsJCgo6Zf1WrVoxZswYJkyYULps1apV9O7dm0OHDhEeHn7KfSZNmsTkyZNPWf7pp5/i5eVVtS9IREROa28uvLnVRolhIS6yhMGNTfvoERERKZWfn8+IESPIzs7Gz8/vrOuausVp8ODBpf9u3749vXr1Ijo6mv/+97889NBDp72PxVJ2X/iTve/vy0964oknyjxWTk4OjRs3ZuDAgeUOjpyd3W5n8eLFDBgw4LRb+6R6aNxrnsb8/KTnFvLce6spMQoZ0CaUN27qiLUCxzVp3M2hcTeHxt0cGndzONO4n9wbrSJM31Xvr7y9vWnfvj2JiYmnvT0sLIzU1NQyy9LT03FxcTntFioAd3d33N3dT1nu6upq+g+qrtBYmkPjXvM05pVXWFzCvZ/9QVpuIS1DfXj9ps64u1fuo0fjbg6Nuzk07ubQuJvDGca9Ms/vVOdxKiwsJCEh4bS73AH06tWLxYsXl1m2aNEiunXrZvqgi4hIWYZhMOn7rWxMPoqfhwvTR3XDp5KlSURExFmYWpzGjx/PihUrSEpKYs2aNVx//fXk5OQwevRo4MRudqNGjSpd/6677mLfvn089NBDJCQk8NFHH/Hhhx8yfvx4s16CiIicwew1ycxZux+rBd4c3pmoYG+zI4mIiJwzU//0d+DAAYYPH05mZiYhISH07NmT1atX07RpUwBSUlJITk4uXT8qKop58+bx4IMP8s477xAREcGbb76pqchFRJzM2qQsJn+/FYBH42Lo2zrU5EQiIiLnx9Ti9Nlnn5319pkzZ56yrE+fPmzcuLGaEomIyPk6dPQ44z7ZQLHD4MqOEYy95PSnmBAREalNnOoYJxERqd0K7CWMnbWBzGNFtA3346XrOpxx1lMREZHaRMVJRESqhGEYPDH3T/48mE2gtxvvj+yKp5vN7FgiIiJVQsVJRESqxIe/JvHNpoPYrBbeHtGZxoE6ybiIiNQdKk4iInLefk3M5Ll5CQD8+/I2XBgdbHIiERGRqqXiJCIi5yX5cD73zNmIw4Dru0Yy5sJmZkcSERGpcipOIiJyzvIKi7lz1nqO5tvp2DiAKdfEajIIERGpk1ScRETknBiGwSNf/cH21FxCfN15/5aueLhqMggREambVJxEROScvPvzbub9mYqrzcK0W7oQ5u9hdiQREZFqo+IkIiKVtmx7Gq8s2gHA01fH0rVpoMmJREREqpeKk4iIVMqu9GPcP2czhgG39GzC8O5NzI4kIiJS7VScRESkwnIK7Nw5az25hcV0bxbIU1e0MzuSiIhIjVBxEhGRCnE4DB78bDN7MvII9/fgnZu74OaijxEREakf9IknIiIV8vqSnSzdno67i5XpI7sR4utudiQREZEao+IkIiLlmv9nCm8t2wXAC9e1p32kv8mJREREapaL2QHqsxKHwdqkLNJzCwj19aB7VCA2q04cKSLOZXtqDg9/+QcAt18UxbWdI01OJCIiUvNUnEyyID6FyT9sIyW7oHRZuL8HE69sS1xsuInJRET+52h+EXd8vJ78ohIuahHM44NjzI4kIiJiCu2qZ4IF8SncPXtjmdIEkJpdwN2zN7IgPsWkZCIi/1Nc4uCeTzexP+s4jQM9eWt4Z1xs+tgQEZH6SZ+ANazEYTD5h20Yp7nt5LLJP2yjxHG6NUREas6LC7bz665MPF1tfDCqGw283cyOJCIiYhoVpxq2NinrlC1Nf2UAKdkFrE3KqrlQIiJ/8+2mg3ywMgmAV4d1JCbMz+REIiIi5lJxqmHpuWcuTX8147ck4g9mYxja8iQiNevPA9k89vUWAO7p14Ih7XXcpYiIiCaHqGGhvh4VWm/RtjQWbUujSaAXcbFhxMWG0SkyAKtm3RORapR5rJCxs9ZTWOzg0phQHhrQyuxIIiIiTkHFqYZ1jwok3N+D1OyC0x7nZAH8PV25oFkDfknMJDkrn+m/7GH6L3sI8/MgLjaMQe3CNHW5iFS5omIH42Zv5FB2Ac1DvJl6Uyf9sUZEROT/qTjVMJvVwsQr23L37I1YoEx5Ovn15IXr2hMXG05eYTErdmYwPz6VZQlppOYUMHPVXmau2kuQtxsD2zUkLjacC6ODcNVMVyJynp75cRtr92bh6+7CB6O64efhanYkERERp6HiZIK42HDeu6XLKedxCvvbeZy83V0Y0j6cIe3DKbCX8GtiJvPjU1mSkMbhvCLmrN3PnLX78fNw4bK2DRkcG87FLYPxcLWZ9dJEpJb6bG0ys1bvw2KBqTd1IjrEx+xIIiIiTkXFySRxseEMaBvG2qQs0nMLCPX1OOvudx6uNi5r25DL2jbEXuLg992HmR+fyuJtqWQeK2LuxoPM3XgQbzcbfWNCGRwbRr/WoXi760csIme3YV8WT34XD8DDA1rRv01DkxOJiIg4H32rNpHNaqFXdFCl7+dqs3JJqxAuaRXClGtiWb83i/nxqSzcmkpKdgE/bUnhpy0puLucWG9wbBj92zTE31O73YhIWanZBdw1eyP2EoPBsWH8s18LsyOJiIg4JRWnWs5mtdCjeRA9mgfx1BVt+ePAURbEpzI/PpXkrHwWb0tj8bY0XG0WLowOZnBsGAPaNiTIx93s6CJisgJ7CWNnbyAjt5DWDX155YaOWCyaDEJEROR0VJzqEKvVQucmDejcpAGPD45hW0pOaYnalX6MFTszWLEzgwnf/En3qEAGx4YTFxtGQ7+KTZEuInWHYRg8+W08f+w/ir+nK9NHddWuvSIiImehT8k6ymKx0C7Cn3YR/jw8sDW70nNLS9TWQzms3pPF6j1ZTPx+K12aBJSWqMaBXmZHF5Ea8N9Ve/lywwGsFnhnRBeaBnmbHUlERMSpqTjVEy1CfbnnUl/uubQlyYfzWbA1hfnxqWxKPsrG/788Oy+B2EZ+pSVKs2qJ1E2/7z7MMz8lADBhSBsuahlsciIRERHnp+JUDzUJ8uLOS6K585JoUrKPszA+lQVbU1mblEX8wRziD+bw8sIdtGroQ1xsOHHtwmgT7qtjH0TqgANH8vnnpxspcRhc27kR/7goyuxIIiIitYKKUz0X7u/JmN5RjOkdReaxQhZvS2N+fCqrdmWyM+0YO9MSeXNpIs2CvBgUG8bg2HA6RvqrRInUQseLSrjz4w1k5RUR28iP54e21/9lERGRClJxklLBPu4M796E4d2bkJ1vZ0nCiRL1S2IGew/n8/6KPby/Yg8R/h4Mig1jQEwIDsPs1CJSEYZh8OjXW9iWkkOQtxvvj+ymk2WLiIhUgoqTnJa/lyvXdY3kuq6RHCssZvn2dBZsTWX59nQOZRcw47e9zPhtL76uNtaWbGNIhwh6Ng/C1WY1O7qInMb7v+zhhz8O4WK18N4tXWkU4Gl2JBERkVpFxUnK5ePuwpUdI7iyYwQF9hJ+2ZnBgvhUFiekkVtQzJx1B5iz7gABXq5c1qYhg2PDuKhlMO4u+mu2iDP4eUc6Ly7YDsDEq9rRPSrQ5EQiIiK1j4qTVIqHq42B7cIY2C6MvOOFvPX5QrK8m7BkewZZeUV8teEAX204gI+7C5fGhDI4Now+rUPwctNbTcQMezPzuG/OJgwDbrqgMbf0aGJ2JBERkVpJ32blnLm5WGnTwGDIkHY8Z7Wxbu8RFsSnsGBrKmk5hXz/xyG+/+MQHq5W+rYKJS42jEvbhOLn4Wp2dJF64VhhMXd8vJ6cgmK6NAlg8tXtNBmEiIjIOVJxkirhYrPSKzqIXtFBTLyyHZv2H2VB/IlzRR04cpwFW09Mee5ms9K7RRCDY8MZ0LYhDbzdzI4uUic5HAYPfb6ZxPRjNPRzZ9otXbX7rIiIyHlQcZIqZ7Va6Nq0AV2bNmDCkDZsPZTD/P8vUXsy8li+I4PlOzKwfWOhZ/NA4mLDGdSuIaG+HmZHF6kz3lq2i0Xb0nCzWZl2S1dC/fT/S0RE5HyoOEm1slgsxDbyJ7aRP48MiiExLZf58anMj08lISWH33Yd5rddh3nqu3i6NW3AoHZhxMWGEdnAy+zoIrXWoq2pvL5kJwBTro2lc5MGJicSERGp/VScpEa1bOhLy4a+3Ne/JXsz81iw9USJ+mP/UdbtPcK6vUeY8lMCHSL9ifv/E+5GBXubHVuk1khMy+XBzzcDMObCZgzr1tjcQCIiInWEipOYplmwN3f1ieauPtEcOnqcBfEnjoNatzeLLQey2XIgm5cW7CAmzLe0RLVq6KOD20XOIPu4nTs+Xk9eUQk9mwfyr8vbmB1JRESkzlBxEqcQEeDJbRdFcdtFUWTkFrJoWyoL4lNZtfsw21Nz2Z6ay9QliTQP9mZQbBiDY8No38hfJUrk/5U4DO6bs4m9h/NpFODJOyO66ITUIiIiVUjFSZxOiK87N/doys09mnI0v4jF29JYEJ/KysRM9mTm8d7Pu3nv5900CvD8/y1RYXRp0gCrVSVK6q9XFu1gxc4MPFytvD+yK0E+7mZHEhERqVNUnMSpBXi5cUO3xtzQrTG5BXaWbU9n4dZUlm/P4ODR43z4axIf/ppEqK87g9qdKFHdowJx0V/apR754Y9DvPfzbgBevK4DsY38TU4kIiJS96g4Sa3h6+HK1Z0acXWnRhwvKmHFzgwWxKewNCGd9NxCZq3ex6zV+2jg5cqAtg0ZHBvOhS2CdO4aqdO2Hsrmka/+AGBsn+Zc3amRyYlERETqJhUnqZU83WzExZ6YurywuIRVuw4zPz6FxdvSOJJv54v1B/hi/QF83V3o3yaUuNhw+rQKwdNNJUrqjqy8Iu78eAMFdgeXtArh0UExZkcSERGps1ScpNZzd7HRLyaUfjGhFJc4WJOUVTpDX0ZuId9uPsS3mw/h6WqjX0wIcbHhXBoTio+73v5Se9lLHPzzk40cPHqcZkFevHVTZ2w6zk9ERKTa6Juj1CkuNiu9WwTTu0Uwk69qx8bkI8yPPzFD38Gjx5n3Zyrz/kzFzcXKxS2CiYsNY0DbhgR4uZkdXaRSnpuXwO97DuPtZmP6qG74e7maHUlERKROU3GSOstqtdCtWSDdmgXy78vb8OfB7NISlZSZx9Lt6Szdno6L1UKv6CDiYsMY2DaMEF/NRibO7asNB5jx214AXruxE60a+pobSEREpB5QcZJ6wWKx0CEygA6RATw6qDU70nJP7M4Xn8r21FxWJmayMjGTf38bzwXNAhn8/8dPhft7mh1dpIzN+48y4Zs/Abi/f0sGtQszOZGIiEj9oOIk9Y7FYiEmzI+YMD8euKwVezKOsWDriRK15UA2a5OyWJuUxeQfttGxcQCD//9cUU2DvM2OLvVcem4Bd83aQFGxgwFtG3J//5ZmRxIREak3VJyk3mse4sO4vi0Y17cFB47kl26J2pB8hD/2H+WP/Ud5Yf522oT7lZaolto1SmpYYXEJd8/eSGpOAS1CfXhtWEed9FlERKQGqTiJ/EVkAy9uv7g5t1/cnPScAhZuS2NBfAqr92SRkJJDQkoOry3eSXSIN4Njw4mLDaNdhB8Wi77ASvWa9P02Nuw7gq+HCx+M6oavhyaDEBERqUkqTiJnEOrnwcieTRnZsylZeUUs2ZbG/PgUft2Vye6MPN5evou3l++icaAnce3CiIsNp3PjAG0FkCo3e/U+5qxNxmKBt4Z3JipYu42KiIjUNBUnkQoI9HZj2AWNGXZBY3IK7CxLSGd+fAordmawP+s4H6xM4oOVSYT5eTCoXUPiYsPpHhWo8+rIeVublMWk77cC8OigGPq2DjU5kYiISP2k4iRSSX4erlzTuRHXdG5EflExK3ZkMD8+lWXb00nNKeC/v+/jv7/vI8jbjYH/X6J6NQ/CzcVqdnSpZQ4dPc64TzZQ7DC4okM4d/VpbnYkERGRekvFSeQ8eLm5MLh9OIPbh1NgL+G3XZnMj09l8bY0DucVMWftfuas3Y+fhwuXtWlIXGwYl7QKwcPVZnZ0cXIF9hLGztpA5rEi2oT78dL1HXQsnYiIiIlUnESqiIerjf5tGtK/TUPsJQ5W7znM/PhUFm1NJfNYEXM3HWTupoN4udnoFxPK4Ngw+rUOxdtd/w2lLMMwmDD3T/48mE0DL1emj+yKl5veJyIiImbSJ7FINXC1Wbm4ZQgXtwzhmatj2bDvCPPjU1gYn8qh7AJ+2pLCT1tScHexckmrEAbHhtE/piH+XpopTeDDX5OYu+kgNquFd27uQuNAL7MjiYiI1HsqTiLVzGa10D0qkO5RgTx1RVv+OJDN/PgUFsSnsu9wPou3pbF4WxouVgsXtghmcGwYA9s2JMjH3ezoYoJfEzN5bl4CAP++vA0XRgebnEhERERAxUmkRlksFjo1DqBT4wAej4shISWXBfEpzI9PJTH9GL/szOCXnRn865s/6R4VyODYcAa1CyPM38Ps6FIDkg/nc8+cjTgMuK5LJGMubGZ2JBEREfl/Kk4iJrFYLLSN8KNthB8PDWzNrvRjLNyayvz4FOIP5rB6Txar92Qx8futdGkSUHrC3TBf7c5XF+UXFXPnrPUczbfTMdKfZ6+N1WQQIiIiTkTFScRJtAj1oUVoC/7ZrwX7s/JZEH+iRG1MPlp6eXZeAm3DfYlysdA6I4+YiACzY0sVMAyDR77cwvbUXIJ93Jk2sqtmXhQREXEyKk4iTqhxoBd3XNKcOy5pTmp2QemWqLVJWWxLyWUbNn568zdahvowODaMuNhw2oT7agtFLfXuz7v56c8UXG0W3h/ZhXB/T7MjiYiIyN+oOIk4uTB/D0Zf2IzRFzbj8LFCFvx5iNkr4tmVayMx/RiJy3bx5rJdNA3yIq5dGHGxYXRqHKASVUss257GK4t2APD01bF0bRpociIRERE5HRUnkVokyMedYd0i8UnfwkX9+rNiVxbz41P5ZWcG+w7n8/4ve3j/lz2E+3swqF0Yg2PD6NYsEJtVJcoZ7c44xv1zNmMYcHOPJgzv3sTsSCIiInIGKk4itZSfpytDu0QytEskeYXFLN+RzoL4VJZvTyclu4CZq/Yyc9Vegn3cGdiuIYNjw+jZPAhXm9Xs6ALkFNi54+P15BYWc0GzBky8sp3ZkUREROQsVJxE6gBvdxeu6BDBFR0iKLCXsDIxk/nxKSzZlkbmsUI+XZPMp2uS8fd0ZUDbEyWqd4tgTUBgEofD4KHPN7MnI49wfw/evbkrbi4qtCIiIs5MxUmkjvFwtTGgbUMGtG1IUbGD3/ccZkF8Cou2pnE4r4ivNhzgqw0H8HF3oV9MKINjw+jbOgQvN/06qClTl+xkSUI6bi5W3h/ZlRBfnexYRETE2embkkgd5uZipU+rEPq0CmHKNQbr9maxID6VBfGppOYU8MMfh/jhj0N4uJ5Yb3BsOJe2CcXPQ+eKqi4L4lN4c9kuAF4Y2p4OkQHmBhIREZEKUXESqSdsVgs9mwfRs3kQT13Rls0HjpaeK2p/1nEWbk1j4dY0XG0WLmoRTFxsGAPahhHo7WZ29Dpje2oOD33xBwD/uCiKoV0iTU4kIiIiFaXiJFIPWa0WujRpQJcmDXhicAxbD+WUlqjdGXks35HB8h0ZTPgmnh5RgQyODWNQuzBC/TzMjl5rHc0v4s6PN5BfVELvFkE8MTjG7EgiIiJSCSpOIvWcxWIhtpE/sY38GT+oNbvSc5n/Zyrz41PZlpLDqt2HWbX7ME99v5WuTRoQF3viXFGRDbzMjl5rFJc4uHfOJpKz8mkc6Mnbw7vgotkNRUREahUVJxEpo0WoL/f29+Xe/i3Zdzjv/7dEpbJ5/1HW7zvC+n1HmPJTAu0b+RMXe+JcUc1DfMyO7dReWriDlYmZeLramD6yGw20+6OIiEito+IkImfUNMibsX2iGdsnmkNHj7Nw64mJJdbtzeLPg9n8eTCblxfuoHVD3xMlqn0YrRv6YrHohLsnfbvpINN/2QPAKzd0pE24n8mJRERE5FyoOIlIhUQEeHJr7yhu7R1FRm4hi7elMT8+hd93H2ZHWi470nJ5Y2kiUcHepVui2jfyr9cl6s8D2Tz29RYA/tkvmss7hJucSERERM6VipOIVFqIrzsjejRhRI8mHM0vYklCOgviU/glMZOkzDze+3k37/28m0YBngxqd2JLVNcmDbBa60+JyjxWyNhZ6yksdnBpTCgPDWhtdiQRERE5DypOInJeArzcuL5rJNd3jeRYYTHLtqezMD6VZdvTOXj0OB/9lsRHvyUR4uvOoHYNGRwbTo+owDo9OYK9xMG4TzZyKLuA5sHeTL2pE7Z6VBpFRETqIhUnEakyPu4uXNUxgqs6RlBgL2HFzgwWxKeyJCGNjNxCZq9OZvbqZBp4uTKg7YkSdWGLINxdbGZHr1LP/LiNtUlZ+Li7MH1UN51QWEREpA5QcRKRauHhamNQuxPnfyoqdvDb7kwW/JnKom2pHMm388X6A3yx/gC+7i5c2iaUwbFh9GkViqdb7S5Rn69L5uPf92GxwNQbO9EiVDMOioiI1AUqTiJS7dxcrPRrHUq/1qE8WxLL2qQsFvz/DH3puYV8t/kQ320+hKerjb6tQ4iLDePSmFB8a9mWmg37jvDkt1sBeOiyVlzWtqHJiURERKSqqDiJSI1ysVm5sEUwF7YIZtKV7di0/0jpCXcPHj3O/P8/b5SbzcrFLYOJiw1jQNuGBHg597mP0nIKuHv2BopKHMS1C+Of/VqYHUlERESqkNMcnf38889jsVh44IEHzrreJ598QseOHfHy8iI8PJxbb72Vw4cP10xIEalSVquFrk0D+fcVbfn1sX78cM9FjOsbTfNgb4pKHCzdns4jX22h25QljPxwDbNX7yMjt9Ds2KcosJcwdtYG0nMLad3Ql1eHdaxXMwiKiIjUB06xxWndunVMnz6dDh06nHW9X3/9lVGjRvH6669z5ZVXcvDgQe666y5uv/12vvnmmxpKKyLVwWKx0D7Sn/aR/jwyqDU7046xID6V+fEpbE/NZWViJisTM3nyu3guaBpIXGwYcbFhRAR4mprbMAye+i6ezfuP4u/pyvRRXfF2d4pfrSIiIlKFTP90P3bsGDfffDMffPABU6ZMOeu6q1evplmzZtx3330AREVFMXbsWF566aUz3qewsJDCwv/9hTonJwcAu92O3W6vgldQf50cP41jzaov4948yINxfZoxrk8z9h7OY+HWdBZtS2PLwRzW7s1i7d4snv5xGx0i/RjUtiGD2jWkaaBXtWQ525jPWp3MF+sPYLXA1GEdiPBzq/M/m5pSX97rzkbjbg6Nuzk07uZwpnGvTAaLYRhGNWYp1+jRowkMDOT111+nb9++dOrUialTp5523VWrVtGvXz+++eYbBg8eTHp6OsOGDaNNmzZMmzbttPeZNGkSkydPPmX5p59+ipdX9XzJEpHqk1UIW7Is/HHYSlIuGPxvl7hGXgYdAh10DDII8wRLNe8tl5ht4d1tVhxYuLppCZdGmPrrVERERCopPz+fESNGkJ2djZ+f31nXNbU4ffbZZzz77LOsW7cODw+PcosTwFdffcWtt95KQUEBxcXFXHXVVXz11Ve4up5+9q3TbXFq3LgxmZmZ5Q6OnJ3dbmfx4sUMGDDgjOMvVU/j/j8ZuYUsTkhn4bY01iQdocTxv19nzYO9SrdEtQ33xXIeLep0Y37w6HGufW81R/LtXNUhnFeujz2v55BT6b1uDo27OTTu5tC4m8OZxj0nJ4fg4OAKFSfTdtXbv38/999/P4sWLcLDw6NC99m2bRv33XcfTz31FIMGDSIlJYVHHnmEu+66iw8//PC093F3d8fd3f2U5a6urqb/oOoKjaU5NO4QEejK6N4+jO7dnCN5RSxOSGNBfCq/JmayJzOf935J4r1fkohs4Mng2DDiYsPp3DjgnCduODnmx4tK+OecPziSbye2kR8v3dARN9faff4pZ6b3ujk07ubQuJtD424OZxj3yjy/acVpw4YNpKen07Vr19JlJSUl/PLLL7z99tsUFhZis5X9IvL888/Tu3dvHnnkEQA6dOiAt7c3F198MVOmTCE8PLxGX4OIOI8G3m4M69aYYd0ak1NgZ/n2dOb/mcrPO9M5cOQ4H6xM4oOVSTT0c2dQuxMTS3RvFoiLrXKTixqGwWNfb2HroRyCvN14f2Q3PFSaRERE6jzTilP//v35888/yyy79dZbiYmJ4bHHHjulNMGJfRBdXMpGPrmeyYdqiYgT8fNw5epOjbi6UyPyi4r5ZWcG8+NTWZqQTlpOIR//vo+Pf99HoLcbA9s2JC42jAujg3FzObVElTgM1iRlsSHTQlBSFn8eyuX7Pw7hYrXw7s1daGTyrH4iIiJSM0wrTr6+vsTGxpZZ5u3tTVBQUOnyJ554goMHD/Lxxx8DcOWVV3LHHXfw3nvvle6q98ADD9C9e3ciIiJq/DWIiPPzcnMhLjacuNhwCotL+G1XJvP/TGVxQhpZeUV8tm4/n63bj6+HCwPanChRl7QKwcPVxoL4FCb/sI2U7ALAxseJ60sfd+KVbenRPMi8FyYiIiI1yvTpyM8mJSWF5OTk0utjxowhNzeXt99+m4cffpiAgAAuvfRSXnzxRRNTikht4e5i49KYhlwa0xB7iYM1e7KYH5/Cwq1pZB4rZO6mg8zddBAvNxsxYb5sTD56xscK9jn12EkRERGpu5yqOP38889lrs+cOfOUde69917uvffemgkkInWWq83KRS2DuahlME9fHcvG5CPM/zOVBfEpHMouOGtpsgBP/7iNge3CsJ3jRBMiIiJSu1TuqGgRkTrIZrVwQbNAnrqyLb89filTrok96/oGkJJdwNqkrJoJKCIiIqZTcRIR+QuLxYKvR8U2xqfnFlRzGhEREXEWKk4iIn8T6luxc8tVdD0RERGp/VScRET+pntUIOH+Hpzp6CULEO7vQfeowJqMJSIiIiZScRIR+Rub1cLEK9sCnFKeTl6feGVbTQwhIiJSj6g4iYicRlxsOO/d0oUw/7K744X5e/DeLV2Iiw03KZmIiIiYwammIxcRcSZxseEMaBvG77vSWbRyDQMv7kGvFqHa0iQiIlIPqTiJiJyFzWqhR1QghxMMekQFqjSJiIjUU9pVT0REREREpBwqTiIiIiIiIuVQcRIRERERESmHipOIiIiIiEg5VJxERERERETKoeIkIiIiIiJSDhUnERERERGRcqg4iYiIiIiIlEPFSUREREREpBwqTiIiIiIiIuVQcRIRERERESmHipOIiIiIiEg5VJxERERERETK4WJ2gJpmGAYAOTk5Jiep/ex2O/n5+eTk5ODq6mp2nHpD417zNObm0LibQ+NuDo27OTTu5nCmcT/ZCU52hLOpd8UpNzcXgMaNG5ucREREREREnEFubi7+/v5nXcdiVKRe1SEOh4NDhw7h6+uLxWIxO06tlpOTQ+PGjdm/fz9+fn5mx6k3NO41T2NuDo27OTTu5tC4m0Pjbg5nGnfDMMjNzSUiIgKr9exHMdW7LU5Wq5XIyEizY9Qpfn5+pr/p6yONe83TmJtD424Ojbs5NO7m0Libw1nGvbwtTSdpcggREREREZFyqDiJiIiIiIiUQ8VJzpm7uzsTJ07E3d3d7Cj1isa95mnMzaFxN4fG3Rwad3No3M1RW8e93k0OISIiIiIiUlna4iQiIiIiIlIOFScREREREZFyqDiJiIiIiIiUQ8VJRERERESkHCpOclbvvfceHTp0KD1BWa9evZg/f37p7YZhMGnSJCIiIvD09KRv375s3brVxMR1z/PPP4/FYuGBBx4oXaZxrx6TJk3CYrGUuYSFhZXernGvPgcPHuSWW24hKCgILy8vOnXqxIYNG0pv19hXvWbNmp3yfrdYLPzzn/8ENObVobi4mH//+99ERUXh6elJ8+bNefrpp3E4HKXraNyrR25uLg888ABNmzbF09OTCy+8kHXr1pXernE/f7/88gtXXnklERERWCwWvv322zK3V2SMCwsLuffeewkODsbb25urrrqKAwcO1OCrKIchchbff/+98dNPPxk7duwwduzYYUyYMMFwdXU14uPjDcMwjBdeeMHw9fU1vv76a+PPP/80brzxRiM8PNzIyckxOXndsHbtWqNZs2ZGhw4djPvvv790uca9ekycONFo166dkZKSUnpJT08vvV3jXj2ysrKMpk2bGmPGjDHWrFljJCUlGUuWLDF27dpVuo7Gvuqlp6eXea8vXrzYAIzly5cbhqExrw5TpkwxgoKCjB9//NFISkoyvvzyS8PHx8eYOnVq6Toa9+oxbNgwo23btsaKFSuMxMREY+LEiYafn59x4MABwzA07lVh3rx5xr/+9S/j66+/NgDjm2++KXN7Rcb4rrvuMho1amQsXrzY2Lhxo/F/7d17XE35/j/wV9fd7upS6aKLokgm0TBhVHIPDedIl6NiNAdRDMkwMzljGBwM4zaHcY/BYySXcxKjixK6X6SpKGVUp+NSkZTq/f3Dr/WzddllbLd5Px+P/XjYn89nrfVe77W2x/7sz2d9cnJyIhsbG6qvr3/NZ9My7jixDuvcuTP99NNP1NjYSHp6erRmzRqh7smTJ6SlpUU//vjjG4zw/fDw4UPq1asXnT9/nhwcHISOE+dddkJCQsjGxqbFOs677AQHB9OwYcNarefcvx6BgYFkbm5OjY2NnHMZcXFxoZkzZ0qUTZkyhf72t78REd/rsvL48WNSUFCgM2fOSJTb2NjQ8uXLOe8y8GLHqT05rqioICUlJTpy5IjQ5s6dOyQvL09nz559bbG3hafqsXZraGjAkSNHUF1dDXt7exQWFqKsrAyjR48W2ohEIjg4OCAhIeENRvp+8Pf3h4uLC0aOHClRznmXrfz8fBgYGKBHjx5wd3dHQUEBAM67LJ06dQp2dnaYOnUqdHV1YWtri127dgn1nHvZq6urQ2hoKGbOnAk5OTnOuYwMGzYMFy5cQF5eHgAgIyMD8fHxGD9+PAC+12Wlvr4eDQ0NUFFRkSgXi8WIj4/nvL8G7clxSkoKnj59KtHGwMAA1tbWb8114I4TkyorKwvq6uoQiUSYPXs2Tpw4ASsrK5SVlQEAunXrJtG+W7duQh17OUeOHEFqaiq+++67ZnWcd9kZPHgwDhw4gMjISOzatQtlZWUYMmQI7t27x3mXoYKCAuzYsQO9evVCZGQkZs+ejYCAABw4cAAA3/OvQ3h4OCoqKuDr6wuAcy4rwcHB8PDwQO/evaGkpARbW1ssWLAAHh4eADjvsqKhoQF7e3usXLkSJSUlaGhoQGhoKK5evYrS0lLO+2vQnhyXlZVBWVkZnTt3brXNm6b4pgNgbz9LS0ukp6ejoqICx48fh4+PD2JjY4V6OTk5ifZE1KyMtd/t27cRGBiIc+fONft17Hmc91dv3Lhxwr/79esHe3t7mJubY//+/fjoo48AcN5lobGxEXZ2dli9ejUAwNbWFtnZ2dixYwe8vb2Fdpx72dm9ezfGjRsHAwMDiXLO+at19OhRhIaG4vDhw+jbty/S09OxYMECGBgYwMfHR2jHeX/1Dh48iJkzZ8LQ0BAKCgoYMGAAPD09kZqaKrThvMvey+T4bboOPOLEpFJWVkbPnj1hZ2eH7777DjY2Nti8ebOw2tiLvwKUl5c3+0WBtV9KSgrKy8sxcOBAKCoqQlFREbGxsfjhhx+gqKgo5JbzLntqamro168f8vPz+X6XIX19fVhZWUmU9enTB8XFxQDAuZexoqIi/Prrr5g1a5ZQxjmXjaCgICxduhTu7u7o168fpk+fjoULFwqzCzjvsmNubo7Y2Fg8evQIt2/fRmJiIp4+fYoePXpw3l+D9uRYT08PdXV1ePDgQatt3jTuOLEOIyLU1tYK/9mcP39eqKurq0NsbCyGDBnyBiN8tzk7OyMrKwvp6enCy87ODl5eXkhPT4eZmRnn/TWpra1FTk4O9PX1+X6XoaFDhyI3N1eiLC8vDyYmJgDAuZexvXv3QldXFy4uLkIZ51w2Hj9+DHl5ya9eCgoKwnLknHfZU1NTg76+Ph48eIDIyEi4urpy3l+D9uR44MCBUFJSkmhTWlqKa9euvT3X4U2tSsHeDV988QVdvHiRCgsLKTMzk5YtW0by8vJ07tw5Inq2tKSWlhaFhYVRVlYWeXh48PKdMvD8qnpEnHdZWbRoEcXExFBBQQFduXKFJkyYQBoaGnTr1i0i4rzLSmJiIikqKtKqVasoPz+fDh06RKqqqhQaGiq04dzLRkNDAxkbG1NwcHCzOs75q+fj40OGhobCcuRhYWGkra1NS5YsEdpw3mXj7NmzFBERQQUFBXTu3DmysbGhQYMGUV1dHRFx3l+Fhw8fUlpaGqWlpREA2rhxI6WlpVFRURERtS/Hs2fPpu7du9Ovv/5KqampNGLECF6OnL07Zs6cSSYmJqSsrEw6Ojrk7OwsdJqIni0vGRISQnp6eiQSiWj48OGUlZX1BiN+P73YceK8y0bT35RQUlIiAwMDmjJlCmVnZwv1nHfZOX36NFlbW5NIJKLevXvTzp07Jeo597IRGRlJACg3N7dZHef81auqqqLAwEAyNjYmFRUVMjMzo+XLl1Ntba3QhvMuG0ePHiUzMzNSVlYmPT098vf3p4qKCqGe8/7HRUdHE4BmLx8fHyJqX45rampo3rx51KVLFxKLxTRhwgQqLi5+A2fTMjkiojc44MUYY4wxxhhjbz1+xokxxhhjjDHGpOCOE2OMMcYYY4xJwR0nxhhjjDHGGJOCO06MMcYYY4wxJgV3nBhjjDHGGGNMCu44McYYY4wxxpgU3HFijDHGGGOMMSm448QYY4wxxhhjUnDHiTHG3gKmpqbYtGnTmw4Djx8/xl/+8hdoampCTk4OFRUVr2zfcnJyCA8PBwDcunULcnJySE9Pb1d7xqRpz2eorq4OPXv2xKVLl176OLW1tTA2NkZKSspL74Mx9m7ijhNj7J3l6+sLOTk5yMnJQUlJCWZmZli8eDGqq6vfdGit2rdvHzp16tSsPCkpCZ999tnrD+gF+/fvR1xcHBISElBaWgotLS2J+t9++w1ycnK4evWqRPngwYMhEonw+PFjoayurg6qqqrYuXMnAKC0tBTjxo1rdyxN7fft2ydc59ZeMTExL33OrV2TF92/fx/z58+HpaUlVFVVYWxsjICAAFRWVra53Yv3abdu3TBq1Cjs2bMHjY2NMon1VfP19cUnn3witZ2joyMWLFjQrDw8PBxycnKvPrAO2rlzJ0xMTDB06FAAzzpB06dPh6amJiwtLREVFSXRft26dZg/f75EmUgkwuLFixEcHPza4maMvR2448QYe6eNHTsWpaWlKCgowLfffovt27dj8eLFLbZ9+vTpa46u/cfX0dGBqqrqa4ymZTdv3kSfPn1gbW0NPT29Zl92e/fuDX19fURHRwtljx49QlpaGnR1dZGQkCCUX716FTU1NXBycgIA6OnpQSQStTuWpvbTpk1DaWmp8LK3t4efn59E2ZAhQ/7gmUtXUlKCkpISrF+/HllZWdi3bx/Onj2LTz/9VOq2TffprVu3EBERAScnJwQGBmLChAmor6+XeezsmS1btmDWrFnC+507dyIlJQWXL1+Gn58fPDw8QEQAgMLCQvz0009YtWpVs/14eXkhLi4OOTk5ry12xtibxx0nxtg7TSQSQU9PD0ZGRvD09ISXl5cwvWvFihXo378/9uzZAzMzM4hEIhARiouL4erqCnV1dWhqasLNzQ3//e9/hX02bfevf/0LRkZGUFVVxdSpUyWmrTU2NuKbb75B9+7dIRKJ0L9/f5w9e1aob5qKduzYMTg6OkJFRQWhoaGYMWMGKisrhRGIFStWAGg+zai9MR48eBCmpqbQ0tKCu7s7Hj582Ga+jh8/jr59+0IkEsHU1BQbNmwQ6hwdHbFhwwZcvHgRcnJycHR0bHEfjo6OEiM8cXFxsLCwwKRJkyTKY2JiYGhoiF69egFoe+pdY2Mj/Pz8YGFhgaKiIon2YrEYenp6wktZWRmqqqrC+y5duuDLL7+EoaEh1NTUMHjwYCGOJ0+eoG/fvhKjeYWFhdDS0sKuXbsQExPT6jV5kbW1NY4fP46JEyfC3NwcI0aMwKpVq3D69GmpnZ+m+9TQ0BADBgzAsmXLcPLkSURERGDfvn1Cu40bN6Jfv35QU1ODkZER5s6di0ePHgn5bC3W0NBQ2NnZQUNDA3p6evD09ER5ebmw3wcPHsDLyws6OjoQi8Xo1asX9u7dK9TfuXMH06ZNQ+fOndG1a1e4urri1q1bAJ7da/v378fJkydfyQgfAGRkZMDJyQkaGhrQ1NTEwIEDkZycLNQnJCRg+PDhEIvFMDIyQkBAgMRIcnl5OSZOnAixWIwePXrg0KFDUo+ZmpqKGzduwMXFRSjLycnBpEmT0LdvX/j7+6O8vBx3794FAMyZMwdr166FpqZms3117doVQ4YMwc8///xH0sAYe8dwx4kx9l4Ri8USIzs3btzAsWPHcPz4ceF5mk8++QT3799HbGwszp8/j5s3b2LatGkS+2na7vTp0zh79izS09Ph7+8v1G/evBkbNmzA+vXrkZmZiTFjxmDSpEnIz8+X2E9wcDACAgKQk5MDZ2dnbNq0CZqamsJISUujY0TUrhhv3ryJ8PBwnDlzBmfOnEFsbCzWrFnTam5SUlLg5uYGd3d3ZGVlYcWKFfjqq6+EL+5hYWHw8/ODvb09SktLERYW1uJ+nJycEB8fL3QWoqOj4ejoCAcHB4mRqOjoaGG0qS11dXVwc3NDcnIy4uPjYWJiInWb582YMQOXLl3CkSNHkJmZialTp2Ls2LHIz8+HiooKDh06hP379yM8PBwNDQ2YPn06nJyc4OfnhyFDhrTrmrSmsrISmpqaUFRU7FDMADBixAjY2NhI5FleXh4//PADrl27hv379yMqKgpLliwBgDZjraurw8qVK5GRkYHw8HAUFhbC19dX2O9XX32F69evIyIiAjk5OdixYwe0tbUBPHuuzcnJCerq6rh48SLi4+Ohrq6OsWPHoq6uDosXL4abm5swavYqRvi8vLzQvXt3JCUlISUlBUuXLoWSkhIAICsrC2PGjMGUKVOQmZmJo0ePIj4+HvPmzRO29/X1xa1btxAVFYVffvkF27dvl+gotuTixYuwsLCQ6AjZ2NggPj4eNTU1iIyMhL6+PrS1tREaGgoVFRVMnjy51f0NGjQIcXFxfygPjLF3DDHG2DvKx8eHXF1dhfdXr16lrl27kpubGxERhYSEkJKSEpWXlwttzp07RwoKClRcXCyUZWdnEwBKTEwUtlNQUKDbt28LbSIiIkheXp5KS0uJiMjAwIBWrVolEc+HH35Ic+fOJSKiwsJCAkCbNm2SaLN3717S0tJqdi4mJib0/fffdyhGVVVVqqqqEtoEBQXR4MGDW82Xp6cnjRo1SqIsKCiIrKyshPeBgYHk4ODQ6j6IiPLy8ggAJSQkCOd97NgxKisrI2VlZaqurqba2loSi8W0e/duYTsAdOLECSL6//mJi4ujkSNH0tChQ6miokLiOM+3f56DgwMFBgYSEdGNGzdITk6O7ty5I9HG2dmZvvjiC+H9unXrSFtbm+bPn096enr0v//9T6hr7ZpIc/fuXTI2Nqbly5e32e7F+/R506ZNoz59+rS67bFjx6hr164djjUxMZEA0MOHD4mIaOLEiTRjxowW2+7evZssLS2psbFRKGu6fpGRkVLP4XnPX5vnnThxgp7/yqGhoUH79u1rcR/Tp0+nzz77TKIsLi6O5OXlqaamhnJzcwkAXblyRajPyckhAMJnqCWBgYE0YsQIibK6ujqaO3cumZqakp2dHcXFxdG9e/fIzMyMioqKaPny5WRubk6jR4+m33//XWLbzZs3k6mpaavHY4y9f3jEiTH2Tjtz5gzU1dWhoqICe3t7DB8+HFu2bBHqTUxMoKOjI7zPycmBkZERjIyMhDIrKyt06tRJ4nkFY2NjdO/eXXhvb2+PxsZG5ObmoqqqCiUlJcID5k2GDh3a7JkHOzu7Dp9Te2M0NTWFhoaG8F5fX7/NX91zcnJajDk/Px8NDQ3tjq9Xr17o3r07YmJiUFVVhbS0NDg4OKBbt27o0aMHLl26hCtXrqCmpgYjRoxoc18eHh549OgRzp0712whivZITU0FEcHCwgLq6urCKzY2Fjdv3hTaLVq0CJaWltiyZQv27t0rjLa0ZvXq1RL7Ky4ulqivqqqCi4sLrKysEBIS0uG4mxCRxHNk0dHRGDVqFAwNDaGhoQFvb2/cu3dP6oInaWlpcHV1hYmJCTQ0NIRplk1xz5kzB0eOHEH//v2xZMkSiWfRUlJScOPGDWhoaAjn26VLFzx58kQih6/S559/jlmzZmHkyJFYs2aNxHFSUlKwb98+ifyPGTMGjY2NKCwsRE5ODhQVFSU+W71795a6aEZNTQ1UVFQkypSUlLBt2zYUFhYiKSkJw4YNw+eff46AgACkp6cjPDwcGRkZ+OijjxAQECCxrVgsllgMhTH2/uOOE2Psnebk5IT09HTk5ubiyZMnCAsLg66urlCvpqYm0f7FL6rSyps01T3f5sX2Le3jxeO3R3tjbJra9Hw8ba3S1tJ+6f89CN9Rjo6OiI6ORlxcHHr16iXkvGm6XnR0NExMTGBqatrmfsaPH4/MzExcuXLlpeJobGyEgoICUlJSkJ6eLrxycnKwefNmoV15eTlyc3OhoKDQbDplS2bPni2xPwMDA6Hu4cOHGDt2LNTV1XHixIlm16EjcnJy0KNHDwBAUVERxo8fLzxLlZKSgm3btgFoe2GR6upqjB49Gurq6ggNDUVSUhJOnDgB4NkUPgAYN24cioqKsGDBApSUlMDZ2VmY5tfY2IiBAwdKnG96ejry8vLg6enZofPR1NRscZXBiooKiSlyK1asQHZ2NlxcXBAVFQUrKysh5sbGRvz973+XiCUjIwP5+fkwNzcX7tmOrtKnra2NBw8etNkmKioK169fx7x58xATE4Px48dDTU0Nbm5uzZ7run//vsSPMoyx91/HJ2UzxthbRE1NDT179mx3eysrKxQXF+P27dvCiM7169dRWVmJPn36CO2Ki4tRUlIifGG+fPky5OXlhWckDAwMEB8fj+HDhwvbJCQkYNCgQW0eX1lZWeroTntj7CgrKyvEx8dLlCUkJMDCwgIKCgod2peTkxMCAgJgZWUlsYiEg4MDtm7dCpFIJHW0CXg2EmJtbY1Jkybh3//+NxwcHDoUh62tLRoaGlBeXo6PP/641XYzZ86EtbU1/Pz88Omnn8LZ2RlWVlYAWr4mXbp0QZcuXZrtp6qqCmPGjIFIJMKpU6eajWB0RFRUFLKysrBw4UIAQHJyMurr67FhwwbIyz/7XfPYsWMS27QU62+//Ya7d+9izZo1wv3y/EILTXR0dODr6wtfX198/PHHCAoKwvr16zFgwAAcPXoUurq6LS6E0NpxW9K7d29EREQ0K09KSoKlpaVEmYWFBSwsLLBw4UJ4eHhg7969mDx5MgYMGIDs7OxWP9d9+vRBfX09kpOThc9bbm6u1L85Zmtrix07drT6w8STJ0/g7++Pw4cPQ0FBAQ0NDUIn7enTp83O/9q1a7C1tW3zmIyx9wuPODHG/lRGjhyJDz74AF5eXkhNTUViYiK8vb3h4OAgMfVHRUUFPj4+yMjIQFxcHAICAuDm5gY9PT0AQFBQENauXYujR48iNzcXS5cuRXp6OgIDA9s8vqmpKR49eoQLFy7g7t27LU71aW+MHbVo0SJcuHABK1euRF5eHvbv34+tW7d2aDGEJk5OTqiursaePXskOjsODg5ITk7GlStX2rUwBADMnz8f3377LSZMmNCsYyeNhYUFvLy84O3tjbCwMGHK1dq1a/Gf//wHALBt2zZcvnwZBw4cgKenJ/7617/Cy8tLGI1pzzUBno00jR49GtXV1di9ezeqqqpQVlaGsrIyqZ2K2tpalJWV4c6dO0hNTcXq1avh6uqKCRMmwNvbGwBgbm6O+vp6bNmyBQUFBTh48CB+/PFHif20FKuxsTGUlZWF7U6dOoWVK1dKbPf111/j5MmTuHHjBrKzs3HmzBmhE+7l5QVtbW24uroiLi4OhYWFiI2NRWBgIH7//XfhuJmZmcjNzcXdu3dbHQGbO3cubt68CX9/f2RkZCAvLw/btm3D7t27ERQUBODZlLmmEZ2ioiJcunQJSUlJQjzBwcG4fPky/P39kZ6ejvz8fJw6dUr4e0qWlpYYO3Ys/Pz8cPXqVaSkpGDWrFkQi8VtXoOmezY7O7vF+m+++QYuLi5CZ2jo0KEICwtDZmYmtm7d2myaa1xcHEaPHt3mMRlj75k382gVY4z9cdIeWA8JCSEbG5tm5UVFRTRp0iRSU1MjDQ0Nmjp1KpWVlTXbbvv27WRgYEAqKio0ZcoUun//vtCmoaGB/vGPf5ChoSEpKSmRjY0NRURECPVNix+kpaU1O/7s2bOpa9euBIBCQkKISHJxiI7E+Lzvv/+eTExMWs0HEdEvv/xCVlZWpKSkRMbGxvTPf/5Tor49i0M0MTExIQDCghlNzM3NCYDE4hpELS8O8Xx+NmzYQBoaGnTp0qVm7Z/34gIEdXV19PXXX5OpqSkpKSmRnp4eTZ48mTIzMyknJ4fEYjEdPnxYaF9ZWUmmpqa0ZMkSoayla/Ki6OhoAtDiq7CwsNU8+fj4CO0UFRVJR0eHRo4cSXv27KGGhgaJths3biR9fX0Si8U0ZswYOnDgAAGgBw8etBnr4cOHydTUlEQiEdnb29OpU6ck8rty5Urq06cPicVi6tKlC7m6ulJBQYGwz9LSUvL29iZtbW0SiURkZmZGfn5+VFlZSURE5eXlNGrUKFJXVycAFB0d3er5Jicn05gxY0hXV5c0NTXJzs6Ofv75Z6G+traW3N3dycjIiJSVlcnAwIDmzZtHNTU1QpvExETheGpqavTBBx9ILMZSWlpKLi4uJBKJyNjYmA4cONDsM9QSd3d3Wrp0abPyrKws6tmzJz169Egoa2hooDlz5pCmpiZ9+OGHlJ+fL9QlJCRQp06d6PHjx20ejzH2fpEjeskJ7owx9p5asWIFwsPDheXLGWPvh6ysLIwcOVJYDONlTZ06Fba2tli2bNkrjI4x9rbjqXqMMcYY+1Po168f1q1bJ/xx35dRW1sLGxsb4dk0xtifBy8OwRhjjLE/DR8fnz+0vUgkwpdffvmKomGMvUt4qh5jjDHGGGOMScFT9RhjjDHGGGNMCu44McYYY4wxxpgU3HFijDHGGGOMMSm448QYY4wxxhhjUnDHiTHGGGOMMcak4I4TY4wxxhhjjEnBHSfGGGOMMcYYk4I7TowxxhhjjDEmxf8BxRUV9PfjHdgAAAAASUVORK5CYII=
"
class="
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Training complete.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>







</html>
